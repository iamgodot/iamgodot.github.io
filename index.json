[{"content":"和之前的习惯一样，这次去扬州也是期待了很久，然后来了一场说走就走的旅行。\n故人西辞黄鹤楼，烟花三月下扬州。\n孤帆远影碧空尽，唯见长江天际流。\n\u0026ndash; 李白\n遥在疫情之前就向往在三月游玩扬州，却一直拖到了现在。不过最近才知道，古人说的烟花三月其实是四月份，避开凉意尚存的四月和拥挤的五一假期，我总算得以在夏天来临之际前往这座心系已久的小城。\n出发时苏州正好下雨，凉快得很，坐高铁一个多小时便到了。订的民宿位置很便利，在彩衣街，邻着有名的东关街。安顿好已经是晚上了，民宿老板推荐了附近的蒋家桥饺面，据说这是当地有名的老店，随意点了三丁包、烫干丝和干拌面，价格都很便宜。其中三丁包肥而不腻，烫干丝微甜爽口，吃得非常满足。随后便顺道逛了逛旁边的东关街。这里可以类比北京的南锣鼓巷，这时候游客不算多，街道干净，也不吵闹，很适合雨后的晚上漫步。\n位于街角的老店\n三丁包\n烫干丝\n东关街尽头的城楼\n第一天 瘦西湖是我的第一站。早饭本打算就近去怡园，这其实是个酒店的餐厅，听说口碑不错，但到了才发现十分拥挤，服务员也顾不上招呼。我不喜欢扎堆，便随意找了个小店，感觉更贴近当地人的生活。\n碳水满满的饺面\n到了瘦西湖，已经有不少人在排队了。可能因为前一天刚下过雨，天气很凉爽。买票进去的时候撞见了热闹，前面的两个阿姨用的证件同名同姓，工作人员起了疑心，便要求出示身份证，双方僵持不下。估计就是为了省钱做的手脚，但说实话门票确实不便宜，白天100，夜场120，不过逛了一圈下来我觉得还是很划算的，瘦西湖的美景名不虚传。\n整个景区还是很大的\n因为我家 KIDDO 不舒服，索性给她来了个直播游览。从南大门开始，一路向北，第一次体验到了网红博主的感觉，原来远程的陪伴也可以很温暖。虽然是工作日，也躲开了假期，游客仍然不少，大部分是跟团旅游的大爷大妈，想来这种 5A 级景区什么时候人都不会少的。从北门出去之后还有大明寺可以逛，但已经临近中午，我便直奔饭馆了。\n我的 KIDDO 说拍得很好\n随后又来到了个园，这里号称是中国四大名园之一。好奇上网查了一下，有说其实没有个园，而是苏州的留园，但是后来又有了个园的说法，总之都是为了吸引游客，对我来说欣赏美景才是最重要的。个园的名字出处很有意思，园主人好竹，所以栽种了各类竹子，而竹便是个字组成的。\n竹林一瞥\n此朴树非彼朴树\n中间的石头貌似很有讲究\n从个园出来又是东关街，看了眼手环已经走了两万多步，着实有点儿累，便直接回去补了个觉。路上还买了扬大酸奶，据说是扬州大学研发的，已经成为本地的网红美食了。有很多种口味，我买了茉莉花和芒果的，前者的花香搭配酸奶的浓稠口感尤其好喝，推荐。\n只要 3.5，很实惠\n一觉醒来，该吃晚饭了。本来有个红星餐厅想打卡的，可惜已经打烊了，于是又去了蒋家桥。这次点了锅贴和馄饨，再配上醋和辣椒，吃得不亦乐乎。\n笋肉锅贴，鲜嫩多汁\n虾籽馄饨，量大份足\n吃完决定去试试扬州搓澡。聊天之间感受到了扬州师傅的热情，还尝试了烫背，非常解乏。这才是真正的洗澡呀。结束之后天已经黑透，便直接回去睡觉了。\n第二天 昨天走得有点儿累，今天就打算悠闲一些。出门先买了个街边的青稞馍，刚出炉的，清甜可口。然后便来到了仁丰里，这条小街和北京的五道营胡同很像，呈现出的都是市井生活与现代美感的交融。\n外酥里嫩\n仁丰里\n竹林，还有鲜花\n前面好像是个民族建筑\n走到尽头，是一家网红的小吃店，叫做樊记火烧。他们家的烧饼夹鸡蛋油香四溢，层次分明。后来我发现里面还加了五花肉来增加口感，怪不得味道如此诱人。\n据说到了下午就会人满为患\n一个字，香\n一边吃着一边往何园走，路上突然收到了 OPR 的邮件，心情大好，没想到在扬州收获了意外之喜。阳光明媚，在何园里和我家 KIDDO 畅想未来，甚至无暇顾及园内的美景。这里不负晚清第一园的盛名，构思精巧，相比个园更加引人入胜。另外，我发现欣赏景点还是需要导游的讲解才能理解其中的奥妙，不然很容易走马观花。比如片石山房的水中月，以假山堆叠出来的圆洞映射在湖面，既精巧又隐蔽。\n假山上的亭子\n倚南窗以寄傲，审容膝之易安。登东皋以抒啸，临清流而赋诗。取自陶渊明的归去来兮辞\n相映成趣\n心中若无烦恼事，便是人生好时节\n月牙形的小门\n之后来到皮市街，进了一家日式小店，环境不错，安静优雅。点了个手作芝士豆腐，浇上蜂蜜，清甜细腻，比冰激凌更解暑。室内的空调有点儿凉，我便又换到了二楼的阳台，在一片树荫下，偶尔有微风吹过，稍作小憩，又看了会儿书，最后心满意足地离开了。\n细腻爽滑，胜似冰激凌\n室外比室内更舒服\n晚饭本来想去前一天没赶上的红星，却正好路过了之前在小红书看到的狮子楼，于是便改了主意。这家是主打淮扬菜的老店，除了招牌的极品狮子头，我还点了大煮干丝和扬州炒饭。狮子头口感细腻，里面还藏了个蛋黄，可惜口味太淡了，就像没放盐一样，实在喜欢不起来，还是挺遗憾的。大煮干丝和扬州炒饭很棒，吃了个肚儿圆。饭后顺着一条小巷慢悠悠地溜达回去，心里还在因为 OPR 激动不已，很美好的一天。\n极品狮子头\n大煮干丝\n扬州炒饭\n喜欢这座小城，也喜欢这种随性的旅行，没有固定行程，也不用为了打卡匆忙赶路。虽然还有很多地方没去，比如大明寺，还有大运河博物馆，但这也让我对下一次的扬州之行充满了期待。\n希望早日和我家 KIDDO 团聚，也希望下次再来扬州就是两个人一起啦。\n","permalink":"https://iamgodot.com/posts/visit-yangzhou/","summary":"和之前的习惯一样，这次去扬州也是期待了很久，然后来了一场说走就走的旅行。\n故人西辞黄鹤楼，烟花三月下扬州。\n孤帆远影碧空尽，唯见长江天际流。\n\u0026ndash; 李白\n遥在疫情之前就向往在三月游玩扬州，却一直拖到了现在。不过最近才知道，古人说的烟花三月其实是四月份，避开凉意尚存的四月和拥挤的五一假期，我总算得以在夏天来临之际前往这座心系已久的小城。\n出发时苏州正好下雨，凉快得很，坐高铁一个多小时便到了。订的民宿位置很便利，在彩衣街，邻着有名的东关街。安顿好已经是晚上了，民宿老板推荐了附近的蒋家桥饺面，据说这是当地有名的老店，随意点了三丁包、烫干丝和干拌面，价格都很便宜。其中三丁包肥而不腻，烫干丝微甜爽口，吃得非常满足。随后便顺道逛了逛旁边的东关街。这里可以类比北京的南锣鼓巷，这时候游客不算多，街道干净，也不吵闹，很适合雨后的晚上漫步。\n位于街角的老店\n三丁包\n烫干丝\n东关街尽头的城楼\n第一天 瘦西湖是我的第一站。早饭本打算就近去怡园，这其实是个酒店的餐厅，听说口碑不错，但到了才发现十分拥挤，服务员也顾不上招呼。我不喜欢扎堆，便随意找了个小店，感觉更贴近当地人的生活。\n碳水满满的饺面\n到了瘦西湖，已经有不少人在排队了。可能因为前一天刚下过雨，天气很凉爽。买票进去的时候撞见了热闹，前面的两个阿姨用的证件同名同姓，工作人员起了疑心，便要求出示身份证，双方僵持不下。估计就是为了省钱做的手脚，但说实话门票确实不便宜，白天100，夜场120，不过逛了一圈下来我觉得还是很划算的，瘦西湖的美景名不虚传。\n整个景区还是很大的\n因为我家 KIDDO 不舒服，索性给她来了个直播游览。从南大门开始，一路向北，第一次体验到了网红博主的感觉，原来远程的陪伴也可以很温暖。虽然是工作日，也躲开了假期，游客仍然不少，大部分是跟团旅游的大爷大妈，想来这种 5A 级景区什么时候人都不会少的。从北门出去之后还有大明寺可以逛，但已经临近中午，我便直奔饭馆了。\n我的 KIDDO 说拍得很好\n随后又来到了个园，这里号称是中国四大名园之一。好奇上网查了一下，有说其实没有个园，而是苏州的留园，但是后来又有了个园的说法，总之都是为了吸引游客，对我来说欣赏美景才是最重要的。个园的名字出处很有意思，园主人好竹，所以栽种了各类竹子，而竹便是个字组成的。\n竹林一瞥\n此朴树非彼朴树\n中间的石头貌似很有讲究\n从个园出来又是东关街，看了眼手环已经走了两万多步，着实有点儿累，便直接回去补了个觉。路上还买了扬大酸奶，据说是扬州大学研发的，已经成为本地的网红美食了。有很多种口味，我买了茉莉花和芒果的，前者的花香搭配酸奶的浓稠口感尤其好喝，推荐。\n只要 3.5，很实惠\n一觉醒来，该吃晚饭了。本来有个红星餐厅想打卡的，可惜已经打烊了，于是又去了蒋家桥。这次点了锅贴和馄饨，再配上醋和辣椒，吃得不亦乐乎。\n笋肉锅贴，鲜嫩多汁\n虾籽馄饨，量大份足\n吃完决定去试试扬州搓澡。聊天之间感受到了扬州师傅的热情，还尝试了烫背，非常解乏。这才是真正的洗澡呀。结束之后天已经黑透，便直接回去睡觉了。\n第二天 昨天走得有点儿累，今天就打算悠闲一些。出门先买了个街边的青稞馍，刚出炉的，清甜可口。然后便来到了仁丰里，这条小街和北京的五道营胡同很像，呈现出的都是市井生活与现代美感的交融。\n外酥里嫩\n仁丰里\n竹林，还有鲜花\n前面好像是个民族建筑\n走到尽头，是一家网红的小吃店，叫做樊记火烧。他们家的烧饼夹鸡蛋油香四溢，层次分明。后来我发现里面还加了五花肉来增加口感，怪不得味道如此诱人。\n据说到了下午就会人满为患\n一个字，香\n一边吃着一边往何园走，路上突然收到了 OPR 的邮件，心情大好，没想到在扬州收获了意外之喜。阳光明媚，在何园里和我家 KIDDO 畅想未来，甚至无暇顾及园内的美景。这里不负晚清第一园的盛名，构思精巧，相比个园更加引人入胜。另外，我发现欣赏景点还是需要导游的讲解才能理解其中的奥妙，不然很容易走马观花。比如片石山房的水中月，以假山堆叠出来的圆洞映射在湖面，既精巧又隐蔽。\n假山上的亭子\n倚南窗以寄傲，审容膝之易安。登东皋以抒啸，临清流而赋诗。取自陶渊明的归去来兮辞\n相映成趣\n心中若无烦恼事，便是人生好时节\n月牙形的小门\n之后来到皮市街，进了一家日式小店，环境不错，安静优雅。点了个手作芝士豆腐，浇上蜂蜜，清甜细腻，比冰激凌更解暑。室内的空调有点儿凉，我便又换到了二楼的阳台，在一片树荫下，偶尔有微风吹过，稍作小憩，又看了会儿书，最后心满意足地离开了。\n细腻爽滑，胜似冰激凌\n室外比室内更舒服\n晚饭本来想去前一天没赶上的红星，却正好路过了之前在小红书看到的狮子楼，于是便改了主意。这家是主打淮扬菜的老店，除了招牌的极品狮子头，我还点了大煮干丝和扬州炒饭。狮子头口感细腻，里面还藏了个蛋黄，可惜口味太淡了，就像没放盐一样，实在喜欢不起来，还是挺遗憾的。大煮干丝和扬州炒饭很棒，吃了个肚儿圆。饭后顺着一条小巷慢悠悠地溜达回去，心里还在因为 OPR 激动不已，很美好的一天。\n极品狮子头\n大煮干丝\n扬州炒饭\n喜欢这座小城，也喜欢这种随性的旅行，没有固定行程，也不用为了打卡匆忙赶路。虽然还有很多地方没去，比如大明寺，还有大运河博物馆，但这也让我对下一次的扬州之行充满了期待。\n希望早日和我家 KIDDO 团聚，也希望下次再来扬州就是两个人一起啦。","title":"游扬州"},{"content":"With Neovim and null-ls plugin we can make code formatting work like a charm, as I stated in My Neovim Revamp previously. While I was happily enjoying it, I did some tweaking for a little more convenience, such as:\nFormat on save.\nCustomize formatter.\nFormat conditionally in runtime.\nLet\u0026rsquo;s get right into it.\nFormat on save This is plain easy if you check out the wiki of null-ls. According to this part, all you need is copy\u0026amp;paste the code into your own config.\nCustomize ruff\u0026amp;stylua Formatters supported by null-ls all have defaults, like arguments. Sometimes we want to add more options, and that\u0026rsquo;s when extra_args comes in handy.\nFor instance, I\u0026rsquo;m using ruff for Python formatting to replace isort, so customization becomes:\nrequire(\u0026#34;null-ls\u0026#34;).builtins.formatting.ruff.with({ extra_args = { \u0026#34;--select\u0026#34;, \u0026#34;I\u0026#34; } }) And for Lua, I want stylua to use spaces instead of tabs, so I did:\nrequire(\u0026#34;null-ls\u0026#34;).builtins.formatting.stylua.with({ extra_args = { \u0026#34;--indent-type\u0026#34;, \u0026#34;Spaces\u0026#34; } }) In addition, you can replace default arguments totally with args, by following the config instruction here.\nBTW, I found a few tricks regarding tabs\u0026amp;spaces:\nIn Neovim:\nUse :retab to replace tabs with spaces(number of spaces defined by tabstop).\nUse :set list to show tabs marking as \u0026gt; and trailing spaces as -.\nIn Shell:\nUse sed to convert tabs to spaces in a bunch of files at one time.\nOn Linux: sed -i \u0026quot;s/\\t//g\u0026quot; /path/to/files.\nOn macOS: sed -i \u0026quot;\u0026quot; \u0026quot;s/\\t//g\u0026quot; /path/to/files. Here -i stands for extension rather than in-place editing.\nFormat conditionally Auto-formatting is sweet, but what if I don\u0026rsquo;t want it? When I\u0026rsquo;m reading some source code or working on a shared project, I want things kept as they were.\nToggling formatters on\u0026amp;off can be annoying, is there a smarter way?\nYes, there sure is. Turns out null-ls has a runtime_condition setting to force it to check whether a formatter should run for the current buffer.\nEssentially, you just need to add a function to determine if formatting is needed:\nrequire(\u0026#34;null_ls\u0026#34;).builtins.formatting.black.with({ runtime_condition = function(params) return string.match(params.bufname, \u0026#34;source\u0026#34;) == nil end, }) I keep all source code projects in ~/projects/source. Based on the above config black will check if current file belongs under this particular path, and if it is, no auto-formatting will be performed.\nJust like this, you can easily split things up with a suitable condition statement in Lua. For reference of how to better write it, see:\nruntime_condition\nparams\nHope these tips can be helpful :)\n","permalink":"https://iamgodot.com/posts/formatting-in-neovim/","summary":"With Neovim and null-ls plugin we can make code formatting work like a charm, as I stated in My Neovim Revamp previously. While I was happily enjoying it, I did some tweaking for a little more convenience, such as:\nFormat on save.\nCustomize formatter.\nFormat conditionally in runtime.\nLet\u0026rsquo;s get right into it.\nFormat on save This is plain easy if you check out the wiki of null-ls. According to this part, all you need is copy\u0026amp;paste the code into your own config.","title":"Formatting in Neovim"},{"content":"Thanks to my lovely gf, I have been able to get my hands on an Apple M2 lately. Coming from Arch with i3, I thought I\u0026rsquo;d get to this more UI-based and mouse-involved operating system, which seems like a degradation. However, after some digging, it becomes really comfortable for me being both elegant and efficient.\nGeneral setup I would skip the system settings part, where you may want to customize display, input methods, or modifier keys etc.\nPackage manager First of all, we need a proper tool to be in charge of all the installations, and Homebrew has been the de facto package manager for macOS since a very long time ago.\nIt\u0026rsquo;s worth noting that since 4.0.0, Homebrew finally ditches its intolerable low-speed updating by switching to JSON:\nToday, I’d like to announce Homebrew 4.0.0. The most significant change since 3.6.0 enables significantly faster Homebrew-maintained tap updates by migrating from Git-cloned taps to JSON downloads.\nWhich reminds me that this used to be a major reason for me not liking macOS. It always tried to update before executing every command, which was extremely inefficient.\nIn addition, there\u0026rsquo;s a new adopt option for brew install now, hence if you have already downloaded and installed something, you could let Homebrew take it over by brew install --adopt $APP.\nNow that we\u0026rsquo;re ready to install applications, I\u0026rsquo;d like to share my common list:\nLauncher: Raycast. I use this instead of Alfred.\nNote-taking\nLogseq: I keep everything here.\nObsidian: some features are amazing, e.g. the canvas drawing.\nNotion: great choice when it comes to sharing and co-working.\nBlogging\nMarkText: good replacement for Typora. PicGo: useful for uploading images to cloud storage. Mind mapping: MindNode. You can\u0026rsquo;t install this by Homebrew, but it\u0026rsquo;s definitely worth the trouble. The above mind map was made by this.\nMedia player: IINA. Open source, modern and smooth.\nScreenshot: Shottr. This supports scrolling screenshot.\nLauncher A good launcher is key to be efficient. Raycast comes with:\nLaunching\nApplications.\nFile search.\nOnline search.\nClipboard history: supports images as well.\nFloating note: very useful for quick noting.\nWindow management: easily arrange every window.\nUtils\nCheck other timezones.\nCheck currency rates.\nCalculations.\nIt also has many extensions, I mainly use:\nGitHub\nEasy dictionary\nEmoji search\nBesides, you can set alias and hotkeys for accessing all these functions to be just one or two keystrokes, such as f for file finding or g for Google searching.\nFinally, you can export and import a config file from Raycast, although for now they have to be done manually.\nDev setup Now that we finished everything as normal people, it\u0026rsquo;s time to open a terminal and play.\nBefore diving We need a good toolkit to start with, such as a friendly shell and a powerful editor.\nTo start with, I use Alacritty as my terminal emulator. It\u0026rsquo;s fast, and another good thing about it is you can customize by a simple config file with instant effect upon saving. See here for detailed configuration options.\nOn top of that, I always choose the classic combination:\nZsh: I use Ohmyzsh for its configuration and Powerlevel10k as theme. There are also nice alternatives, e.g. Starship.\nTmux: the terminal multiplexing is all good, except when restarting the machine, which makes Tmux-resurrect super useful.\nNeovim: check out my last post My Neovim Revamp.\nNow we can head out and prepare for coding, and I\u0026rsquo;m going to present for Python.\nPython MacOS has builtin Python installed, which we can call System Python. Besides, we need Dev Python, so that we can keep the former out of the hands of our projects.\nFor System Python, we leave the original one which resides in /usr/bin/python3 alone by introducing an installation via Homebrew. This System Python by Homebrew locates at /opt/homebrew/bin/python3, which in fact is a link and finally points to somewhere in the Cellar, e.g. /opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/bin/python3.11.\nFor Dev Python, we simply leverage on Pyenv. It allows us to keep multiple versions of Python and easily switch among them by commands, environment variables or special .python-version files.\nYou can read this blog for more on this topic.\nCLI tool Sometimes we want command line tools and we want them to be globally available, such as http by Httpie. In this case we should use Pipx, of which the slogan states:\nInstall and Run Python Applications in Isolated Environments.\nIt spares virtual environments for each application installed thus we can manage them effortlessly without worrying about dependency conflict.\nVirtual environment Finally we come to our projects. We choose a proper Python version via Pyenv, and the next step is to create a virtual environment.\nThere\u0026rsquo;re a lot of choices, and they\u0026rsquo;re still growing. I\u0026rsquo;ve tried the following:\nVirtualenv\nPipenv\nPew\nPoetry\nPDM\nEssentially a good one should satisfy 2 needs:\nPackage CRUD: installation, uninstallation, upgrade etc.\nVersion tracking: via whether requirements.txt or some other kind of lock files.\nIf you\u0026rsquo;re contributing to other projects, you may have to adapt to their selection. For myself, I use PDM currently for a few good reasons:\nIt\u0026rsquo;s based on a mature project and well-maintained.\nIt\u0026rsquo;s designed as smart and handy with elegant APIs.\nIt\u0026rsquo;s documented thoroughly.\nIt supports PEP 582.\nREPL Python developers are lucky to have IPython, and Jupyter levels things up further with web-based notebooks. Since JupyterLab depends on IPython, we can put them together:\n# This will expose ipython executable as well pipx install jupyterlab --include-deps ipython # Install a better dark theme in the same virtual environment pipx inject jupyterlab jupyterlab_materialdarker At last The above may seem a little overwhelming, and we certainly don\u0026rsquo;t want to repeat it every time on a new machine. I wrap things up in my dotfiles so that I can setup with just one command. Take a look for all the softwares and tips I mentioned.\nReferences\nmacOS Setup Guide\nBest Python Development Setup for 2022 and Beyond - laike9m\u0026rsquo;s blog\n","permalink":"https://iamgodot.com/posts/my-mac-setup/","summary":"Thanks to my lovely gf, I have been able to get my hands on an Apple M2 lately. Coming from Arch with i3, I thought I\u0026rsquo;d get to this more UI-based and mouse-involved operating system, which seems like a degradation. However, after some digging, it becomes really comfortable for me being both elegant and efficient.\nGeneral setup I would skip the system settings part, where you may want to customize display, input methods, or modifier keys etc.","title":"My Mac Setup"},{"content":"Yeah, I did it again, but for a good reason.\nI have been using VSCode for while, which is great with plugins like GitLens and Docker. Besides, it\u0026rsquo;s really handy to debug code, view all kinds of files and draw various diagrams such as UML. I thought I\u0026rsquo;d wave my hands to Neovim, however, I found I still need it, a lot.\nNot trying to nitpick, but I have to switch between keyboard and mouse from time to time with VSCode, which sometimes can really interrupt my train of thoughts. In addition, it doesn\u0026rsquo;t feel effortless to use terminal as when I\u0026rsquo;m in a Tmux session.\nFor whatever it\u0026rsquo;s worth, I spent some hours on picking Neovim back and upgrading everything. Now it feels unprecedentedly smooth and efficient, and I\u0026rsquo;d like to share how I revamped my configs.\nTry it out First and most important of all, a showcase:\nOf course, you will need Neovim + Git + Lua installed. It\u0026rsquo;s better to have black + isort + ruff executables since I use them for Python linting and formatting.\nThen replace your ~/.config/nvim with my https://github.com/iamgodot/dotfiles/tree/master/nvim folder and open with nvim to see how everything goes.\nIf it works as expected, lazy.nvim is going to take over and install everything shortly, then you\u0026rsquo;re all set.\nIn case things go south, please leave a comment and let me know. Now if you\u0026rsquo;re still interested, read along and I\u0026rsquo;ll explain as much I can.\nWhy Neovim So I ask myself, why don\u0026rsquo;t I just use Vim? Let\u0026rsquo;s see how Neovim states for itself:\nI notice documented API\u0026amp;compatible with Vim, and I\u0026rsquo;m interested in that builtin terminal emulator, but what really got me is the Lua support for config and plugins. To me, it feels lighter and simpler to use and learn, after all, it\u0026rsquo;s a real programming language. From the Lua guide it provides, we can easily pick up:\nNeovim supports a init.lua config file with which you can replace init.vim. Lua uses require() to load other modules, so you can do require(foo.bar). foo.bar or foo/bar means a sub-module bar under module foo. My configs Here is my structure of my config files:\nTo simply put it, the init.lua loads lazy.lua, which utilizes lazy.nvim, a plugin manager to install and setup every other plugin inside plugins. Besides, it will also import from config to configure Vim options and keymaps.\nMy plugins It takes a proper combination of plugins to have excellent experiences with Neovim, which is also the best part to enjoy while setting up.\nPlugin manager I\u0026rsquo;ve used vim-plug for a very long time while now the popular one is lazy.nvim. So I jumped right into it.\nIt provides a nice UI where you can manage all the packages, and I like how everything gets explained thoroughly in its documents, which is very friendly for starters, even those who are not.\nIn fact there\u0026rsquo;s even a full-fledged setup repo based on this plugin manager, called LazyVim , so that you can build your own on top of it.\nFuzzy finder Besides coding, we\u0026rsquo;re always searching stuff, therefore a powerful fuzzy finder is vital. There were ctrlp and fzf, and now it is telescope.\nIt has pickers, sorters and previewers. So you can find files, do live grep, and search through nearly everything such as help documents, git commits and command history. Just imagine away.\nBTW, this could become a test for your keymapping design skill. I tried my best to figure out proper leader key combinations.\nLSP support This ought to be the most complex part, so I\u0026rsquo;ll try to make the best sense of it and explain logically.\nFirst thing to know is LSP requires both client and server, in order to provide code functions like auto-completion. Neovim already has builtin LSP client so we just need to install servers(for our languages) and configure properly.\nTherefore we introduce mason, which plays a role of language server installer. Just type :Mason and install accordingly. This is convenient since we no longer have to prepare executables ourselves, e.g. pip install --user black. Pure installation won\u0026rsquo;t suffice, sometimes we need a bit more integration.\nFor LSP configuration, mason-lspconfig allows us to work easier with nvim-lspconfig. Let\u0026rsquo;s look at some setup code:\n... local servers = { pyright = {}, lua_ls = {}, } local capabilities = vim.lsp.protocol.make_client_capabilities() capabilities = require(\u0026#34;cmp_nvim_lsp\u0026#34;).default_capabilities(capabilities) require(\u0026#34;mason\u0026#34;).setup() local mason_lspconfig = require(\u0026#34;mason-lspconfig\u0026#34;) mason_lspconfig.setup({ ensure_installed = vim.tbl_keys(servers), }) mason_lspconfig.setup_handlers({ function(server_name) require(\u0026#34;lspconfig\u0026#34;)[server_name].setup({ capabilities = capabilities, on_attach = on_attach, settings = servers[server_name], }) end, }) Basically there\u0026rsquo;re two things. One is keep servers installed by ensure_installed, the other is setup handlers for them. I only add a default handler yet dedicated ones can be set for certain languages. Moreover, on_attach is usually for keymapping and capabilities comes in handy for broadcasting to server with additional functionality such as snippets, you can check from lspconfig document.\nFor linters and formatters, null-ls is a plugin which makes it every easy to setup these utilities. I setup classic black, isort as well as the new hot ruff, and for Lua I picked stylua, which seems just as opinionated as black.\nNow we have linting and formatting, and we can go to definition etc. There\u0026rsquo;s only one missing piece left called completion. To achieve that we just need nvim-cmp along with some helpers. I chose LuaSnip with friendly-snippets as its source, and nvim-path for file path completion.\nSo far we\u0026rsquo;ve got everything covered for code functions, in which each part can be further extended to support more languages and richer functionalities.\nMiscellaneous There\u0026rsquo;s no reason to stop here, because so many more await. I\u0026rsquo;ll list some of them here:\nnvim-tree: file explorer. vim-fugitive: git helper. nvim-autopairs: simple yet necessary. trouble: manage diagnostics in a better way. lightspeed: my favorite for faster movements. vim-airline + tmuxline: decorate status lines for both Neovim and Tmux. Last but not least, you deserve nice color schemes, here\u0026rsquo;s my recommendation:\ntokyonight: good and dark. catppuccin: pretty and elegant. neosolarized: classic forever. space-vim-dark: I used it all the time. rose-pine: Heard they\u0026rsquo;re for minimalist. At last In my mind, using Neovim is all about fast(well, maybe not themes), and once you make it your own, no one can ever steal that from you. I feel so safe with it.\nReferences\nMy dotfiles ","permalink":"https://iamgodot.com/posts/my-neovim-revamp/","summary":"Yeah, I did it again, but for a good reason.\nI have been using VSCode for while, which is great with plugins like GitLens and Docker. Besides, it\u0026rsquo;s really handy to debug code, view all kinds of files and draw various diagrams such as UML. I thought I\u0026rsquo;d wave my hands to Neovim, however, I found I still need it, a lot.\nNot trying to nitpick, but I have to switch between keyboard and mouse from time to time with VSCode, which sometimes can really interrupt my train of thoughts.","title":"My Neovim Revamp"},{"content":"从感染新冠到现在差不多两周，除了咳嗽，再加上嗅觉和味觉的失灵，已经没有太大的不适了。\n本来以为过了这么久，自己已经不会再感染，可惜因为需要在医院照顾家人，还是不幸中招了。简单记录一下症状的变化：\n第一天中午，开始感觉到头疼、腰酸，吃了布洛芬之后缓解，测试抗原非阳性。 第二天头疼的症状基本消失，嗓子开始剧痛，测试抗原依旧非阳性。 第三天症状集中在嗓子痛和剧烈咳嗽，测试抗原终于呈现阳性。 第四天嗓子基本恢复，开始出现轻微的感冒症状，咳嗽加剧。 后面随着休息咳嗽渐渐减轻，一周之后感觉到嗅觉和味觉的消失。 整体来说我没有出现发烧、肌肉酸痛等严重影响正常活动的症状，除了一点布洛芬和感冒冲剂也并未吃其他的药，只是精神确实不如平时，需要更多的睡眠了。\n在家窝了太久，今天早上便打算出去走走。正好想起来以前看过一本冥想的入门书，上面介绍过如何在走路时冥想。今年以来还没有好好地练习过，于是便有了这病后的第一次步行冥想体验。\n因为最近脑子里的事情很多，想一下进入清明的状态并不容易，所以我设置了十分钟倒计时，打算先只做一次简单的恢复性训练。\n散步和静坐还是很不一样的，鸟叫、人声、车来车往，极其容易分心。我努力让自己融入到环境中，体会身边的一切。眼前的道路、树木、楼房以及行人，形状颜色各不相同；耳边的风声、人语、发动机轰鸣，交杂在一起却又可以分辨；手指露在外面，一阵微寒传导至脖颈，有汗毛竖立的感觉。只是因为嗅、味觉的钝化，世界缺少了重要的一环，不禁有点沮丧。\n事实上，这些体察全都发生在电光火石之间，我微微调整思绪，开始沿路绕行，尽量让自己的脚步慢一点，稳一些。眼前的画面晃动起来，脑中的想法也随之起舞。我习惯通过专注呼吸的节奏代替平时的浮想联翩，从而进入归寂的状态。而这次明显很难做到，即使默念着一吸、一呼，各种各样的回忆、计划、想象迅速弥漫，神游不知多久，突然意识到自己的失控，于是再次回归呼吸，进入下一次的尝试。这大概有些像扫地，每下都可以荡开一些尘土，但无论多么用力也无法一次完成。\n到了后半段，我渐渐能够持续较久的专注了，也感觉到了一阵轻松。也许是注意力集中，甚至没有怎么咳嗽。最后，开始觉得时间过于漫长，正要看看十分钟有没有到，却又想到，时间可以只是物质的一种体现，如果所有的粒子保持原位，那么世界便静止了。正琢磨着，手环响起，时间终于到了，原来短短几分钟也可以如此之久。掩藏的思绪又开始泛起，我也不打算强求，便结束了这次冥想。\n抬头看了看天，阳光从灰蒙蒙的雾霾中挣扎出来，心中浮起思念，真希望时间过得快一点，再快一点。\n","permalink":"https://iamgodot.com/posts/first-meditation-after-covid/","summary":"从感染新冠到现在差不多两周，除了咳嗽，再加上嗅觉和味觉的失灵，已经没有太大的不适了。\n本来以为过了这么久，自己已经不会再感染，可惜因为需要在医院照顾家人，还是不幸中招了。简单记录一下症状的变化：\n第一天中午，开始感觉到头疼、腰酸，吃了布洛芬之后缓解，测试抗原非阳性。 第二天头疼的症状基本消失，嗓子开始剧痛，测试抗原依旧非阳性。 第三天症状集中在嗓子痛和剧烈咳嗽，测试抗原终于呈现阳性。 第四天嗓子基本恢复，开始出现轻微的感冒症状，咳嗽加剧。 后面随着休息咳嗽渐渐减轻，一周之后感觉到嗅觉和味觉的消失。 整体来说我没有出现发烧、肌肉酸痛等严重影响正常活动的症状，除了一点布洛芬和感冒冲剂也并未吃其他的药，只是精神确实不如平时，需要更多的睡眠了。\n在家窝了太久，今天早上便打算出去走走。正好想起来以前看过一本冥想的入门书，上面介绍过如何在走路时冥想。今年以来还没有好好地练习过，于是便有了这病后的第一次步行冥想体验。\n因为最近脑子里的事情很多，想一下进入清明的状态并不容易，所以我设置了十分钟倒计时，打算先只做一次简单的恢复性训练。\n散步和静坐还是很不一样的，鸟叫、人声、车来车往，极其容易分心。我努力让自己融入到环境中，体会身边的一切。眼前的道路、树木、楼房以及行人，形状颜色各不相同；耳边的风声、人语、发动机轰鸣，交杂在一起却又可以分辨；手指露在外面，一阵微寒传导至脖颈，有汗毛竖立的感觉。只是因为嗅、味觉的钝化，世界缺少了重要的一环，不禁有点沮丧。\n事实上，这些体察全都发生在电光火石之间，我微微调整思绪，开始沿路绕行，尽量让自己的脚步慢一点，稳一些。眼前的画面晃动起来，脑中的想法也随之起舞。我习惯通过专注呼吸的节奏代替平时的浮想联翩，从而进入归寂的状态。而这次明显很难做到，即使默念着一吸、一呼，各种各样的回忆、计划、想象迅速弥漫，神游不知多久，突然意识到自己的失控，于是再次回归呼吸，进入下一次的尝试。这大概有些像扫地，每下都可以荡开一些尘土，但无论多么用力也无法一次完成。\n到了后半段，我渐渐能够持续较久的专注了，也感觉到了一阵轻松。也许是注意力集中，甚至没有怎么咳嗽。最后，开始觉得时间过于漫长，正要看看十分钟有没有到，却又想到，时间可以只是物质的一种体现，如果所有的粒子保持原位，那么世界便静止了。正琢磨着，手环响起，时间终于到了，原来短短几分钟也可以如此之久。掩藏的思绪又开始泛起，我也不打算强求，便结束了这次冥想。\n抬头看了看天，阳光从灰蒙蒙的雾霾中挣扎出来，心中浮起思念，真希望时间过得快一点，再快一点。","title":"感染，以及恢复后的第一次冥想"},{"content":"It\u0026rsquo;s been a while since last post, yet I haven\u0026rsquo;t been idle. As the title tells, this is a record for that first experience. Since DMCA is a US law, here I chose to write in English.\nI\u0026rsquo;m aware many have read my blog for just one reason: \u0026ldquo;Amazon OA 2022\u0026rdquo;. I shared quite a bit of information in that post which I consider would be useful for preparing the Amazon online assessment, and there have been some positive feedbacks. Sadly this will no longer be the case.\nI published that on 2022.8.11, and removed it permanently on 2022.11.25, which was yesterday.\nThe reason is an official complaint from Amazon via GitHub where I host this little site. I was a bit surprised though since there are tutorials about Amazon interviews all over the Internet, however, this notice probably implied the one I wrote has been helpful. Anyway, long story short, I complied with the instructions from GitHub and got my blog back online, which all happened in a week.\nWell, what I\u0026rsquo;ve firmly believed is we can always learn from things. So here I\u0026rsquo;d like to talk a bit about this DMCA issue.\nThe Digital Millennium Copyright Act (DMCA) is a 1998 United States copyright law that implements two 1996 treaties of the World Intellectual Property Organization (WIPO). It criminalizes production and dissemination of technology, devices, or services intended to circumvent measures that control access to copyrighted works (commonly known as digital rights management or DRM). It also criminalizes the act of circumventing an access control, whether or not there is actual infringement of copyright itself. In addition, the DMCA heightens the penalties for copyright infringement on the Internet.\nWikipedia taught me the above while this page on GitHub seems more relevant and practical: DMCA Takedown Policy. Essentially they think my post was an infringement of their copyrighted content, in terms of some interview questions. So they issued a notice against me, which is transparent to public and can be viewed here. So my next step could be either of:\nMake changes or remove the content. Argue with a counter notice. It was an easy decision for me, but instead of notifying me with 1-day time window, GitHub took my site down directly. Then I had to argue to make them give me extra time before the whole thing sorted out.\nSo if you encounter something like this, there\u0026rsquo;s no need to panic, all you need to do is contact them and make the changes. See here for counter notices if you like to fight back.\nAdditionally, I wanna mention about removing contents from a Git repository. GitHub has a comprehensive guide, where they introduced a tool called git filter-repo. My understanding of it\u0026rsquo;s a better substitute for git filter-branch, which is not recommended anymore due to some safety issues. So essentially what it does is to rewrite the whole history by eliminating related files as well as the after empty commits, and updating all the commit hashes.\nI didn\u0026rsquo;t use it for all I needed was to ditch two simple commits and force push. Nonetheless, this filter-repo would really come in handy if you\u0026rsquo;re facing a collaborative repository with a messy history and tons of commits.\nAnyhow, copyright is vital for all of us, whether on Internet or not. I respect it and I hope this small article could be of assistance to anyone, or simply an eye-opener. :)\n","permalink":"https://iamgodot.com/posts/my-first-dmca-takedown-notice/","summary":"It\u0026rsquo;s been a while since last post, yet I haven\u0026rsquo;t been idle. As the title tells, this is a record for that first experience. Since DMCA is a US law, here I chose to write in English.\nI\u0026rsquo;m aware many have read my blog for just one reason: \u0026ldquo;Amazon OA 2022\u0026rdquo;. I shared quite a bit of information in that post which I consider would be useful for preparing the Amazon online assessment, and there have been some positive feedbacks.","title":"My First DMCA Takedown"},{"content":"粗略估计，使用 Obsidian 也有两年了。最近试了下 Logseq，感觉很不错，说说自己的想法。\n回顾过去，我是在工作后才开始注重记录的，也尝试过不少工具：有道云笔记，印象笔记，一个比较小众的软件 Leanote，甚至是实体笔记本。\n过了一两年，被同事安利了 Notion（那时候小 No 还处于艰难的求生阶段），简单了解之后我觉得非常好，便开始全面使用。\n到 2020 年，Roam Research 火了起来，同时炒热的还有双链、图谱等概念。建立一个高效的第二大脑相当吸引人，于是我对个人笔记的热情被再次点燃了。由于 RR 过于昂贵，我投向了 Obsidian 的怀抱，直到现在。\nBefore Obsidian 于我而言，Notion 之前的笔记软件基本可以归为一类，以印象笔记为代表。这类软件一般基于层级目录的结构，以分类和标签的方式聚合笔记，并配合以关键字为主的查询方式（印象笔记甚至支持搜索图片中的文字）。有段时间我一度沉迷于印象笔记推出的各类折扣。\nNotion 的创新应该算是具有划时代的意义了，比如 Page 和 Block 的概念也在 Logseq 中沿用。在我的印象里，除了偶尔的网络问题，Notion 是很完美的，甚至因为功能过于复杂和强大，让我后来有些望而却步了。\nWith Obsidian 除了 Zettelkasten，本地存储是我切换到 Obsidian 的另外一个重要原因。Notion 对网络的依赖让我认识到本地数据的重要性，再加上云端同步，Markdown + Local files + Dropbox 成为了我的笔记标配。\n可惜的是，虽然 Obsidian 非常先进、好用，但它本质上也只是个工具，错误的使用让我又走上了从入门到放弃的老路。\n仔细想想，其实我一直把它当成一个加强型的 Markdown 编辑器来用。对于那些核心的 Feature，比如 Backlink，我都是默认关闭（可能是因为显示在右侧，觉得比较占地方吧），几乎没有看过；再比如 Graph view，虽然笔记积累了不少，但也没有从中产生过什么有用的联想；在多数时候，我只是输入关键词做全局查询，连标签都很少用到。\n时间一长，我又失去了做笔记的热情。\nWith Logseq 初看 Logseq 让我觉得很有 Notion + Org-mode 的感觉（曾经试图研究过后者，最后算是弃坑了吧，不过无论 Org-mode 还是 Emacs 都非常了不起），但抛开工具本身，它的设计理念解答了我很久以来的困扰。\n这里推荐 Randy 的 我是如何使用 Logseq 的 这个视频，把核心理念解释得很清楚。\n为什么使用 Logseq 能够帮助我做笔记呢？因为我最大的问题在于无法坚持记录，而这又是因为每次想写些什么之前，都需要先想好要写到哪篇笔记里，如果没有的话还要再想新建一篇笔记叫什么好、放到哪个目录下面合适、如何分类标签等等，等这些都想清楚了，最开始要写的内容可能已经忘记了。另外，这可能让我们在潜意识里觉得记录这件事很困难，写之前就要想很多东西，久而久之就不愿意动笔了。Logseq 解决这个问题的思路是日志，也就是打开软件之后默认展示当天的日记作为入口，不需要多做任何思考，直接开写。\n这一点对我的启发最大，其他的功能可以说与 Obsidian 各有千秋吧，像 Graph view 我认为后者做得要成熟很多。不过整体使用下来 Logseq 还是带给我很多惊喜的：\n查询：通过 Query 命令把散落在日志中的只言片语整合到一起（当然这些只言片语中是要有关键字信息的）。 任务管理：同样可以通过 Query 把清单项整合到一起，功能上和 Org-mode 很像了，当然也很好用。 PDF 文档阅读：内嵌了阅读器，可以很方便地上传、阅读以及标注 PDF 文件。这个功能很赞，因为它集成了一个非常常用又和笔记密切相关的场景。 记忆卡片：类似 Anki 的 Flashcards 工具，同样又是一个和笔记关系非常紧密的使用场景。 反向链接：我觉得比 Obsidian 强的地方在于它把链接放到了下方，这样不容易被忽视。 网络代理：可以直接在设置里面添加配置，很方便。Obsidian 没有，但也不难解决。 最后要说下 Vim mode。Obsidian 提供了这个功能，用起来也很方便，但我现在的认识是 Vim mode 对于 Markdown 来说并不必要，甚至有副作用。像 Logseq 的编辑器本身就有一定的辅助功能，比如缩进（的批量操作），改用 Vim 反而复杂。另外，与在代码中需要做频繁的跳转和移动不同，记录时更多地是在当前光标下添加内容，所以效率上并不会有太大的提升，说不定还可能起到喧宾夺主的反效果。总之，重点在于记录，而不是快捷键。\n写到最后，不禁产生了一个想法。关于笔记软件的进化，除了技术迭代，应该也少不了社会进步的影响。以前信息获取相对困难，给笔记分门别类的负担并不大，人们更多地注重积累和收藏；现在是个信息爆炸的时代，哪怕不主动学习，工作、生活上的事情也越来越多，所以我们渴望极简，追求工具带来的极限效率，以此最小化心智负担。变聪明了，因此也更累了？也许是吧。\n","permalink":"https://iamgodot.com/posts/why-i-use-logseq/","summary":"粗略估计，使用 Obsidian 也有两年了。最近试了下 Logseq，感觉很不错，说说自己的想法。\n回顾过去，我是在工作后才开始注重记录的，也尝试过不少工具：有道云笔记，印象笔记，一个比较小众的软件 Leanote，甚至是实体笔记本。\n过了一两年，被同事安利了 Notion（那时候小 No 还处于艰难的求生阶段），简单了解之后我觉得非常好，便开始全面使用。\n到 2020 年，Roam Research 火了起来，同时炒热的还有双链、图谱等概念。建立一个高效的第二大脑相当吸引人，于是我对个人笔记的热情被再次点燃了。由于 RR 过于昂贵，我投向了 Obsidian 的怀抱，直到现在。\nBefore Obsidian 于我而言，Notion 之前的笔记软件基本可以归为一类，以印象笔记为代表。这类软件一般基于层级目录的结构，以分类和标签的方式聚合笔记，并配合以关键字为主的查询方式（印象笔记甚至支持搜索图片中的文字）。有段时间我一度沉迷于印象笔记推出的各类折扣。\nNotion 的创新应该算是具有划时代的意义了，比如 Page 和 Block 的概念也在 Logseq 中沿用。在我的印象里，除了偶尔的网络问题，Notion 是很完美的，甚至因为功能过于复杂和强大，让我后来有些望而却步了。\nWith Obsidian 除了 Zettelkasten，本地存储是我切换到 Obsidian 的另外一个重要原因。Notion 对网络的依赖让我认识到本地数据的重要性，再加上云端同步，Markdown + Local files + Dropbox 成为了我的笔记标配。\n可惜的是，虽然 Obsidian 非常先进、好用，但它本质上也只是个工具，错误的使用让我又走上了从入门到放弃的老路。\n仔细想想，其实我一直把它当成一个加强型的 Markdown 编辑器来用。对于那些核心的 Feature，比如 Backlink，我都是默认关闭（可能是因为显示在右侧，觉得比较占地方吧），几乎没有看过；再比如 Graph view，虽然笔记积累了不少，但也没有从中产生过什么有用的联想；在多数时候，我只是输入关键词做全局查询，连标签都很少用到。\n时间一长，我又失去了做笔记的热情。\nWith Logseq 初看 Logseq 让我觉得很有 Notion + Org-mode 的感觉（曾经试图研究过后者，最后算是弃坑了吧，不过无论 Org-mode 还是 Emacs 都非常了不起），但抛开工具本身，它的设计理念解答了我很久以来的困扰。\n这里推荐 Randy 的 我是如何使用 Logseq 的 这个视频，把核心理念解释得很清楚。","title":"我为什么开始用 Logseq"},{"content":"在 Python 中，EAFP 的风格很受青睐，这种写法能让代码更加简洁，还可以避免一些重复判断和多线程竞争的问题。为此，了解并熟练使用异常是很重要的。\n异常类 首先来看一下 Python 内置的异常类（有省略）：\nBaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StopAsyncIteration +-- ArithmeticError +-- AssertionError +-- AttributeError +-- BufferError +-- EOFError +-- ImportError +-- LookupError +-- MemoryError +-- NameError +-- OSError +-- ReferenceError +-- RuntimeError +-- SyntaxError +-- SystemError +-- TypeError +-- ValueError +-- Warning BaseException 是所有异常的老祖宗，但很少会用到，通常我们只需要 Exception，比如自定义一个错误类型：\n# 命名习惯一般以 Error 结尾 class CustomError(Exception): def __init__(self, message, status): # 这里最好把参数都放进去，之后会统一存在 e.args 中 super().__init__(message, status) self.message = message self.status = status 除此之外，有两种与 Exception 平级的异常需要我们注意，就是 SystemExit 和 KeyboardInterrupt。\nSystemExit 可以通过 sys.exit() 来触发，会让程序以特定的 Exit code 退出；而 KeyboardInterrupt 一般由 Ctrl-C 导致，正常情况下也会让 Interpreter 结束工作。\n这两种异常都会直接影响程序的执行退出，继承自 BaseException 可能也是为了和 Exception 做区分。比如 KeyboardInterrupt，因为过于不可控（任意发出的打断操作），即使通过异常处理可能也无法正常完成资源回收等操作，所以用注册 Signal handler 的方式来实现 Graceful shutdown 更加合适。\n另外，要避免用单独的 except 语句，因为默认针对的是 BaseException，会把上面两种异常都包含进去。\n抛出异常 抛出异常是很简单的，基本上只需要记住 raise 关键字，后面加上异常对象就好了。\n这里有个知识点是 raise 的时候也可以直接使用异常类型：\nIf it is a class, the exception instance will be obtained when needed by instantiating the class with no arguments.\n当然，初始化异常对象并且加入一些上下文信息会更有利于 Debug。\n在异常处理中，如果想重新抛出异常，只需要这样做：\ndef test_exception_chaining(): try: 1 / 0 except ZeroDivisionError as e: print(\u0026#39;Trying to divide 1 by 0\u0026#39;) raise e # 或者直接 raise 即可 最后要提的是 Exception chaining，可以理解为一个异常打印消息的优化，在文本中会显示更加清晰的异常链关系：\ndef test_exception_chaining(): try: 1 / 0 except ZeroDivisionError as e: raise ValueError from e 此时执行函数打印的错误栈会显示：\nTraceback (most recent call last): File \u0026#34;/tmp/test.py\u0026#34;, line 3, in test_exception_chaining 1 / 0 ZeroDivisionError: division by zero The above exception was the direct cause of the following exception: Traceback (most recent call last): File \u0026#34;/tmp/test.py\u0026#34;, line 37, in \u0026lt;module\u0026gt; foo() File \u0026#34;/tmp/test.py\u0026#34;, line 5, in test_exception_chaining raise ValueError from e ValueError 可以看到，消息中指明了 ZeroDivisionError 是导致 ValueError 的直接原因。\n在这种情况下，ValueError 的 __cause__ 属性会被设置为前面的 ZeroDivisionError 对象，而 __suppress_context__ 为 True。\n而如果我们不加 raise ValueError 后面的 from e，则 __supress_context__ 为 False，另一个属性 __context__ 会被设置为 ZeroDivisionError 对象。这是出现连环异常的默认处理，此时错误栈会显示：\nDuring handling of the above exception, another exception occurred:\n看上去就没有 Exception chaining 那么直观了。\n异常处理 Python 异常处理语句的完全体如下：\ndef test_var(var): try: assert isinstance(var, str) except AssertionError: print(f\u0026#39;{var} is not a string\u0026#39;) finally: print(\u0026#39;End test\u0026#39;) else: print(f\u0026#39;{var} is a string\u0026#39;) 只有存在至少一个 except，才可以使用 else 语句。如果不出现任何异常情况，在 try 中的代码执行完成之后，会继续执行 else。\n而 finally 很好理解，简单来说就是一定会执行：\nthe finally clause is executed in any event.\n具体可以分为下面几种情况：\n出现 Unhandle 的异常。 不论是 except 没有覆盖还是异常处理过程中又出现了新的异常，都会先完成 finally 的逻辑再抛出。 但是如果 finally 中直接 return/break/continue 了，则异常会被忽略掉。 未出现异常或者异常被成功 Handle。 不论是 try 还是 except 中的 return/break/continue，执行之前还是要先处理 finally 的逻辑。 同样，如果 finally 中直接退出了，那么也不会再继续之前的 try 或者 except。 总结一下就是 finally 最后一定会执行，而且优先级更高。\n虽然这套四连很好用，但是代码中写多了比较麻烦，也影响可读性。所幸还有一种更简洁的语法，就是 with。\n使用 with 在上下文管理器协议中，从 __exit__ 方法的参数中可以得到 with 块中执行语句可能抛出的 Exception，所以这里很适合做异常处理。\nclass ExceptionManager: def __init__(self, exception, handler): self.exception = exception self.handler = handler def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type == self.exception: self.handler(exc_val) return True return False 这里要注意 __exit__ 的返回值，如果布尔结果为 True，则异常不会继续抛出。\n利用内置的 contextlib 还可以这样实现：\nfrom contextlib import contextmanager @contextmanager def manage_exception(exception, handler): try: yield except exception as e: handler(e) 如果想忽略一些特定的异常：\nfrom contextlib import suppress with suppress(KeyError): d = {} print(d[\u0026#39;foo\u0026#39;]) 一些结论 在使用异常机制时，可以参考下面几点：\n提前考虑可能发生的异常，比如非法输入、网络或 I/O 错误等。 对于不合理的情况应当直接抛出异常，交给上层处理。 如果是底层函数，那么可以直接使用内置异常类型。 或者自定义内部异常，但是要注意和模块的层级匹配。 异常处理。 重试。推荐 Tenacity 这个库。 记录日志，还可以配合 Sentry 发出告警。 资源回收与回滚操作。比如关闭打开的文件、回滚数据库等。 返回值。 直接抛出异常。 使用默认值，如 False 或 -1。 根据异常返回对应的 HTTP Response，这在服务器应用中很常见。 兜底。总会发生意想不到的错误，为了保险起见最好多加一层处理。 离线任务：做好适当的回滚，不要 Block 其他任务，修复之后再手动触发。 在线应用：做好记录并返回错误响应，最重要的是不打断程序的正常运行。 References\nErrors and Exceptions - Python Docs Built-in Exceptions - Python Docs LBYL vs EAFP - RealPython Python 工匠： 异常处理的三个好习惯 ","permalink":"https://iamgodot.com/posts/exception-in-python/","summary":"在 Python 中，EAFP 的风格很受青睐，这种写法能让代码更加简洁，还可以避免一些重复判断和多线程竞争的问题。为此，了解并熟练使用异常是很重要的。\n异常类 首先来看一下 Python 内置的异常类（有省略）：\nBaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StopAsyncIteration +-- ArithmeticError +-- AssertionError +-- AttributeError +-- BufferError +-- EOFError +-- ImportError +-- LookupError +-- MemoryError +-- NameError +-- OSError +-- ReferenceError +-- RuntimeError +-- SyntaxError +-- SystemError +-- TypeError +-- ValueError +-- Warning BaseException 是所有异常的老祖宗，但很少会用到，通常我们只需要 Exception，比如自定义一个错误类型：\n# 命名习惯一般以 Error 结尾 class CustomError(Exception): def __init__(self, message, status): # 这里最好把参数都放进去，之后会统一存在 e.","title":"Python 中的异常"},{"content":"浅析一下 Python 中的 Import 机制。代码版本：3.11.0 - 4dd8219。\nModule \u0026amp; Package Import 的对象就是各种各样的模块，即 Module。如何定义呢？官方文档这样描述：\nA module is a file containing Python definitions and statements.\n实际上，Module 可以是 Builtin，也可以是 C extension，但最常见的存在形式还是 *.py 文件。\n一个 Module 同时也可能是 Package，此时它从文件升级为目录，就可以拥有 Submodule 了。Package 分为两种：\nRegular package：这类 Package 必须包含一个 __init__.py 文件，代表了这个 Module(Package) 本身。 Namespace package：如果不存在 __init__.py，Python 会将其创建为此类 Package。Namespace package 的特殊之处在于同名的 Package 可以出现在多个目录下，而 Import 完成之后又可以统一使用。 不管是哪一种 Package，都会有 __path__ 属性，指向目录的路径。属性值是个列表，这对于 Namespace package 尤为重要。除此之外，一个 Module 还有：\n__name__：模块名称。 __file__：文件位置。 __package__：主要是为了在 Relative import 时计算起点位置。 如果是 Package 则设置为 __name__。 如果非 Package 则设置为 Parent package 的名称（Top-level 的 Module 应为空字符串）。 如果以脚本执行，那么取值为 None。 How to Import 一般情况下 Import 都是通过 import 关键字完成的，可分为两大类：\nAbsolute import：from foo import bar as bat 其中 bar 可以是 Function，Class 或者 Submodule。 如果 import module.submodule，则实际 Import 的是整个 module。 Wildcard import：from module import * 如果 module 中定义了 __all__，则只会 Import 其指定的部分。 如果没有 __all__，那么非 _ 开头的属性都会被 Import。 Relative import：from ..foo import bar 这种方式会以当前 Module 为起点定位 foo，一般会出现两种错误： 相对位置超出了 Top-level package：ImportError: attempted relative import beyond top-level package 以脚本的方式运行：ImportError: attempted relative import with no known parent package 以模块的方式运行文件：python -m package.module 此时 module 的 __name__ 仍然是 __main__，和脚本方式一样。 而 __package__ 则不会是 None，而是 package。 此外，Python 还提供了 importlib，这样就可以在代码中动态 Import。实际上，__import__（也就是 import 关键字） 和 importlib.import_module 都是基于同一套 Codebase 实现的。\nHow Import Works 先来看两个接口的实现：\ndef __import__(name, globals=None, locals=None, fromlist=(), level=0): if level == 0: module = _gcd_import(name) else: globals_ = globals if globals is not None else {} package = _calc___package__(globals_) module = _gcd_import(name, package, level) if not fromlist: if level == 0: return _gcd_import(name.partition(\u0026#39;.\u0026#39;)[0]) elif not name: return module else: cut_off = len(name) - len(name.partition(\u0026#39;.\u0026#39;)[0]) return sys.modules[module.__name__[:len(module.__name__)-cut_off]] elif hasattr(module, \u0026#39;__path__\u0026#39;): return _handle_fromlist(module, fromlist, _gcd_import) else: return module def import_module(name, package=None): level = 0 if name.startswith(\u0026#39;.\u0026#39;): if not package: msg = (\u0026#34;the \u0026#39;package\u0026#39; argument is required to perform a relative \u0026#34; \u0026#34;import for {!r}\u0026#34;) raise TypeError(msg.format(name)) for character in name: if character != \u0026#39;.\u0026#39;: break level += 1 return _bootstrap._gcd_import(name[level:], package, level) 可以发现，两者在实际 Import 时调用的都是 _gcd_import 这个方法。gcd 的意思是 greatest common denominator，表示其作为两个接口的主要功能的公共函数。\n相对来说，__import__ 要更灵活一点，因为还提供了 fromlist 参数，可以指定要 Import 的具体属性，在代码中会对其做进一步的解析和校验。\n下面从 _gcd_import 出发，梳理一下 Import 的具体流程：\n一开始的 Sanity check 和 Name resolving 主要是针对 Relative import 的情况，比较容易理解。接下来会在 sys.modules 中检查 Module 是否已经存在，避免重复开销。如果 Parent module 尚不存在，则以递归的方式先对其做 Import，再继续执行当前流程。\n正式的 Import 主要包括 Find 和 Load 两大步骤。在大多数情况下，都是先定位到对应的 *.py 文件，读取到内存，最后生成一个 Module 对象并返回。\n看上去很简单，但有几个问题要考虑：\n在多线程情况下共享 sys.modules 这个字典结构，必须保证操作的原子性，还要考虑到 Deadlock。 模块文件可能分散在系统的多个目录下，因此必须要实现一个有效的管理和搜索策略。 Import 作为底层功能，还牵涉到很多 I/O 操作，所以在速度上要尽可能地优化。 先看多线程的处理。这里引入了 Global import lock 和 Module lock 两种锁。\n# A dict mapping module names to weakrefs of _ModuleLock instances # Dictionary protected by the global import lock _module_locks = {} class _ModuleLockManager: def __init__(self, name): self._name = name self._lock = None def __enter__(self): self._lock = _get_module_lock(self._name) self._lock.acquire() def __exit__(self, *args, **kwargs): self._lock.release() def _get_module_lock(name): # 获取 Global lock _imp.acquire_lock() try: try: # 尝试获取 Module lock # 所有的 Module lock 都在一个字典中维护 lock = _module_locks[name]() except KeyError: lock = None if lock is None: if _thread is None: lock = _DummyModuleLock(name) else: lock = _ModuleLock(name) # 这里通过 weakref 的 callback 避免内存泄漏 def cb(ref, name=name): _imp.acquire_lock() try: if _module_locks.get(name) is ref: del _module_locks[name] finally: _imp.release_lock() _module_locks[name] = _weakref.ref(lock, cb) finally: _imp.release_lock() return lock class _ModuleLock: def __init__(self, name): self.lock = _thread.allocate_lock() self.wakeup = _thread.allocate_lock() self.name = name self.owner = None self.count = 0 self.waiters = 0 def has_deadlock(self): # Deadlock avoidance for concurrent circular imports. me = _thread.get_ident() tid = self.owner seen = set() while True: lock = _blocking_on.get(tid) if lock is None: return False tid = lock.owner # 如果我等待的锁的 owner 在等待我手上的锁，说明出现 Deadlock if tid == me: return True if tid in seen: return False seen.add(tid) def acquire(self): ... def release(self): ... 下面来看 Module lock 的使用：\n_NEEDS_LOADING = object() # 作为 Sentinel object def _find_and_load(name, import_): module = sys.modules.get(name, _NEEDS_LOADING) if (module is _NEEDS_LOADING or getattr(getattr(module, \u0026#34;__spec__\u0026#34;, None), \u0026#34;_initializing\u0026#34;, False)): # 这里先获取 Global lock 和 Module lock with _ModuleLockManager(name): module = sys.modules.get(name, _NEEDS_LOADING) if module is _NEEDS_LOADING: # 开始真正的 Import return _find_and_load_unlocked(name, import_) # 如果 _initializing 为 True，说明有其他 Thread 正在 Import _lock_unlock_module(name) if module is None: message = (\u0026#39;import of {} halted; \u0026#39; \u0026#39;None in sys.modules\u0026#39;.format(name)) raise ModuleNotFoundError(message, name=name) return module ... def _lock_unlock_module(name): # 两个主要作用 # 一是通过 lock 的 acquire\u0026amp;release 来保证 Initializing 的完成 lock = _get_module_lock(name) try: lock.acquire() # 二是捕捉并忽略 Deadlock 异常 except _DeadlockError: pass else: lock.release() 获取 Module lock 之后，下一步要找到 Spec，它决定了 Module 的类别与一些相关属性，以及后面加载要使用的 Loader。为了查找 Spec，解释器会分别尝试下面三种 Importer 的 find_spec 方法，这些 Importer 是在 sys.meta_path 中定义的：\nBuiltinImporter FrozenImporter PathFinder 前两者针对的是预编译好的模块，最常用的其实是 PathFinder，因为 Python 自带的函数库和第三方库都要通过它找到模块文件再进行加载。这些文件分散在系统的多个路径下，为了方便管理，sys.path 中定义了一个目录列表，里面每个条目都代表一个特定的搜索路径。对于每个条目，PathFinder 会调用对应的 PathEntryFinder(其实是 FileFinder) 进行查找。\n因为目录可能很多，所以这里又引入了缓存优化（前面的 sys.modules 也是一层缓存）：先在 sys.path_importer_cache 中寻找 PathEntryFinder，如果没有，再调用 sys.path_hooks 中的钩子函数做初始化创建并更新到 cache 中。\n针对 Namespace package 的处理也在这部分：\nclass PathFinder: ... @classmethod def _get_spec(cls, fullname, path, target=None): namespace_path = [] # 遍历 sys.path 中的每个条目 for entry in path: if not isinstance(entry, (str, bytes)): continue # 优先从 sys.path_importer_cache 中查找 # 如果没有则通过 sys.path_hooks 生成 finder = cls._path_importer_cache(entry) if finder is not None: if hasattr(finder, \u0026#39;find_spec\u0026#39;): spec = finder.find_spec(fullname, target) else: spec = cls._legacy_get_spec(fullname, finder) if spec is None: continue if spec.loader is not None: return spec portions = spec.submodule_search_locations if portions is None: raise ImportError(\u0026#39;spec missing loader\u0026#39;) # 记录所有可能作为 Namespace package 的 path 目录 namespace_path.extend(portions) else: spec = _bootstrap.ModuleSpec(fullname, None) spec.submodule_search_locations = namespace_path return spec @classmethod def find_spec(cls, fullname, path=None, target=None): if path is None: path = sys.path spec = cls._get_spec(fullname, path, target) if spec is None: return None elif spec.loader is None: namespace_path = spec.submodule_search_locations if namespace_path: # 这里会创建针对 Namespace package 的 Spec spec.origin = None spec.submodule_search_locations = _NamespacePath(fullname, namespace_path, cls._get_spec) return spec else: return None else: return spec 找到 Spec 以后，也就确定了要使用的 Loader。一般来说，Load 就是执行 *.py 文件的内容，将里面的属性绑定到 Module object 上面。最后再返回这个 Object 便完成了 Import。\nPartially Circular Import 对于下面这种情况：\n# foo.py import bar # bar.py import foo 看起来会出现错误，其实是可以执行成功的。原因在于 Import 做了特殊处理，来看代码：\ndef _load_unlocked(spec): # 这里的 initializing 对应了前面的 _lock_unlock_module spec._initializing = True try: # 现在已经得到了 Spec，准备进行 Load # 但是在实际的 exec_module 之前会先将 Module object 放进 sys.modules # 这样在 Circular import 时缓存中就可以找到这个 Module object # 但是这个 Object 尚未完成加载，所以是 Partial 的 sys.modules[spec.name] = module try: if spec.loader is None: if spec.submodule_search_locations is None: raise ImportError(\u0026#39;missing loader\u0026#39;, name=spec.name) else: spec.loader.exec_module(module) except: try: del sys.modules[spec.name] except KeyError: pass raise module = sys.modules.pop(spec.name) sys.modules[spec.name] = module _verbose_message(\u0026#39;import {!r} # {!r}\u0026#39;, spec.name, spec.loader) finally: spec._initializing = False return module 当然，如果使用不当也是会引发异常的。\n# foo.py from foo import a a = 11 # 这种情况下 Import foo 会导致 ImportError # ImportError: cannot import name \u0026#39;a\u0026#39; from partially initialized module \u0026#39;foo\u0026#39; (most likely due to a circular import) # foo.py import bar # bar.py import foo print(foo.a) # 这种情况下 Import foo 会导致 AttributeError # AttributeError: partially initialized module \u0026#39;foo\u0026#39; has no attribute \u0026#39;a\u0026#39; (most likely due to a circular import) 原因就是尝试在 foo 模块仅仅 Partially imported 的情况下获取尚不存在的属性。\nReload 除了 import_module，importlib 还提供了一个 reload 接口，可以用来重新加载之前 Import 过的模块。\nreload 会刷新 sys.modules 中的 Module object，这没有问题。但是，对于 from foo import bar 这样的 Import 方式，bar 是不会单独更新的。\n# foo.py def bar(): print(\u0026#39;bar\u0026#39;) # 如果 import foo，然后这样使用 foo.bar()。Reload 是 OK 的。 # 如果再加上 from foo import bar，那么即使改变 bar 的代码再 reload(foo)，bar() 还是会保持原有的效果，即打印 `bar` 字符串。 从源码来理解，这是因为以上涉及到的 Import 实现都只针对 Module object 的创建和更新。从字节码可以看到：\n➜ echo \u0026#39;from os import path\u0026#39; | python -m dis 1 0 LOAD_CONST 0 (0) 2 LOAD_CONST 1 ((\u0026#39;path\u0026#39;,)) 4 IMPORT_NAME 0 (os) 6 IMPORT_FROM 1 (path) 8 STORE_NAME 1 (path) 10 POP_TOP 12 LOAD_CONST 2 (None) 14 RETURN_VALUE path 的 Name binding 是通过 STORE_NAME 指令完成的，而 Import 的代码只负责 IMPORT_NAME 和 IMPORT_FROM，所以 reload 才会有 Module level 的限制。\n相比之下，IPython 的 autoreload 扩展则实用许多。不仅实现了自动重载，对模块中的 Function 和 Class 等也都同样有效。用法很简单，参考官方文档。\nReferences\nHow the Python import system works\nModule attributes - Python Docs\nReload - python3 Cookbook\n","permalink":"https://iamgodot.com/posts/source-code-of-python-import/","summary":"浅析一下 Python 中的 Import 机制。代码版本：3.11.0 - 4dd8219。\nModule \u0026amp; Package Import 的对象就是各种各样的模块，即 Module。如何定义呢？官方文档这样描述：\nA module is a file containing Python definitions and statements.\n实际上，Module 可以是 Builtin，也可以是 C extension，但最常见的存在形式还是 *.py 文件。\n一个 Module 同时也可能是 Package，此时它从文件升级为目录，就可以拥有 Submodule 了。Package 分为两种：\nRegular package：这类 Package 必须包含一个 __init__.py 文件，代表了这个 Module(Package) 本身。 Namespace package：如果不存在 __init__.py，Python 会将其创建为此类 Package。Namespace package 的特殊之处在于同名的 Package 可以出现在多个目录下，而 Import 完成之后又可以统一使用。 不管是哪一种 Package，都会有 __path__ 属性，指向目录的路径。属性值是个列表，这对于 Namespace package 尤为重要。除此之外，一个 Module 还有：\n__name__：模块名称。 __file__：文件位置。 __package__：主要是为了在 Relative import 时计算起点位置。 如果是 Package 则设置为 __name__。 如果非 Package 则设置为 Parent package 的名称（Top-level 的 Module 应为空字符串）。 如果以脚本执行，那么取值为 None。 How to Import 一般情况下 Import 都是通过 import 关键字完成的，可分为两大类：","title":"Python Import 源码阅读"},{"content":"来云南前只想好了去腾冲，并没有决定之后的行程，这样随性的旅行让我觉得自由。\n至于其他的城市，小时候跟着家里去过大理和丽江，所以并不打算重游故地。不过，在腾冲结识的一位大叔极力推荐洱海的美景，还热情地拿出照片证明，于是我改变主意，既然不想这么快回家，大理又离得不远，就把它作为下一站吧。\n落脚 大理的车站不比昆明，这本没什么，不太方便的是出来找不到厕所。一番折腾后，才在马路对面的巷子里找到了公厕。\n打个车来到了预订的住处，与其说酒店，更像是高层的公寓被改造成了统一装修的房间，不过环境尚可。\n住宿的位置在下关镇。后来才发现，这是个错误的决定，因为离景区太远了，更明智的选择是古城里面或周边的民宿。\n地理位置大致如下（图里的大理镇就是古城）：\n图片来自豆瓣 - 在大理旅居的日子\n简单收拾下，便去城里转了转。不得不说，这趟短行令人失望，街道两边满是小吃店，人声喧闹，让我觉得格格不入。浮躁、商业化是时隔近二十年后大理古城给我的初印象。\n洱海 第二天到了下午才出门，一个重要原因是防晒。\n之前在腾冲顶着大太阳走，一天下来发现小臂和鼻子都晒伤了，这才意识到云南紫外线的厉害。\n虽然擦防晒很管用，但需要配合卸妆油冲洗。在网上看到还有喷雾类的产品，不知道可不可以省去这种麻烦。\n前一天在京东下了单，上午便收到了，除了防晒，还买了个 U 盘。之所以买它是因为升级操作系统时不小心搞坏了 Grub，必须要 Live boot 修复。这也让我意识到作为 Linux 用户，随身携带 Live media 的重要性。\n下关的风很大（大理有苍山雪，洱海月，上关花，下关风的说法），到了洱海边便风平浪静了。进入生态廊道后，有很多自行车可以租骑，路程很长，所以骑行观赏是个不错的选择。\n这次的海边之行，让我真正领略到洱海之美，也动了留在大理的心思。\n爸爸和女儿的对话很有爱\n小哥的背影完美融合\n美丽的洱海\n云海笼罩的苍山\n一路向前，天色渐晚，我又来到了古城。肚子有些饿，正好看到一位慈祥的老奶奶在摆摊，便决定尝尝。视频里的烤乳扇是大理特色的奶酪制品，加热烤软后再裹上玫瑰酱，甜香又有嚼头。\n老人家一边做东西一边亲切地给我介绍大理的小吃，让我深深地感受到了当地人的热情。\n佛乐 第三天依然过得很慵懒，虽然知道有很多美景未去，但游玩并不是我的目标。就在这天，我得到了一些期望的慰藉。\n之前在豆瓣上联系了家月租的客栈，在古城内，所以下午又来到了这里。客栈的位置很好，紧挨着人民路，小间在一楼，价格便宜，800 一个月，包水电网。我对居住条件没有太高要求，所以觉得还不错，但因为无法就此留下，所以只是答应对方考虑一下。开店的是一对夫妇，大哥告诉我他们定居大理已经四年有余，给我讲了很多当地的风土人情，还说许多人来这里都是为了疗伤，有些选择离开，有些留了下来。最后聊到了饭辙，他们很少做饭，因为附近吃饭很方便，旁边有家本素拾堂，专做素食。我一听便来了兴致，正好晚饭没有着落。\n大哥带我来到餐店门口，打了两句招呼，便扭头回去了。我按着看店大姐说的，拿起饭盒打了饭菜，津津有味地吃了起来。\n虽然都是素菜，味道却不错。我看其中一道满是青椒，顺嘴问了句会不会很辣。有些出乎意料地，除了大姐，还有个在一旁吃饭的姑娘也加入回答我的问题，对话很是自然。这感觉很舒服，我便开了话匣子，问到店里播放的诵乐，说听得自己想哭。这好像触动了大姐，她提到很少人会有如此感觉，也许是我有缘，还建议我不妨尝试自然地让眼泪流出来。我深知自己是无法在旁人面前落泪的，连忙摆手婉拒。大姐很是理解，没再多说什么，我便自顾自地开始吃剩下的菜。\n而后在城内转了转，之前的感觉犹在，仿佛心里打开了一道缺口，有些积压许久的东西缓缓流淌出来，让我在悲伤之中又有些许畅快。\n大概是缘分牵引，我又回到了那个小店，打算问问住宿，其实是心里想再听听那诵经声。大姐见我回来，也没有过多诧异，我们便随意攀谈起来。说话之间又聊到了那首曲子，她说是佛乐，网上找不到，我也无意强求什么，只想再多听一会儿。大姐见状也不再打扰，为我泡了壶茶，径自收拾厨房去了。\n云滇红，味道清香\n这乐曲为女声吟唱，似乎只有一句，听来却不觉得枯燥。说实话，它让我感到久违的疲累，这反倒是件好事，因为我正苦于不知如何放下一些沉重的念头。不用装模作样，不用秉持信念，不用时刻准备战斗。如果能不那么执着，就像电影里说的，把手松开，是不是就可以拥有一切了。\n如此一夜过去。那些反覆的杂念，无法消散的呓语，挥之不去的思绪，好像都随着昨日的乐声离去了。或许只是暂时的沉淀，未来还会再度泛起，我不能确定，但心确实有一点放空，还变得有些轻松。\n最后一天要赶飞机，夜里难眠，莫名又想起了金刚经里写的：\n过去心不可得，现在心不可得，未来心不可得。\n好像更理解之前为什么不能放下了，总是在想，过去为何糟糕，未来会不会好。不管是否拥有，一旦想要把握，便会开始失去。心不可得，也就是心一直在变化，不会停留，就像时间一样。\n如同在心流中，如果能抛下执念，做任何事情都会变得轻松和满足，也感受不到时光的流逝了。\n是为合一的状态？我不知道，也许只需要，一件事一件事地去做就好了。\n因为暂时没有做好留在这里的准备，所以还是要离开的。不过我想，待到时机成熟，一定要再来大理居住些日子。到时候，想要认识些有意思的人，多看看苍山雪与洱海月，再次享受这份独一无二的自由。\n","permalink":"https://iamgodot.com/posts/visit-dali/","summary":"来云南前只想好了去腾冲，并没有决定之后的行程，这样随性的旅行让我觉得自由。\n至于其他的城市，小时候跟着家里去过大理和丽江，所以并不打算重游故地。不过，在腾冲结识的一位大叔极力推荐洱海的美景，还热情地拿出照片证明，于是我改变主意，既然不想这么快回家，大理又离得不远，就把它作为下一站吧。\n落脚 大理的车站不比昆明，这本没什么，不太方便的是出来找不到厕所。一番折腾后，才在马路对面的巷子里找到了公厕。\n打个车来到了预订的住处，与其说酒店，更像是高层的公寓被改造成了统一装修的房间，不过环境尚可。\n住宿的位置在下关镇。后来才发现，这是个错误的决定，因为离景区太远了，更明智的选择是古城里面或周边的民宿。\n地理位置大致如下（图里的大理镇就是古城）：\n图片来自豆瓣 - 在大理旅居的日子\n简单收拾下，便去城里转了转。不得不说，这趟短行令人失望，街道两边满是小吃店，人声喧闹，让我觉得格格不入。浮躁、商业化是时隔近二十年后大理古城给我的初印象。\n洱海 第二天到了下午才出门，一个重要原因是防晒。\n之前在腾冲顶着大太阳走，一天下来发现小臂和鼻子都晒伤了，这才意识到云南紫外线的厉害。\n虽然擦防晒很管用，但需要配合卸妆油冲洗。在网上看到还有喷雾类的产品，不知道可不可以省去这种麻烦。\n前一天在京东下了单，上午便收到了，除了防晒，还买了个 U 盘。之所以买它是因为升级操作系统时不小心搞坏了 Grub，必须要 Live boot 修复。这也让我意识到作为 Linux 用户，随身携带 Live media 的重要性。\n下关的风很大（大理有苍山雪，洱海月，上关花，下关风的说法），到了洱海边便风平浪静了。进入生态廊道后，有很多自行车可以租骑，路程很长，所以骑行观赏是个不错的选择。\n这次的海边之行，让我真正领略到洱海之美，也动了留在大理的心思。\n爸爸和女儿的对话很有爱\n小哥的背影完美融合\n美丽的洱海\n云海笼罩的苍山\n一路向前，天色渐晚，我又来到了古城。肚子有些饿，正好看到一位慈祥的老奶奶在摆摊，便决定尝尝。视频里的烤乳扇是大理特色的奶酪制品，加热烤软后再裹上玫瑰酱，甜香又有嚼头。\n老人家一边做东西一边亲切地给我介绍大理的小吃，让我深深地感受到了当地人的热情。\n佛乐 第三天依然过得很慵懒，虽然知道有很多美景未去，但游玩并不是我的目标。就在这天，我得到了一些期望的慰藉。\n之前在豆瓣上联系了家月租的客栈，在古城内，所以下午又来到了这里。客栈的位置很好，紧挨着人民路，小间在一楼，价格便宜，800 一个月，包水电网。我对居住条件没有太高要求，所以觉得还不错，但因为无法就此留下，所以只是答应对方考虑一下。开店的是一对夫妇，大哥告诉我他们定居大理已经四年有余，给我讲了很多当地的风土人情，还说许多人来这里都是为了疗伤，有些选择离开，有些留了下来。最后聊到了饭辙，他们很少做饭，因为附近吃饭很方便，旁边有家本素拾堂，专做素食。我一听便来了兴致，正好晚饭没有着落。\n大哥带我来到餐店门口，打了两句招呼，便扭头回去了。我按着看店大姐说的，拿起饭盒打了饭菜，津津有味地吃了起来。\n虽然都是素菜，味道却不错。我看其中一道满是青椒，顺嘴问了句会不会很辣。有些出乎意料地，除了大姐，还有个在一旁吃饭的姑娘也加入回答我的问题，对话很是自然。这感觉很舒服，我便开了话匣子，问到店里播放的诵乐，说听得自己想哭。这好像触动了大姐，她提到很少人会有如此感觉，也许是我有缘，还建议我不妨尝试自然地让眼泪流出来。我深知自己是无法在旁人面前落泪的，连忙摆手婉拒。大姐很是理解，没再多说什么，我便自顾自地开始吃剩下的菜。\n而后在城内转了转，之前的感觉犹在，仿佛心里打开了一道缺口，有些积压许久的东西缓缓流淌出来，让我在悲伤之中又有些许畅快。\n大概是缘分牵引，我又回到了那个小店，打算问问住宿，其实是心里想再听听那诵经声。大姐见我回来，也没有过多诧异，我们便随意攀谈起来。说话之间又聊到了那首曲子，她说是佛乐，网上找不到，我也无意强求什么，只想再多听一会儿。大姐见状也不再打扰，为我泡了壶茶，径自收拾厨房去了。\n云滇红，味道清香\n这乐曲为女声吟唱，似乎只有一句，听来却不觉得枯燥。说实话，它让我感到久违的疲累，这反倒是件好事，因为我正苦于不知如何放下一些沉重的念头。不用装模作样，不用秉持信念，不用时刻准备战斗。如果能不那么执着，就像电影里说的，把手松开，是不是就可以拥有一切了。\n如此一夜过去。那些反覆的杂念，无法消散的呓语，挥之不去的思绪，好像都随着昨日的乐声离去了。或许只是暂时的沉淀，未来还会再度泛起，我不能确定，但心确实有一点放空，还变得有些轻松。\n最后一天要赶飞机，夜里难眠，莫名又想起了金刚经里写的：\n过去心不可得，现在心不可得，未来心不可得。\n好像更理解之前为什么不能放下了，总是在想，过去为何糟糕，未来会不会好。不管是否拥有，一旦想要把握，便会开始失去。心不可得，也就是心一直在变化，不会停留，就像时间一样。\n如同在心流中，如果能抛下执念，做任何事情都会变得轻松和满足，也感受不到时光的流逝了。\n是为合一的状态？我不知道，也许只需要，一件事一件事地去做就好了。\n因为暂时没有做好留在这里的准备，所以还是要离开的。不过我想，待到时机成熟，一定要再来大理居住些日子。到时候，想要认识些有意思的人，多看看苍山雪与洱海月，再次享受这份独一无二的自由。","title":"游大理"},{"content":"来到腾冲，主要是想找个地方散心。\n之前有人告诉我：\n你可能有时候过于认为自己的精力是无限的。\n其实你身体很累，但你意识总是想支出更多的体力。\n于是我想，可能什么都不做就会好起来。后来才发现，原来让自己休息并没有那么容易。\n启程 苏州没有机场，所以要先乘高铁到上海，再坐地铁到浦东机场。这实在让我有些想念北京。\n腾冲，是云南的一个县级市，隶属保山市。原本附近有个驼峰机场，到了当地才听说由于疫情已经停用很久了，因此要先飞到昆明，再乘高铁到保山，最后坐大巴到腾冲市区。因为没考虑到后面的车程，所以不得不在昆明住了一晚。不过我本来就喜欢自由行，所以并不在意。第一顿吃了小锅米线，味道很棒：\n加帽儿（肉片），加臭豆腐（白色的，经过发酵），必须微辣\n第二天一大早出发前往和顺古镇。\n之前在网上订好了客栈，老板娘知道我从昆明过来，耐心地给我讲解路线，还让我到了市区联系司机来接。后来才知道，司机大叔和老板娘是夫妻，也都是和顺本地人，非常地热情好客。\n一番周折，终于到了。大叔介绍说，前两周是人最多的时候，现在赶上开学季，所以游客很少。落个清静，正合我意。\n我本来的房间在一楼，有些小，因为客人少，所以大叔直接给换到二楼的大间，幸福。\n房间的名字很美\n二楼做成了玻璃栈道的样子，阳光落下来的时候很美，但是走在上面实在有些刺激，生怕掉下来。\n初探 简单收拾下，也算松了口气。天色尚早，是时候出去逛逛了。\n碰到一只熟睡的小猫咪：\n狗狗也睡着了：\n走出小巷，外面风光无限。这边的天黑得很晚，八点之后才开始有傍晚的感觉。\n不知走了多久，有些饿了，来到一家烧烤店。小店其实是家住的院子改造的，氛围很好：\n店名叫小俩口，门外的夫妻俩负责烧烤，里面还有个老大爷坐镇。大爷一边招呼我一边热情地介绍当地的历史，眼神中充满了作为腾冲人的自豪与骄傲。\n腾冲作为丝绸之路上的名镇，不论在商贸还是战争中都是交通要道，加上接近边境，很多人闯荡南洋后致富归来后反哺故土，让这里成为了著名侨乡。历史悠久，文化积淀深厚，自然风光秀丽，真的是一片神奇的土地。\n吃的很快上来了，虽然我有所克制，但还是点多了：\n木瓜水，酸甜可口\n蘸料是当地特色的腌菜膏，酸辣鲜咸，有些接近东南亚的口味\n小牛肉串\n包浆豆腐，非常入味\n吃饱喝足，我趁着夜色又溜达了一会儿，便回去休息了。\n跷跷板 一天晚上散步时，望着漫漫夜色，听到蛙鸣四起，一阵无助的沮丧莫名涌了上来。\n我看空地上有些健身器材，便挑了个脚蹬的架子踩了上去，随意摆动。这时来了三个人，看着像是当地的村民，一个年轻姑娘左右手各挽着年长些的一男一女，有说有笑地也来到这里。姑娘站上了我旁边的架子，玩了起来，我心情正差，看了她一眼，没有说话。那一对男女用当地话对了几句，一边一个坐上了跷跷板，男的自然重些，所以压在下面。姑娘见状便加入其中，一起帮忙把男的翘起，三个人玩闹得兴起，如同孩子般开心。我在一旁看着，心里微微起了些变化，也许是被她们的情绪感染，瞬间觉得生命并不复杂，大人也可以尽情享受跷跷板的快乐。\n之后攀谈了起来，才知道她在小镇上的客栈打工，那对男女是老板夫妇。姑娘简单地介绍了下小镇的地形，又欢迎我来这里游玩，几个人便一起离开了。\n我回忆着刚才发生的一切，有种被微光照亮的感觉。我好像与她们完全不在一个世界，但又有什么不同呢？我自认为要追求比她们更好的人生答案，但标准真的存在吗？\n水黾 相比苏州接近四十度的高温，腾冲的天气很宜人，早晚甚至有些凉意。\n上午下起了小雨\n之后逛了逛当地的图书馆和博物馆，开始了解到另一条丝绸之路的伟大：\n之前的游河西走廊就是北方丝绸之路了\n马帮行走在商路上\n落脚的客栈在小镇的西边，所以我一路向东，这里尽是湖边的美景。\n当地的孩子直接下水游泳，看起来凉爽极了\n走得累了，我便望着湖水发呆。水中趴满了一种小虫（后来才知道叫做水黾），细长的肢体，浮在水面上四处游窜。一阵风逆着吹来，将它们送回原处，甚至倒退。看这些小生物拼命地向前冲，却只是做无用功，我感到有些虚无缥缈。难道它们没有意识到一切如此无力么？我开始找寻，有没有一只会放弃抵抗、随风而去呢？\n也许是数量太多，看不过来，直到最后我也没有找到想要的证明。但可能这本身也是一种证明吧，至少对这些水黾来说，生命不息，游动不止。\n艾思奇 如果对哲学有好奇或喜爱，艾思奇纪念馆是一定要看看的。\n他对马克思主义哲学的研究，让我感受了那个年代的脚踏实地。想到自己也看了几本哲学书，却仍然说不清一些基本概念，不禁有些惭愧。\n不知道他们两个交谈时有没有知音相遇的感觉\n离开 好久没出来旅行，东西带得不多。在腾冲的几天，意识到有些准备不足：\n要做好防晒，云南的阳光很厉害，真的会晒伤。 防蚊药物最好也带上些，至少有个止痒的药膏。 记得做核酸，这边出入都要求 48 小时阴性报告，所以最好两天做一次。 临走的时候，碰上了突发状况，幸亏有客栈大叔帮忙。\n因为没想到会打不到车，所以去车站之前没有预留很多的时间，我只好给客栈打电话。大叔当机立断，决定骑摩托车带我，因为这样可以抄小路，比开车更快。\n我几乎从来没坐过摩托，身体紧绷地不行，大叔一边笑我一边宽慰让我放松。一路上风驰电掣，最后时间还提前了不少。我不迭地向大叔道谢，他爽朗一笑，招手让我赶紧去乘车了。\n其实小镇周边还有不少景点，比如火山、温泉，但总体上更适合比较喜欢安静的人。对我来说，腾冲像快乐童年的一隅，没有烦恼，可以尽情地发呆、玩耍。如果有机会，我还会再回这里看看的。\n","permalink":"https://iamgodot.com/posts/visit-tengchong/","summary":"来到腾冲，主要是想找个地方散心。\n之前有人告诉我：\n你可能有时候过于认为自己的精力是无限的。\n其实你身体很累，但你意识总是想支出更多的体力。\n于是我想，可能什么都不做就会好起来。后来才发现，原来让自己休息并没有那么容易。\n启程 苏州没有机场，所以要先乘高铁到上海，再坐地铁到浦东机场。这实在让我有些想念北京。\n腾冲，是云南的一个县级市，隶属保山市。原本附近有个驼峰机场，到了当地才听说由于疫情已经停用很久了，因此要先飞到昆明，再乘高铁到保山，最后坐大巴到腾冲市区。因为没考虑到后面的车程，所以不得不在昆明住了一晚。不过我本来就喜欢自由行，所以并不在意。第一顿吃了小锅米线，味道很棒：\n加帽儿（肉片），加臭豆腐（白色的，经过发酵），必须微辣\n第二天一大早出发前往和顺古镇。\n之前在网上订好了客栈，老板娘知道我从昆明过来，耐心地给我讲解路线，还让我到了市区联系司机来接。后来才知道，司机大叔和老板娘是夫妻，也都是和顺本地人，非常地热情好客。\n一番周折，终于到了。大叔介绍说，前两周是人最多的时候，现在赶上开学季，所以游客很少。落个清静，正合我意。\n我本来的房间在一楼，有些小，因为客人少，所以大叔直接给换到二楼的大间，幸福。\n房间的名字很美\n二楼做成了玻璃栈道的样子，阳光落下来的时候很美，但是走在上面实在有些刺激，生怕掉下来。\n初探 简单收拾下，也算松了口气。天色尚早，是时候出去逛逛了。\n碰到一只熟睡的小猫咪：\n狗狗也睡着了：\n走出小巷，外面风光无限。这边的天黑得很晚，八点之后才开始有傍晚的感觉。\n不知走了多久，有些饿了，来到一家烧烤店。小店其实是家住的院子改造的，氛围很好：\n店名叫小俩口，门外的夫妻俩负责烧烤，里面还有个老大爷坐镇。大爷一边招呼我一边热情地介绍当地的历史，眼神中充满了作为腾冲人的自豪与骄傲。\n腾冲作为丝绸之路上的名镇，不论在商贸还是战争中都是交通要道，加上接近边境，很多人闯荡南洋后致富归来后反哺故土，让这里成为了著名侨乡。历史悠久，文化积淀深厚，自然风光秀丽，真的是一片神奇的土地。\n吃的很快上来了，虽然我有所克制，但还是点多了：\n木瓜水，酸甜可口\n蘸料是当地特色的腌菜膏，酸辣鲜咸，有些接近东南亚的口味\n小牛肉串\n包浆豆腐，非常入味\n吃饱喝足，我趁着夜色又溜达了一会儿，便回去休息了。\n跷跷板 一天晚上散步时，望着漫漫夜色，听到蛙鸣四起，一阵无助的沮丧莫名涌了上来。\n我看空地上有些健身器材，便挑了个脚蹬的架子踩了上去，随意摆动。这时来了三个人，看着像是当地的村民，一个年轻姑娘左右手各挽着年长些的一男一女，有说有笑地也来到这里。姑娘站上了我旁边的架子，玩了起来，我心情正差，看了她一眼，没有说话。那一对男女用当地话对了几句，一边一个坐上了跷跷板，男的自然重些，所以压在下面。姑娘见状便加入其中，一起帮忙把男的翘起，三个人玩闹得兴起，如同孩子般开心。我在一旁看着，心里微微起了些变化，也许是被她们的情绪感染，瞬间觉得生命并不复杂，大人也可以尽情享受跷跷板的快乐。\n之后攀谈了起来，才知道她在小镇上的客栈打工，那对男女是老板夫妇。姑娘简单地介绍了下小镇的地形，又欢迎我来这里游玩，几个人便一起离开了。\n我回忆着刚才发生的一切，有种被微光照亮的感觉。我好像与她们完全不在一个世界，但又有什么不同呢？我自认为要追求比她们更好的人生答案，但标准真的存在吗？\n水黾 相比苏州接近四十度的高温，腾冲的天气很宜人，早晚甚至有些凉意。\n上午下起了小雨\n之后逛了逛当地的图书馆和博物馆，开始了解到另一条丝绸之路的伟大：\n之前的游河西走廊就是北方丝绸之路了\n马帮行走在商路上\n落脚的客栈在小镇的西边，所以我一路向东，这里尽是湖边的美景。\n当地的孩子直接下水游泳，看起来凉爽极了\n走得累了，我便望着湖水发呆。水中趴满了一种小虫（后来才知道叫做水黾），细长的肢体，浮在水面上四处游窜。一阵风逆着吹来，将它们送回原处，甚至倒退。看这些小生物拼命地向前冲，却只是做无用功，我感到有些虚无缥缈。难道它们没有意识到一切如此无力么？我开始找寻，有没有一只会放弃抵抗、随风而去呢？\n也许是数量太多，看不过来，直到最后我也没有找到想要的证明。但可能这本身也是一种证明吧，至少对这些水黾来说，生命不息，游动不止。\n艾思奇 如果对哲学有好奇或喜爱，艾思奇纪念馆是一定要看看的。\n他对马克思主义哲学的研究，让我感受了那个年代的脚踏实地。想到自己也看了几本哲学书，却仍然说不清一些基本概念，不禁有些惭愧。\n不知道他们两个交谈时有没有知音相遇的感觉\n离开 好久没出来旅行，东西带得不多。在腾冲的几天，意识到有些准备不足：\n要做好防晒，云南的阳光很厉害，真的会晒伤。 防蚊药物最好也带上些，至少有个止痒的药膏。 记得做核酸，这边出入都要求 48 小时阴性报告，所以最好两天做一次。 临走的时候，碰上了突发状况，幸亏有客栈大叔帮忙。\n因为没想到会打不到车，所以去车站之前没有预留很多的时间，我只好给客栈打电话。大叔当机立断，决定骑摩托车带我，因为这样可以抄小路，比开车更快。\n我几乎从来没坐过摩托，身体紧绷地不行，大叔一边笑我一边宽慰让我放松。一路上风驰电掣，最后时间还提前了不少。我不迭地向大叔道谢，他爽朗一笑，招手让我赶紧去乘车了。\n其实小镇周边还有不少景点，比如火山、温泉，但总体上更适合比较喜欢安静的人。对我来说，腾冲像快乐童年的一隅，没有烦恼，可以尽情地发呆、玩耍。如果有机会，我还会再回这里看看的。","title":"游腾冲"},{"content":"前两天做了一道算法题，虽然没能成功解决，但是是一道很有意思的题目。\n抛开题面的包装不谈，核心内容就是给定一个数组，计算它的所有子数组的最小值与加和的乘积的总和。\n（这里要注意子数组的定义，一定是连续的，如果不连续的话叫做子序列。）\n比如对于 [1, 2, 3] 来说，一共有六种情况：\n[1]: 1 * 1 = 1 [2]: 2 * 2 = 4 [3]: 3 * 3 = 9 [1, 2]: 1 * (1 + 2) = 3 [2, 3]: 2 * (2 + 3) = 10 [1, 2, 3]: 1 * (1 + 2 + 3) = 6 最后答案为 1 + 4 + 9 + 3 + 10 + 6 = 33。\n暴力解法 直接的做法很容易想到，那就是嵌套遍历数组，对于每个子数组再计算 min 与 sum 的乘积，最后求和。\n看着感觉还好？但其实除了双层循环之外，计算最小值以及求和也需要一次遍历，最终的时间复杂度为 O(n^3)，非常之慢。\n看上去每个子数组的计算之间有很多重复，如何优化呢？\n单调栈 单独来看每一个元素：在某个区间内它一定是最小值，即便只有它自己，那么此范围内的子数组的最小值直接使用该元素即可。\n那么第一步就是找到每个元素的有效区间，于是问题变成了求前一个和后一个的更小元素。\n单调栈是专门来解决这类问题的，简单来说就是在遍历过程中保证栈的单调性，进而为每个元素定位前/后的更小/大元素值。一般可以这么写：\ndef find_last_greater(nums): stack = [] length = len(nums) last_greater_element_index = [-1] * length for i in range(length): while stack and nums[stack[-1]] \u0026lt;= nums[i]: stack.pop() if stack: last_greater_element_index[i] = stack[-1] stack.append(i) return last_greater_element_index 其中，遍历的顺序决定往前找（正序）还是往后找（倒序），与栈顶元素的比较决定找到的是更小还是更大的元素（的下标）。需要注意比较中的等号，它表示寻找的条件是严格单调，即排除了等值的情况。\n此外，还有一个省力的技巧。如果想同时寻找前后两个更大的元素，那么只需遍历一次即可：\ndef mono_stack(nums): stack = [] length = len(nums) last_greater_element_index = [-1] * length next_greater_element_index = [length] * length for i in range(length): while stack and nums[stack[-1]] \u0026lt;= nums[i]: # 这里正好利用出栈的机会来更新 next 数组 next_greater_element_index[stack.pop()] = i if stack: last_greater_element_index[i] = stack[-1] stack.append(i) return last_greater_element_index, next_greater_element_index 更小元素的话也是一样，改变比较条件就好了。另外结果中的两个数组正好是一开一闭的，不会出现对于等值情况的重复。\n还有初始值，比如对于前一个更大元素最好预设为 -1，这样逻辑上保持统一，计算区间长度的时候也更方便。\n前缀和 -\u0026gt; 前缀和 找到了区间，也解决了最小值的问题，要想想怎么求和了。\n假设 [l, r] 之内包含着元素 i，这样产生的子数组数量（包含 i）为两边长度的乘积：(i - l + 1) * (r - i + 1)。\n如何加和呢，我当时也卡在了这里，虽然利用前缀和可以快速得到某个子数组的和，但依次遍历这些子数组求和的复杂度仍然很高。\n后来才知道，其实可以更上一层楼，应用前缀和的前缀和快速计算出区间内所有子数组和的总和。\n公式推导的过程参考这里，截图如下：\n一般的前缀和是前面所有元素加上当前元素之和，而图中的定义略有不同，每个前缀和并不包括当前位置的元素。基于此，推导图中第二行的右半部分应为 presum[r] - presum[l - 1]。\n另外，第三行到第四行之所以消解求和符号是因为公式中没有再依赖该变量，所以能够转化为乘积关系。\n实现 先以上图的原始推导结果展示代码：\nfrom itertools import accumulate def total_strength(strength): length = len(strength) min_left, min_right = [-1] * length, [length] * length stack = [] for i in range(length): while stack and strength[stack[-1]] \u0026gt;= strength[i]: min_right[stack.pop()] = i if stack: min_left[i] = stack[-1] stack.append(i) res = 0 prepresum = list(accumulate(accumulate(strength, initial=0), initial=0)) for i in range(length): range_sum = (i - min_left[i]) * ( prepresum[min_right[i] + 1] - prepresum[i + 1] ) - (min_right[i] - i) * (prepresum[i + 1] - prepresum[min_left[i] + 1]) res += range_sum * strength[i] return res % (10 ** 9 + 7) 可以看到，在计算前缀和数组时，先在最前面增加了一个 0 元素（通过 initial 参数），这样得到的前缀和就是不包含当前位置元素的。好处是不会造成数组越界，因为下面 prepresum 的下标存在 i + 1、min_right[i] + 1 等情况。\n但这确实不符合直觉的前缀和定义，于是强迫症让我按照传统又推导了一遍，range_sum 中的 + 都变成了 -。这时候计算 prepresum 就不需要前面加 0 了。这里还有个坑要注意，因为 - 的存在，prepresum 的下标可能会小于 0，由于 Python 的切片特性并不会越界报错，而是从末尾继续计算，导致结果错误。因此，当下标变成负数时，value 要直接取 0。\nfrom itertools import accumulate def total_strength(strength): length = len(strength) min_left, min_right = [-1] * length, [length] * length stack = [] for i in range(length): while stack and strength[stack[-1]] \u0026gt;= strength[i]: min_right[stack.pop()] = i if stack: min_left[i] = stack[-1] stack.append(i) res = 0 prepresum = list(accumulate(accumulate(strength))) for i in range(length): prepresum_i = prepresum[i - 1] if i \u0026gt; 0 else 0 prepresum_left = prepresum[min_left[i] - 1] if min_left[i] - 1 \u0026gt;= 0 else 0 prepresum_right = prepresum[min_right[i] - 1] if min_right[i] - 1 \u0026gt;= 0 else 0 range_sum = (i - min_left[i]) * (prepresum_right - prepresum_i) - (min_right[i] - i) * (prepresum_i - prepresum_left) res += range_sum * strength[i] return res % (10 ** 9 + 7) 代码略微繁琐一点，不过我个人觉得还是更好理解些。\n最后之所以对 10^9 + 7 取余是因为测试数据量很大，会造成溢出。\n单调栈加前缀和的做法实现了线性的时间复杂度，相比暴力解法是飞跃般的提升，也让我切实感受到了算法之美。\nReferences\n巫师的总力量和 - Leetcode：原题参考。 Prefix Sum：综合讲解前缀和，上面的公式推导即出自这里。 子数组的最小值之和 - Leetcode：另一道类似的题目，主要是针对单调栈的应用。 ","permalink":"https://iamgodot.com/posts/sum-of-total-strength-of-wizards/","summary":"前两天做了一道算法题，虽然没能成功解决，但是是一道很有意思的题目。\n抛开题面的包装不谈，核心内容就是给定一个数组，计算它的所有子数组的最小值与加和的乘积的总和。\n（这里要注意子数组的定义，一定是连续的，如果不连续的话叫做子序列。）\n比如对于 [1, 2, 3] 来说，一共有六种情况：\n[1]: 1 * 1 = 1 [2]: 2 * 2 = 4 [3]: 3 * 3 = 9 [1, 2]: 1 * (1 + 2) = 3 [2, 3]: 2 * (2 + 3) = 10 [1, 2, 3]: 1 * (1 + 2 + 3) = 6 最后答案为 1 + 4 + 9 + 3 + 10 + 6 = 33。","title":"Sum of Total Strength of Wizards"},{"content":"这将是一篇很散的散文，仅凭着一些美好的感觉动笔，没有规划，也没有大纲。之所以这么做，是因为有时意境转瞬即逝，如果过去了，就很难再找回来。\n一切来自于刚刚的午后散步，不过短短半个小时。这本是一天中最热的时间，现在又是夏季，幸得在绿荫的庇护下，我反而觉得清凉。最近才搬来的这个小区面积广阔，绿植遍布，如花园一般，住的多是老人与孩子，氛围恰到好处。\n我站在路边的台阶上，看着不远处三两棵高木冲着烈日而去，泻出一片阴凉在四周，几只鸽子掠起，隐入了树叶的怀抱。正好奇自己何以将鸟儿的动作看得如此清晰，一阵轻巧的凉风吹过，顿时将我带到舒适的凉意中，于是我放弃了思索，闭眼享受。良久，路过的行人给这份宁静画上了句号，我接着向前走，来到了一处小小的池塘边。水不深，但还算透澈，一条暗色的游鱼捕捉了我的注意，它不动声色地摆动着尾巴，很快消失不见。这让我开始思考矛盾作为运动基础的说法，大概不管是鱼还是人，我们要活动，就永远离不开一左一右、一屈一伸的配合。我沿着池塘边做平衡式的前进，突然想到个很好的解闷法子，那就是闭着眼像现在这般走，加上路线的弧形变化，想必要比直来直去刺激许多。虽然很喜欢自己的点子，我却没有付诸行动，因为心里并不无聊，只感到平和的惬意。\n在归途的一棵树下，忽地又起了风，我自然要享受这难得的凉爽，于是驻足，仰头望去，叶子的形状比刚才看过的又都不同，它们帮我抵挡日晒，我欣赏它们的翠色欲滴。到了家里，耳中突然响起热闹的流行歌曲，我有些疑惑，想了想又觉得释然。音乐有助于改变我们的情绪，而心情又可以影响我们听到的声音。\n只是一次简单的步行，写下来也不过寥寥数语。虽然文字不够生动，可即便换作语音或视频，也不足以向第二个人分享瞬间的微妙感觉。这像是一条鸿沟，造成了人与人之间的隔阂，但它也给予我们安全，让我们觉得自己是独一无二的，更感到无比的自由。\n","permalink":"https://iamgodot.com/posts/a-peaceful-afternoon/","summary":"这将是一篇很散的散文，仅凭着一些美好的感觉动笔，没有规划，也没有大纲。之所以这么做，是因为有时意境转瞬即逝，如果过去了，就很难再找回来。\n一切来自于刚刚的午后散步，不过短短半个小时。这本是一天中最热的时间，现在又是夏季，幸得在绿荫的庇护下，我反而觉得清凉。最近才搬来的这个小区面积广阔，绿植遍布，如花园一般，住的多是老人与孩子，氛围恰到好处。\n我站在路边的台阶上，看着不远处三两棵高木冲着烈日而去，泻出一片阴凉在四周，几只鸽子掠起，隐入了树叶的怀抱。正好奇自己何以将鸟儿的动作看得如此清晰，一阵轻巧的凉风吹过，顿时将我带到舒适的凉意中，于是我放弃了思索，闭眼享受。良久，路过的行人给这份宁静画上了句号，我接着向前走，来到了一处小小的池塘边。水不深，但还算透澈，一条暗色的游鱼捕捉了我的注意，它不动声色地摆动着尾巴，很快消失不见。这让我开始思考矛盾作为运动基础的说法，大概不管是鱼还是人，我们要活动，就永远离不开一左一右、一屈一伸的配合。我沿着池塘边做平衡式的前进，突然想到个很好的解闷法子，那就是闭着眼像现在这般走，加上路线的弧形变化，想必要比直来直去刺激许多。虽然很喜欢自己的点子，我却没有付诸行动，因为心里并不无聊，只感到平和的惬意。\n在归途的一棵树下，忽地又起了风，我自然要享受这难得的凉爽，于是驻足，仰头望去，叶子的形状比刚才看过的又都不同，它们帮我抵挡日晒，我欣赏它们的翠色欲滴。到了家里，耳中突然响起热闹的流行歌曲，我有些疑惑，想了想又觉得释然。音乐有助于改变我们的情绪，而心情又可以影响我们听到的声音。\n只是一次简单的步行，写下来也不过寥寥数语。虽然文字不够生动，可即便换作语音或视频，也不足以向第二个人分享瞬间的微妙感觉。这像是一条鸿沟，造成了人与人之间的隔阂，但它也给予我们安全，让我们觉得自己是独一无二的，更感到无比的自由。","title":"夏日午后"},{"content":"最近读了矛盾论，颇有收获。\n开篇先介绍了两种对立的宇宙观：形而上学与辩证法。什么是形而上学呢？在维基百科中这样定义：\n形而上学是指透过理性的推理和逻辑去研究不能直接透过感知而得到答案的问题。\n同时也有许多种不同的解释：\n指关于世界构造的猜想，比如有没有上帝。（这也是我一直以来的理解） 指那些与科学相对的理论，它们没有科学的可证伪性，比如电子显微镜出现之前的原子论。 就是与辩证法相对的概念。 所以矛盾论里的形而上学其实是第三种，认为事物只会永远循环重复，过程中只存在数量的增减。而辩证法提出发展是对立的统一，在矛盾双方的作用下旧事物可能会变为新事物。\n有时会听到一句话：人是不会变的。以形而上学解释，好人坏人懒人勤快人各有分布，但是天定难改，因此个体的努力也就失去了意义。辩证法则告诉我们，在内因驱动下，一个人是完全有可能改变自己的。\n有内因，自然就有外因。无论是形而上学、进化论还是机械唯物论，都将外因作为事物变化的根本。但辩证法更强调内因，矛盾论里解释得很透彻：\n事物发展的根本原因，不是在事物的外部而是在事物的内部，在于内部的矛盾性。任何事物内部都有这种矛盾性，因此引起了事物的运动和发展。\n唯物辩证法认为外因是变化的条件，内因是变化的根据，外因通过内因而起作用。鸡蛋因得适当的温度而变化为鸡子，但温度不能使石头变为鸡子，因为二者的根据是不同的。\n从另一方面看，这也体现了必然性和偶然性的关系。因为必然性来自事物内部的根本矛盾，决定着事物发展的方向；而偶然性作为表现形式，其中一定包含了某种程度的必然性。\n接下来说到了矛盾的普遍性，也就是事物的发展过程中始终存在矛盾运动。矛盾是否可以作为一切运动的基础，我并不确信，但联想到生活中又觉得有些道理。\n经常听人抱怨有做不完的事儿，可一旦真的闲下来了，又着急忙慌地去找工作来做。老话儿说，人不能闲着，大概如果真的消除了一切矛盾（连饭都不吃水都不喝），生命就终结了吧。这么一想，做事只是生命中矛盾运动的体现而已，没必要太过焦虑，更不要想着什么时候能把所有的事情都做完。不过这并不意味着 996 就是合理的，因为还要考虑到矛盾的特殊性。\n共性中存在着个性，这很好理解。矛盾论直接从特殊性中总结出了实践经验的精髓：\n具体问题具体分析 优先解决主要矛盾 对我来说，从上学起就对这两句话有印象了，尤其是具体问题具体分析。在人口众多的中国，一概而论的代价实在太大了。至于第二句，放到今天就是任务的优先级安排，主要矛盾也就意味着重要且紧急，当然应该优先解决。\n最后讨论的是矛盾的同一性和斗争性。\n所谓同一性，就是矛盾双方以对方为自己存在的前提，并且，在一定的条件下，向其相反的方向转化。这里的一定的条件是很重要的一点，说明只有在特定情况下，矛盾双方才会互换，但这种转换不是必然的。\n比如在故事中，屠龙少年因为恶龙而成为英雄的角色，恶龙也由于村民的存在才被称为恶。屠龙一旦结束，有可能，少年幻化为新的恶龙，新生儿（恶龙转世）成为下一任屠龙者。当然，这种情形是可以避免的，所以尼采说：\nHe who fights with monsters should look to it that he himself does not become a monster.\n了解这种转换对看电影看剧是有帮助的，因为一旦出现好人上位坏人下台之后角色互换的反转，我就可以淡定地想到，由于编剧的脑洞大开，才造就了矛盾互相转化的前提条件。\n矛盾的斗争性是其普遍性（或者说绝对性）的一种体现。也就是说斗争无处不在，只是表现不同。激化到一定程度时，双方会进入对抗的状态并最终使矛盾得到解决，也由此产生了新事物。\n对于不同形式的矛盾斗争，要采取不同的解决办法。如果轻描淡写，问题得不到解决；但是处理方式过激，又会造成严重后果（所以不能凡事都上纲上线呀，同志们）。\n其实同一性和斗争性在道德经中也有提到，只是过于言简意赅：\n万物负阴而抱阳，冲气以为和。\n前半句说事物都背阴而向阳，暗示了矛盾双方的统一存在，后半句指出阴阳激荡会形成新的和谐体，也就是斗争之后产生新事物的结果。矛盾论中结合实例阐述，用白话文的形式让每个人都能看懂，还是很了不起的。\n那么矛盾论到了今天还有价值么？我想这一点是毋庸置疑的，因为在生活中处处都可以应用到它。\n首先，要接受一个事实，就是矛盾永远存在，并且只会伴随着事物生命周期的终结而结束。因此我们追求的不应当是消灭矛盾，而是学会以游刃有余的心态处理不断出现的新的矛盾。\n从个人的角度来讲，本我和超我的对立是永远存在的，这一点经常体现在我们想要一样东西，又觉得这么做不合适的时候。从矛盾的普遍性来看，前者出自本能欲望，后者由社会道德构建，出现冲突是必然的，所以没必要走极端，做一个极度任性或刻板的人。基于斗争性分析，如果是很普通的一件事，又不对他人造成影响，那么完全可以按想要的来，减少内耗；若是原则性的冲突，就需要认真思考再做决定（所以不能过于严肃，给太多事情贴上原则性标签）。这种冲突一旦爆发，那么矛盾解决，我们本身也就会发生一些新的改变，比如更加贴近想象中的自我形象，亦或是打开精神枷锁从而获得心灵的自由解放。\n从人与人的关系来讲，分歧也是一直都会存在的。和朋友相处而不产生争端，是一种不切实际的幻想。寄希望于形势永远保持不变或者一直变好，只会在事态崩坏后更加无所适从。我想，关系的递进也离不开矛盾斗争的解决，通常两个人在争吵又和好之后都会觉得彼此之间更亲密了，这可能就是斗争性中对抗结束后新事物产生的一种证明吧。\n","permalink":"https://iamgodot.com/posts/on-contradiction/","summary":"最近读了矛盾论，颇有收获。\n开篇先介绍了两种对立的宇宙观：形而上学与辩证法。什么是形而上学呢？在维基百科中这样定义：\n形而上学是指透过理性的推理和逻辑去研究不能直接透过感知而得到答案的问题。\n同时也有许多种不同的解释：\n指关于世界构造的猜想，比如有没有上帝。（这也是我一直以来的理解） 指那些与科学相对的理论，它们没有科学的可证伪性，比如电子显微镜出现之前的原子论。 就是与辩证法相对的概念。 所以矛盾论里的形而上学其实是第三种，认为事物只会永远循环重复，过程中只存在数量的增减。而辩证法提出发展是对立的统一，在矛盾双方的作用下旧事物可能会变为新事物。\n有时会听到一句话：人是不会变的。以形而上学解释，好人坏人懒人勤快人各有分布，但是天定难改，因此个体的努力也就失去了意义。辩证法则告诉我们，在内因驱动下，一个人是完全有可能改变自己的。\n有内因，自然就有外因。无论是形而上学、进化论还是机械唯物论，都将外因作为事物变化的根本。但辩证法更强调内因，矛盾论里解释得很透彻：\n事物发展的根本原因，不是在事物的外部而是在事物的内部，在于内部的矛盾性。任何事物内部都有这种矛盾性，因此引起了事物的运动和发展。\n唯物辩证法认为外因是变化的条件，内因是变化的根据，外因通过内因而起作用。鸡蛋因得适当的温度而变化为鸡子，但温度不能使石头变为鸡子，因为二者的根据是不同的。\n从另一方面看，这也体现了必然性和偶然性的关系。因为必然性来自事物内部的根本矛盾，决定着事物发展的方向；而偶然性作为表现形式，其中一定包含了某种程度的必然性。\n接下来说到了矛盾的普遍性，也就是事物的发展过程中始终存在矛盾运动。矛盾是否可以作为一切运动的基础，我并不确信，但联想到生活中又觉得有些道理。\n经常听人抱怨有做不完的事儿，可一旦真的闲下来了，又着急忙慌地去找工作来做。老话儿说，人不能闲着，大概如果真的消除了一切矛盾（连饭都不吃水都不喝），生命就终结了吧。这么一想，做事只是生命中矛盾运动的体现而已，没必要太过焦虑，更不要想着什么时候能把所有的事情都做完。不过这并不意味着 996 就是合理的，因为还要考虑到矛盾的特殊性。\n共性中存在着个性，这很好理解。矛盾论直接从特殊性中总结出了实践经验的精髓：\n具体问题具体分析 优先解决主要矛盾 对我来说，从上学起就对这两句话有印象了，尤其是具体问题具体分析。在人口众多的中国，一概而论的代价实在太大了。至于第二句，放到今天就是任务的优先级安排，主要矛盾也就意味着重要且紧急，当然应该优先解决。\n最后讨论的是矛盾的同一性和斗争性。\n所谓同一性，就是矛盾双方以对方为自己存在的前提，并且，在一定的条件下，向其相反的方向转化。这里的一定的条件是很重要的一点，说明只有在特定情况下，矛盾双方才会互换，但这种转换不是必然的。\n比如在故事中，屠龙少年因为恶龙而成为英雄的角色，恶龙也由于村民的存在才被称为恶。屠龙一旦结束，有可能，少年幻化为新的恶龙，新生儿（恶龙转世）成为下一任屠龙者。当然，这种情形是可以避免的，所以尼采说：\nHe who fights with monsters should look to it that he himself does not become a monster.\n了解这种转换对看电影看剧是有帮助的，因为一旦出现好人上位坏人下台之后角色互换的反转，我就可以淡定地想到，由于编剧的脑洞大开，才造就了矛盾互相转化的前提条件。\n矛盾的斗争性是其普遍性（或者说绝对性）的一种体现。也就是说斗争无处不在，只是表现不同。激化到一定程度时，双方会进入对抗的状态并最终使矛盾得到解决，也由此产生了新事物。\n对于不同形式的矛盾斗争，要采取不同的解决办法。如果轻描淡写，问题得不到解决；但是处理方式过激，又会造成严重后果（所以不能凡事都上纲上线呀，同志们）。\n其实同一性和斗争性在道德经中也有提到，只是过于言简意赅：\n万物负阴而抱阳，冲气以为和。\n前半句说事物都背阴而向阳，暗示了矛盾双方的统一存在，后半句指出阴阳激荡会形成新的和谐体，也就是斗争之后产生新事物的结果。矛盾论中结合实例阐述，用白话文的形式让每个人都能看懂，还是很了不起的。\n那么矛盾论到了今天还有价值么？我想这一点是毋庸置疑的，因为在生活中处处都可以应用到它。\n首先，要接受一个事实，就是矛盾永远存在，并且只会伴随着事物生命周期的终结而结束。因此我们追求的不应当是消灭矛盾，而是学会以游刃有余的心态处理不断出现的新的矛盾。\n从个人的角度来讲，本我和超我的对立是永远存在的，这一点经常体现在我们想要一样东西，又觉得这么做不合适的时候。从矛盾的普遍性来看，前者出自本能欲望，后者由社会道德构建，出现冲突是必然的，所以没必要走极端，做一个极度任性或刻板的人。基于斗争性分析，如果是很普通的一件事，又不对他人造成影响，那么完全可以按想要的来，减少内耗；若是原则性的冲突，就需要认真思考再做决定（所以不能过于严肃，给太多事情贴上原则性标签）。这种冲突一旦爆发，那么矛盾解决，我们本身也就会发生一些新的改变，比如更加贴近想象中的自我形象，亦或是打开精神枷锁从而获得心灵的自由解放。\n从人与人的关系来讲，分歧也是一直都会存在的。和朋友相处而不产生争端，是一种不切实际的幻想。寄希望于形势永远保持不变或者一直变好，只会在事态崩坏后更加无所适从。我想，关系的递进也离不开矛盾斗争的解决，通常两个人在争吵又和好之后都会觉得彼此之间更亲密了，这可能就是斗争性中对抗结束后新事物产生的一种证明吧。","title":"读《矛盾论》"},{"content":"说起 CORS，就不得不先提到 SOP(Same-origin policy)：浏览器打开的网页只可以对该网页的同源网站发起请求。注意，受约束的主要是脚本代码，不包括图片或者 CSS 等资源（字体文件是个例外）。同源的定义包括三部分，即协议、域名和端口都要保持一致。\n为了缓解 SOP 带来的严格限制，有几种主流的解决方案可以选择：\nCORS JSONP：利用 \u0026lt;script\u0026gt; 标签来请求非同源地址的 JSON 响应，同时配合一个预先定义的回调函数来处理响应数据。 WebSocket：WS 连接并不受同源策略的约束，但是在建立连接时服务端也需要判断 headers 中的 Origin 是否可以接受。 其中 CORS 应该是最实用的一种，相比 JSONP 只支持 GET 请求，前者扩展了各种 HTTP 方法的跨域调用。\nCORS(Cross-origin resource sharing)，是一种跨域共享资源的机制，它利用特定的 Headers 来保证跨域请求的安全性，这些请求分为两类：简单请求和非简单请求。\n简单请求，包括 GET、HEAD 和 POST，这里 POST 的 Content-Type 仅限于下面三种：\napplication/x-www-form-urlencoded\nmultipart/form-data\ntext/plain\n对于这些请求来说，只需要保证 Access-Control-Allow-Origin 中匹配了当前网页的域名即可，如果是 * 的话表明所有的域名都是允许的。\n非简单请求，比如 Content-Type 为 application/json 的 POST，会增加一次额外的 Preflight 请求，即先发送 OPTIONS 请求给服务器，然后通过响应中的一系列 Headers 决定是否可以进行真正的请求。这些 Headers 包括：\nAccess-Control-Allow-Methods：服务器允许的跨域方法，比如 POST。 Access-Control-Allow-Headers：服务器允许的跨域头部，比如 Content-Type。 Access-Control-Max-Age：Preflight 请求结果的缓存时间，默认为 5s。 另外，如果想在 Chrome 中查看 Preflight 请求的话，打开 Network 标签，点击 Other filter 就可以看到了。\nCredential 对于用到 Cookie 或者其他 HTTP Auth 信息的请求，还需要通信双方做一些额外的设置，服务器要提供：\nAccess-Control-Allow-Credentials：设置为 true。在 Preflight 请求的响应中，这个 Header 表示正式请求中可以携带 Credential 信息。而对于 GET 这种不需要 Preflight 的简单请求，没有此 Header 的话浏览器会直接拒绝服务器的响应。 Access-Control-Expose-Headers：允许设置的 Headers 暴露给客户端。对于 Cookie 场景，要添加 Set-Cookie，浏览器脚本才可以使用此 Header，进而 Cookie 才能够设置成功。 而客户端想发送 Credential 请求的话，也要显式地加上一个特殊的 flag： withCredentials: true，无论是 XMLHttpRequest、Fetch 还是 Axios。\n最后要注意的是，对于 Credential 请求的响应，下面三种 Headers 不可以使用 * 匹配，必须要指定特定的合法值：\nAccess-Control-Allow-Origin Access-Control-Allow-Headers Access-Control-Allow-Methods CORS in Python 使用 Flask 的话，可以安装 Flask-CORS 来实现服务端的跨域：\nfrom flask import Flask from flask_cors import CORS app = Flask(__name__) CORS(app, supports_credentials=True, allow_headers=[\u0026#39;Content-Type\u0026#39;], expose_headers=[\u0026#34;Set-Cookie\u0026#34;]) 如果是 FastAPI，直接用内置的 Middleware 就好了，参考官方文档。\nProxy 其实换一种思路的话，只要有中间网关做转发来避免跨域请求就不存在 SOP 的限制了。\n所以在前端开发中，比如 React，只需配置 proxy 为服务端的地址，API 请求就会先传递到 Dev server，再转发给后端。\n同理，在正式部署中，我们同样可以利用 Nginx 的 proxy_pass 达到代理转发的效果。\n当然，即便如此，了解 SOP 和 CORS 的原理依然是必要的，而且也并不困难。\nReferences\nCORS - MDN\nSame-origin policy - Wikipedia\nCross-origin resource sharing - Wikipedia\nProxying API Requests in Development - React\n","permalink":"https://iamgodot.com/posts/about-cors/","summary":"说起 CORS，就不得不先提到 SOP(Same-origin policy)：浏览器打开的网页只可以对该网页的同源网站发起请求。注意，受约束的主要是脚本代码，不包括图片或者 CSS 等资源（字体文件是个例外）。同源的定义包括三部分，即协议、域名和端口都要保持一致。\n为了缓解 SOP 带来的严格限制，有几种主流的解决方案可以选择：\nCORS JSONP：利用 \u0026lt;script\u0026gt; 标签来请求非同源地址的 JSON 响应，同时配合一个预先定义的回调函数来处理响应数据。 WebSocket：WS 连接并不受同源策略的约束，但是在建立连接时服务端也需要判断 headers 中的 Origin 是否可以接受。 其中 CORS 应该是最实用的一种，相比 JSONP 只支持 GET 请求，前者扩展了各种 HTTP 方法的跨域调用。\nCORS(Cross-origin resource sharing)，是一种跨域共享资源的机制，它利用特定的 Headers 来保证跨域请求的安全性，这些请求分为两类：简单请求和非简单请求。\n简单请求，包括 GET、HEAD 和 POST，这里 POST 的 Content-Type 仅限于下面三种：\napplication/x-www-form-urlencoded\nmultipart/form-data\ntext/plain\n对于这些请求来说，只需要保证 Access-Control-Allow-Origin 中匹配了当前网页的域名即可，如果是 * 的话表明所有的域名都是允许的。\n非简单请求，比如 Content-Type 为 application/json 的 POST，会增加一次额外的 Preflight 请求，即先发送 OPTIONS 请求给服务器，然后通过响应中的一系列 Headers 决定是否可以进行真正的请求。这些 Headers 包括：\nAccess-Control-Allow-Methods：服务器允许的跨域方法，比如 POST。 Access-Control-Allow-Headers：服务器允许的跨域头部，比如 Content-Type。 Access-Control-Max-Age：Preflight 请求结果的缓存时间，默认为 5s。 另外，如果想在 Chrome 中查看 Preflight 请求的话，打开 Network 标签，点击 Other filter 就可以看到了。","title":"关于 CORS"},{"content":"最近读完了叔本华的《人生的智慧》，其中关于独处的言论令人印象深刻。作者的观点鲜明，欣赏之余，我也不禁想重新解读下这件事情。\n先看看书中的描述：\n拘谨、掣肘不可避免地伴随着社交聚会。社交聚会要求人们做出牺牲，而一个人越具备独特的个性，那他就越难做出这样的牺牲。因此，一个人逃避、忍受抑或喜爱独处是和这一个人自身具备的价值恰成比例。因为在独处的时候，一个可怜虫就会感受到自己的全部可怜之处，而一个具有丰富思想的人只会感受到自己丰富的思想。一言以蔽之：一个人只会感觉到自己的自身。进一步而言，一个人在大自然的级别中所处的位置越高，那他就越孤独，这是根本的，同时也是必然的。\n首先要承认，作为一名孤独患者，读完后充满了优越感，但又感到有些不对劲：人都生活在社会中，到底怎样才算是独处？如果这才是正确的选择，那还有必要社交吗？独处者真的高人一等么？\n要解答这些问题，需要先给独处下个定义。我想它并不等同于独居或独来独往，因为这些造成的是生活中的影响，而没有体现精神层面的差异。从书中来看，作者针对的是上流社会的社交方式：\n所谓的上流社会承认一个人在其他方面的优势，却唯独不肯承认一个人在精神思想方面的优势；他们甚至抵制这方面的优势。\n另外，由于真正的、精神思想的优势不会见容于社交聚会，并且也着实难得一见，为了代替它，人们就采用了一种虚假的、世俗常规的、建立在相当随意的原则之上的东西作为某种优越的表现——它在高级的社交圈子里传统般地传递着，就像暗语一样地可以随时更改。这也就是人们名之为时尚或时髦的东西。\n而并不是所有的聚会场合：\n具有深度的交谈和充满思想的话语只能属于由思想丰富的人所组成的聚会。\n因此，相比在人群中泛泛而谈，独处看起来是个不错的选择，而真正可以深度交流的机会更是求之不得的。\n那么独处是在做什么？抛开实际的活动不谈，我想这包括了思想的创造和心灵的解放。前者指的是思考过程，这一点无论在行动中（散步）还是静止状态下（发呆）都可以完成；后者则要求我们的身体停顿下来，让内心深处的感受浮现，这通常难以做到，除非坚持长期的练习，比如冥想。\n如果这样便已足够，社会恐怕不会发展成今天的样子。无论是谁，在生命历程中都需要经验资料来丰富自己的认知。即使独处，我们仍然会不断地从外界获取信息，无论是书籍、网站还是播客。\n此时已经可以联想到一些好的生活习惯是如何在底层逻辑上成立的：\n复盘 冥想 阅读 必须承认，不论聪明才智还是性格习惯，个体都受限于独立本身，所以与贤为伴是必要的。从父母老师，到同事朋友，甚至是学生晚辈，即使对方没有更好的见解，我们也很可能在交流中反窥出自己的问题。简单来说：三人行，必有我师。\n从叔本华的角度看，才智卓越之士在人群之中只会受到拖累，这么说无可厚非，只是如他一般的天才实难多见。对大多数人来说，更实用的做法就是组合成为强大的团队，在合作过程中相互促进。从另一个角度上讲，互利共赢优于闭关锁国。\n我更赞赏心灵的独处：\n因此，完全、真正的内心平和和感觉宁静——这是在这尘世间仅次于健康的至高无上的恩物\u0026ndash;也只有在一个人孤身独处的时候才可觅到；而要长期保持这一心境，则只有深居简出才行。\n青年人首上的一课，就是要学会承受孤独，因为孤独是幸福、安乐的源泉。\n智商自出生便有高低，有时候再努力也难以跨越天赋的鸿沟。内心则不同，每个人都可以通过足够的修炼让自己达到独立、自由与平和的境界。孤独面前，人人平等，越早接受并适应这一现实，我们就越少受到独处时带来的痛苦煎熬。当然，生活也时而赋予我们陪伴，所以独处更应当作为一种能力，而非状态。\n至于自身价值，很明显不能单单通过独处能力来判定，就像按照财富或社会地位将人划分为三六九等一样，对号入座可能会让自己心情好些，但并没有道理。饶是如此，如果不能很好地与自己相处，对未来的人生的确会产生不利影响，因为这意味着大部分的时间我们都是无所适从的，尤其到了老年时期。\n遗憾的是，在当今时代，虽然人口和信息都在无限爆炸，但我们与独处更加密不可分了。网络的便利提供足不出户的借口，疫情负责夺走人身自由，孤独感依旧，绝望的情绪却已经悄悄完成了全球化。\n物质是有限的，但精神可以不受约束。也许叔本华想象不到今天的世界，但他的话确实打动了我：\n谁要是不热爱独处，那他也就是不热爱自由，因为只有当一个人独处的时候，他才是自由的。\n","permalink":"https://iamgodot.com/posts/on-solitude/","summary":"最近读完了叔本华的《人生的智慧》，其中关于独处的言论令人印象深刻。作者的观点鲜明，欣赏之余，我也不禁想重新解读下这件事情。\n先看看书中的描述：\n拘谨、掣肘不可避免地伴随着社交聚会。社交聚会要求人们做出牺牲，而一个人越具备独特的个性，那他就越难做出这样的牺牲。因此，一个人逃避、忍受抑或喜爱独处是和这一个人自身具备的价值恰成比例。因为在独处的时候，一个可怜虫就会感受到自己的全部可怜之处，而一个具有丰富思想的人只会感受到自己丰富的思想。一言以蔽之：一个人只会感觉到自己的自身。进一步而言，一个人在大自然的级别中所处的位置越高，那他就越孤独，这是根本的，同时也是必然的。\n首先要承认，作为一名孤独患者，读完后充满了优越感，但又感到有些不对劲：人都生活在社会中，到底怎样才算是独处？如果这才是正确的选择，那还有必要社交吗？独处者真的高人一等么？\n要解答这些问题，需要先给独处下个定义。我想它并不等同于独居或独来独往，因为这些造成的是生活中的影响，而没有体现精神层面的差异。从书中来看，作者针对的是上流社会的社交方式：\n所谓的上流社会承认一个人在其他方面的优势，却唯独不肯承认一个人在精神思想方面的优势；他们甚至抵制这方面的优势。\n另外，由于真正的、精神思想的优势不会见容于社交聚会，并且也着实难得一见，为了代替它，人们就采用了一种虚假的、世俗常规的、建立在相当随意的原则之上的东西作为某种优越的表现——它在高级的社交圈子里传统般地传递着，就像暗语一样地可以随时更改。这也就是人们名之为时尚或时髦的东西。\n而并不是所有的聚会场合：\n具有深度的交谈和充满思想的话语只能属于由思想丰富的人所组成的聚会。\n因此，相比在人群中泛泛而谈，独处看起来是个不错的选择，而真正可以深度交流的机会更是求之不得的。\n那么独处是在做什么？抛开实际的活动不谈，我想这包括了思想的创造和心灵的解放。前者指的是思考过程，这一点无论在行动中（散步）还是静止状态下（发呆）都可以完成；后者则要求我们的身体停顿下来，让内心深处的感受浮现，这通常难以做到，除非坚持长期的练习，比如冥想。\n如果这样便已足够，社会恐怕不会发展成今天的样子。无论是谁，在生命历程中都需要经验资料来丰富自己的认知。即使独处，我们仍然会不断地从外界获取信息，无论是书籍、网站还是播客。\n此时已经可以联想到一些好的生活习惯是如何在底层逻辑上成立的：\n复盘 冥想 阅读 必须承认，不论聪明才智还是性格习惯，个体都受限于独立本身，所以与贤为伴是必要的。从父母老师，到同事朋友，甚至是学生晚辈，即使对方没有更好的见解，我们也很可能在交流中反窥出自己的问题。简单来说：三人行，必有我师。\n从叔本华的角度看，才智卓越之士在人群之中只会受到拖累，这么说无可厚非，只是如他一般的天才实难多见。对大多数人来说，更实用的做法就是组合成为强大的团队，在合作过程中相互促进。从另一个角度上讲，互利共赢优于闭关锁国。\n我更赞赏心灵的独处：\n因此，完全、真正的内心平和和感觉宁静——这是在这尘世间仅次于健康的至高无上的恩物\u0026ndash;也只有在一个人孤身独处的时候才可觅到；而要长期保持这一心境，则只有深居简出才行。\n青年人首上的一课，就是要学会承受孤独，因为孤独是幸福、安乐的源泉。\n智商自出生便有高低，有时候再努力也难以跨越天赋的鸿沟。内心则不同，每个人都可以通过足够的修炼让自己达到独立、自由与平和的境界。孤独面前，人人平等，越早接受并适应这一现实，我们就越少受到独处时带来的痛苦煎熬。当然，生活也时而赋予我们陪伴，所以独处更应当作为一种能力，而非状态。\n至于自身价值，很明显不能单单通过独处能力来判定，就像按照财富或社会地位将人划分为三六九等一样，对号入座可能会让自己心情好些，但并没有道理。饶是如此，如果不能很好地与自己相处，对未来的人生的确会产生不利影响，因为这意味着大部分的时间我们都是无所适从的，尤其到了老年时期。\n遗憾的是，在当今时代，虽然人口和信息都在无限爆炸，但我们与独处更加密不可分了。网络的便利提供足不出户的借口，疫情负责夺走人身自由，孤独感依旧，绝望的情绪却已经悄悄完成了全球化。\n物质是有限的，但精神可以不受约束。也许叔本华想象不到今天的世界，但他的话确实打动了我：\n谁要是不热爱独处，那他也就是不热爱自由，因为只有当一个人独处的时候，他才是自由的。","title":"论独处"},{"content":"写这篇文章最开心的一点是终于可以用这张截图了：\n相比名声在外的 Django/Flask/FastAPI，Bottle 可以说是非常不起眼了，甚至很多人并不知道它的存在。其实在很多方面，这个框架都极其优秀：\n速度：截止到 2022-04-13，Bottle 在一众 Python Web 框架的测评中名列第二，要知道这可是十年以上的老前辈了。 易用性：Bottle 早在 Flask 之前就使用了装饰器来定义路由，此外还有全局可用的 Request/Response 对象。 文档：不仅将框架本身的使用讲得很清楚，还总结了很多 Web 场景下的解决方案。 代码质量：虽然为了 Python 2 做了不少兼容，但是代码很精炼，而且 Pythonic。 其他：Bottle 坚持单模块以及无第三方库依赖；仓库仍然在积极维护中。 换作几年前，我会一开始就使用并将 Bottle 研究透彻，而不是让自己淹没在 Django 浩瀚如烟的文档中。下面开始梳理 Bottle 源码的阅读理解。因为代码量不大，所以就直接看最新的版本了：0.11.1 - 5a6c620。\nWeb 框架的基本元素 参考 The Hitchhiker\u0026rsquo;s Guide to Python 的说法，一个 Web 框架要满足的基本功能：\nURL Routing Request and Response Objects Template Engine Development Web Server 从后端的角度来讲更重要的是 1、2、4 三项，其中 1 负责转发请求到对应的视图函数，2 是对 HTTP 协议元素的解析处理，而 4 决定了服务的部署方式和基础性能。\nBottle 在这几方面都做了很好的实现：路由上提供了通配符匹配和装饰器接口；请求和响应对象作为全局对象存在并保证了线程安全；Server 部署除了 Python 自带的 wsgiref 还支持绝大多数的 WSGI Server。\n之外 Bottle 服务还会自动检测代码变更并重启，扩展方面有 Hook 和 Plugin 机制等等。\n一切从 WSGI 开始 WSGI 定义了 Python Web 框架的统一接口规范，因此也是了解 Bottle 最好的突破口。一个 Web 服务可以简单看成 Server 和 Handler 两部分，前者负责监听端口并建立连接，而后者处理请求然后返回响应内容。Handler 在 WSGI 中称为 app，是一个可调用对象，比如：\ndef application(environ, start_response): response_body = [ \u0026#39;%s: %s\u0026#39; % (key, value) for key, value in sorted(environ.items()) ] response_body = \u0026#39;\\n\u0026#39;.join(response_body) status = \u0026#39;200 OK\u0026#39; response_headers = [ (\u0026#39;Content-Type\u0026#39;, \u0026#39;text/plain\u0026#39;), (\u0026#39;Content-Length\u0026#39;, str(len(response_body))) ] start_response(status, response_headers) return [response_body.encode()] 在 Bottle 中 app 被包装成了一个 Bottle 对象，实际的调用过程在它的 wsgi 方法里：\nclass Bottle(object): ... def wsgi(self, environ, start_response): try: # 获取响应内容并做适当转化 out = self._cast(self._handle(environ)) ... exc_info = environ.get(\u0026#34;bottle.exc_info\u0026#34;) if exc_info is not None: del environ[\u0026#34;bottle.exc_info\u0026#34;] start_response(response._wsgi_status_line(), response.headerlist, exc_info) return out except (KeyboardInterrupt, SystemExit, MemoryError): ... def _handle(self, environ): ... try: while True: out = None try: self.trigger_hook(\u0026#34;before_request\u0026#34;) # 通过路由找到视图函数 route, args = self.router.match(environ) environ[\u0026#34;route.handle\u0026#34;] = route environ[\u0026#34;bottle.route\u0026#34;] = route environ[\u0026#34;route.url_args\u0026#34;] = args # 调用视图函数获取结果 out = route.call(**args) break except HTTPResponse as E: .... 可以看到，_handle 方法负责路由到对应的视图函数并调用获取响应，而 _cast 会对响应内容进行 WSGI 兼容的处理。\n接下来根据 self.router.match(environ) 来看路由部分的具体实现。\n路由 Router 是抽象出来的负责路由转发的对象，实质上是一系列 Routes 的集合，而每个 Route 代表方法和路径到视图函数的对应关系。因此，当一个 HTTP 请求到来，Router 就可以从 Routes 中找到匹配的视图函数。思路很简单，关键是如何实现高效的查找过程。下面看 Router 的代码：\nclass Router(object): ... def match(self, environ): ... for method in methods: if method in self.static and path in self.static[method]: target, getargs = self.static[method][path] return target, getargs(path) if getargs else {} elif method in self.dyna_regexes: for combined, rules in self.dyna_regexes[method]: match = combined(path) if match: target, getargs = rules[match.lastindex - 1] return target, getargs(path) if getargs else {} ... 核心逻辑有两部分：首先是静态匹配，在 self.static 中保存了从方法到路径再到视图函数（target）的映射，这里会直接用哈希表实现快速查找；其次是通配符匹配，self.dyna_regexes 里每个方法都包含多个 (combined, rules) 元组，而 combined 由多个正则表达式组合到一起（每个正则代表一个动态路径），对应到 rules 中的多个视图函数。之所以会有多个元组，是因为 CPython 中正则的分组匹配最多只支持 99 个，所以一个 combined 的容量是有限的，如果动态路由过多，就需要增加新的元组。\n这里体现了 Bottle 路由查找的基本原则：\n静态路由匹配的优先级高于动态路由。 动态路由匹配有先后顺序，注意不要造成短路。 还有添加路由的时候 一个视图函数可以定义多个路径。 重复定义会覆盖原有路由，当然这也是允许的。 请求 \u0026amp; 响应 接下来是对 HTTP 请求和响应的抽象，Bottle 定义了全局的 Request \u0026amp; Response 对象。看起来和 Flask 很像，其实要比后者更早。\n关键在于保证线程安全，这部分已经在 Python 中的 TLS 是如何实现的 中说得很详细了，下面看看 Bottle 是怎么实现的：\ndef _local_property(): ls = threading.local() def fget(_): try: return ls.var except AttributeError: raise RuntimeError(\u0026#34;Request context not initialized.\u0026#34;) def fset(_, value): ls.var = value def fdel(_): del ls.var return property(fget, fset, fdel, \u0026#34;Thread-local property\u0026#34;) class LocalRequest(BaseRequest): bind = BaseRequest.__init__ environ = _local_property() class LocalResponse(BaseResponse): bind = BaseResponse.__init__ _status_line = _local_property() _status_code = _local_property() _cookies = _local_property() _headers = _local_property() body = _local_property() ... request = LocalRequest() response = LocalResponse() 基于 threading.local，Bottle 使用修饰符来定义 LocalRequest 和 LocalResponse 中的 HTTP 属性，这样的实现很灵活，也可以轻松地应用到其他的对象。\n需要注意的是，在 greenlet 和 coroutine 大行其道的今天，threading.local 已经完全不够用了。Bottle 与 ASGI 水土不服，但是一定要部署成 Async 服务的话，也是有方法的：比如保证 threading.local 提前被 monkeypatch（针对 gevent），或者在代码中使用 request.copy() 拷贝出新的请求对象。作者在文档和 Issue 中都做了详细的解释。\n服务 Bottle 默认使用了 wsgiref 模块中的 WSGI Server 来启动服务，这种服务是单线程的，所以也只适用于本地开发。\n此外 Bottle 支持许多 Web Server 部署，在官网有详细列举：\n为了兼容这么多的 Server，Bottle 在内部实现了各种各样的适配器，比如 wsgiref：\nclass ServerAdapter(object): quiet = False def __init__(self, host=\u0026#34;127.0.0.1\u0026#34;, port=8080, **options): self.options = options self.host = host self.port = int(port) def run(self, handler): pass def __repr__(self): args = \u0026#34;, \u0026#34;.join(\u0026#34;%s=%s\u0026#34; % (k, repr(v)) for k, v in self.options.items()) return \u0026#34;%s(%s)\u0026#34; % (self.__class__.__name__, args) class WSGIRefServer(ServerAdapter): def run(self, app): import socket from wsgiref.simple_server import (WSGIRequestHandler, WSGIServer, make_server) ... handler_cls = self.options.get(\u0026#34;handler_class\u0026#34;, FixedHandler) server_cls = self.options.get(\u0026#34;server_class\u0026#34;, WSGIServer) ... self.srv = make_server(self.host, self.port, app, server_cls, handler_cls) self.port = self.srv.server_port try: self.srv.serve_forever() except KeyboardInterrupt: self.srv.server_close() raise 通过适配器模式，可以很方便地修改原有适配或者添加新的 Server 支持。这里不详述了。\n模板系统 Bottle 实现了自己的模板生成功能，同时也支持主流的 Mako 和 Jinja2。无论使用哪一种，都可以直接调用 template 这个简单的接口：\ndef template(*args, **kwargs): tpl = args[0] if args else None for dictarg in args[1:]: kwargs.update(dictarg) adapter = kwargs.pop(\u0026#34;template_adapter\u0026#34;, SimpleTemplate) lookup = kwargs.pop(\u0026#34;template_lookup\u0026#34;, TEMPLATE_PATH) tplid = (id(lookup), tpl) if tplid not in TEMPLATES or DEBUG: settings = kwargs.pop(\u0026#34;template_settings\u0026#34;, {}) if isinstance(tpl, adapter): TEMPLATES[tplid] = tpl if settings: TEMPLATES[tplid].prepare(**settings) elif \u0026#34;\\n\u0026#34; in tpl or \u0026#34;{\u0026#34; in tpl or \u0026#34;%\u0026#34; in tpl or \u0026#34;$\u0026#34; in tpl: TEMPLATES[tplid] = adapter(source=tpl, lookup=lookup, **settings) else: TEMPLATES[tplid] = adapter(name=tpl, lookup=lookup, **settings) if not TEMPLATES[tplid]: abort(500, \u0026#34;Template (%s) not found\u0026#34; % tpl) return TEMPLATES[tplid].render(kwargs) 通过指定 template_adapter 使用不同的模板系统，这是很典型的策略模式。另外，这里也同样出现了适配器模式，基于 BaseTemplate 来适配各个模板库：\nclass MakoTemplate(BaseTemplate): ... class Jinja2Template(BaseTemplate): ... class SimpleTemplate(BaseTemplate): ... 自动重启 Bottle 还提供了检测 Python 文件改动并自动重启服务的功能，实现思路也很巧妙：\ndef run( app=None, server=\u0026#34;wsgiref\u0026#34;, host=\u0026#34;127.0.0.1\u0026#34;, port=8080, interval=1, reloader=False, quiet=False, plugins=None, debug=None, config=None, **kargs ): if NORUN: return if reloader and not os.environ.get(\u0026#34;BOTTLE_CHILD\u0026#34;): import subprocess fd, lockfile = tempfile.mkstemp(prefix=\u0026#34;bottle.\u0026#34;, suffix=\u0026#34;.lock\u0026#34;) environ = os.environ.copy() environ[\u0026#34;BOTTLE_CHILD\u0026#34;] = \u0026#34;true\u0026#34; environ[\u0026#34;BOTTLE_LOCKFILE\u0026#34;] = lockfile args = [sys.executable] + sys.argv if getattr(sys.modules.get(\u0026#34;__main__\u0026#34;), \u0026#34;__package__\u0026#34;, None): args[1:1] = [\u0026#34;-m\u0026#34;, sys.modules[\u0026#34;__main__\u0026#34;].__package__] # 如果设置了 Reload 那么主进程会执行下面的 try block， # 启动子进程并且 Polling 在 while 循环中 try: os.close(fd) # We never write to this file while os.path.exists(lockfile): p = subprocess.Popen(args, env=environ) while p.poll() is None: os.utime(lockfile, None) # Tell child we are still alive time.sleep(interval) if p.returncode == 3: # Child wants to be restarted continue sys.exit(p.returncode) except KeyboardInterrupt: pass finally: if os.path.exists(lockfile): os.unlink(lockfile) return # 如果没有设置 Reload 或者是子进程，则会执行下面的 try block # 这时才会真正启动 Server，而且如果是子进程的话还会启动额外的检测线程 try: if debug is not None: _debug(debug) app = app or default_app() if isinstance(app, basestring): app = load_app(app) if not callable(app): raise ValueError(\u0026#34;Application is not callable: %r\u0026#34; % app) for plugin in plugins or []: if isinstance(plugin, basestring): plugin = load(plugin) app.install(plugin) if config: app.config.update(config) if server in server_names: server = server_names.get(server) if isinstance(server, basestring): server = load(server) if isinstance(server, type): server = server(host=host, port=port, **kargs) if not isinstance(server, ServerAdapter): raise ValueError(\u0026#34;Unknown or unsupported server: %r\u0026#34; % server) server.quiet = server.quiet or quiet if not server.quiet: _stderr( \u0026#34;Bottle v%s server starting up (using %s)...\u0026#34; % (__version__, repr(server)) ) if server.host.startswith(\u0026#34;unix:\u0026#34;): _stderr(\u0026#34;Listening on %s\u0026#34; % server.host) else: _stderr(\u0026#34;Listening on http://%s:%d/\u0026#34; % (server.host, server.port)) _stderr(\u0026#34;Hit Ctrl-C to quit.\\n\u0026#34;) # 这里判断 Reload 成功就会启动 Daemon thread 检测文件改动 if reloader: lockfile = os.environ.get(\u0026#34;BOTTLE_LOCKFILE\u0026#34;) bgcheck = FileCheckerThread(lockfile, interval) with bgcheck: server.run(app) # 如果文件出现改动则退出子进程 # 如果是 lockfile 有问题这里的 status 会是 error # 子进程也会退出，但 Exit status 不是 3 所以不会重启 if bgcheck.status == \u0026#34;reload\u0026#34;: sys.exit(3) else: server.run(app) except KeyboardInterrupt: pass except (SystemExit, MemoryError): raise except: if not reloader: raise # 如果是其他的异常，非 quiet 情况下会打印错误栈 # sleep 之后退出子进程并重启 if not getattr(server, \u0026#34;quiet\u0026#34;, quiet): print_exc() time.sleep(interval) sys.exit(3) class FileCheckerThread(threading.Thread): def __init__(self, lockfile, interval): threading.Thread.__init__(self) self.daemon = True self.lockfile, self.interval = lockfile, interval #: Is one of \u0026#39;reload\u0026#39;, \u0026#39;error\u0026#39; or \u0026#39;exit\u0026#39; self.status = None def run(self): exists = os.path.exists mtime = lambda p: os.stat(p).st_mtime files = dict() for module in list(sys.modules.values()): path = getattr(module, \u0026#34;__file__\u0026#34;, \u0026#34;\u0026#34;) or \u0026#34;\u0026#34; if path[-4:] in (\u0026#34;.pyo\u0026#34;, \u0026#34;.pyc\u0026#34;): path = path[:-1] if path and exists(path): files[path] = mtime(path) while not self.status: # 如果 lockfile 不存在或者过于陈旧则通知子进程退出 # 这里的 interrupt_main 默认会发送给主线程（即子进程） # SIGINT 信号，触发 KeyboardInterrupt 异常 if ( not exists(self.lockfile) or mtime(self.lockfile) \u0026lt; time.time() - self.interval - 5): self.status = \u0026#34;error\u0026#34; thread.interrupt_main() for path, lmtime in list(files.items()): if not exists(path) or mtime(path) \u0026gt; lmtime: self.status = \u0026#34;reload\u0026#34; thread.interrupt_main() break time.sleep(self.interval) def __enter__(self): self.start() def __exit__(self, exc_type, *_): if not self.status: self.status = \u0026#34;exit\u0026#34; # silent exit self.join() # 这里通过判断类型来 Suppress interrupt_main() # 造成的 KeyboardInterrupt 异常，如果 __exit__ 返回 True # 则上下文管理器不会抛出异常 return exc_type is not None and issubclass(exc_type, KeyboardInterrupt) 大致的流程图如下：\nflowchart TD start([\"Start\"]) --\u003e reload_or_subproc{\"Is reloader set to True\\n or is this a child process?\"} reload_or_subproc --\u003e |Yes| subprocess[\"Spawn a subprocess\"] reload_or_subproc --\u003e |No| reload[\"Is reloader set to True?\"] subprocess --\u003e reload reload --\u003e |No| serve[\"Start serving\"] serve --\u003e if_restart{\"Need to restart?\"} if_restart --\u003e |Yes| subprocess if_restart --\u003e |No| stop([\"Stop\"]) reload --\u003e |Yes| filechecker[\"Spawn a file checker thread\"] filechecker --\u003e changes{\"Is there any changes\\n or broken lockfile?\"} changes --\u003e |Yes| if_restart changes --\u003e |No| changes 其中以 3 作为 Exit status 来标识重启的子进程，其实并不是一种标准用法（也没有固定的标准），可能算作 Python 程序的某种传统吧。\n扩展性 虽然 Bottle 已经自带了很多常用的工具，比如 Cookie 支持和文件上传，但并不妨碍在其基础上开发扩展，因为有 Hook 和 Plugin。\nHook 类似 Django 的 Middleware，可以在几个固定时机执行特定的功能，比如 before_request 和 after_request。\nPlugin 更灵活一些，也是添加 ORM 等复杂的定制化功能的最好方式。Plugin 基于视图函数执行，既可以全局生效，也能单独进行设置。对此 Bottle 定义了一整套抽象接口，这让 Plugin 不只是函数，也可以定义成复杂的对象，具体参考官方的开发文档。\n现状 虽然优点众多，但 Bottle 的没落也不是没有理由的。由于作者坚持单文件模块并且不增加额外依赖，同时又要兼容 Python 2，很大程度上限制框架的发展。不像 Flask，虽然出现得晚，这么多年来也早已发展壮大了。不过我倒是很佩服作者，让 Bottle 保持一直以来的定位：A fast, simple and lightweight WSGI micro web-framework for Python。\n即使不再流行，Bottle 背后现在仍然有一拨坚定的开发者，这离不开框架本身的实用性和过硬的代码质量。作为源代码学习的项目，Bottle 再合适不过了。而且，如果能够基于一个熟悉程度超高的 Web 框架做开发，体验也会是完全不一样的。\n向 Bottle 致敬。\nReferences\nBottle - GitHub\nBottle: Python Web Framework\nWeb Frameworks Benchmark\n","permalink":"https://iamgodot.com/posts/source-code-of-bottle/","summary":"写这篇文章最开心的一点是终于可以用这张截图了：\n相比名声在外的 Django/Flask/FastAPI，Bottle 可以说是非常不起眼了，甚至很多人并不知道它的存在。其实在很多方面，这个框架都极其优秀：\n速度：截止到 2022-04-13，Bottle 在一众 Python Web 框架的测评中名列第二，要知道这可是十年以上的老前辈了。 易用性：Bottle 早在 Flask 之前就使用了装饰器来定义路由，此外还有全局可用的 Request/Response 对象。 文档：不仅将框架本身的使用讲得很清楚，还总结了很多 Web 场景下的解决方案。 代码质量：虽然为了 Python 2 做了不少兼容，但是代码很精炼，而且 Pythonic。 其他：Bottle 坚持单模块以及无第三方库依赖；仓库仍然在积极维护中。 换作几年前，我会一开始就使用并将 Bottle 研究透彻，而不是让自己淹没在 Django 浩瀚如烟的文档中。下面开始梳理 Bottle 源码的阅读理解。因为代码量不大，所以就直接看最新的版本了：0.11.1 - 5a6c620。\nWeb 框架的基本元素 参考 The Hitchhiker\u0026rsquo;s Guide to Python 的说法，一个 Web 框架要满足的基本功能：\nURL Routing Request and Response Objects Template Engine Development Web Server 从后端的角度来讲更重要的是 1、2、4 三项，其中 1 负责转发请求到对应的视图函数，2 是对 HTTP 协议元素的解析处理，而 4 决定了服务的部署方式和基础性能。\nBottle 在这几方面都做了很好的实现：路由上提供了通配符匹配和装饰器接口；请求和响应对象作为全局对象存在并保证了线程安全；Server 部署除了 Python 自带的 wsgiref 还支持绝大多数的 WSGI Server。","title":"Bottle 框架源码阅读"},{"content":"TLS(Thread Local Storage)，或者说 Threadlocal，可以说是一种并发编程的常用模式，既实现了线程之间的资源隔离，又满足了全局变量的使用。\n从 TLS 出发，这篇文章研究了 Python 中的 Threadlocal 是如何实现的，比如自带的 threading.local，再比如 Flask 框架中 Local 对象。\nWhy Threadlocal 先思考一下为什么要用 Threadlocal，这就不得不提到线程安全。Race condition 说到底是因为数据共享和非原子操作，这可以体现在函数的两种基本写法：一种是显式地传参（参数对象也可能变化？这也是为什么最好不要传递可变对象），没有共享自然安全；另一种就是全局对象，这么写既简化了函数签名，代码也比较清晰，缺点就是很容易出现线程不安全的问题，所以经常会和锁配合使用。\n而 Threadlocal 就结合了两者的优点，在共享全局变量的同时，保证每个线程操作的都是自己独有的数据对象。\n对比一下 Django 和 Flask 两大框架就会发现，前者总是在视图函数中显式声明 request 参数，而后者的只需要 import 一次就可以到处使用。在 Flask 的文档中，Armin Ronacher 也提及了这一点：\nFor example, Flask uses thread-local objects internally so that you don’t have to pass objects around from function to function within a request in order to stay threadsafe.\n不过 Flask 并没有直接使用 Python 内置的 threading.local，而是重新做了实现。\nThreading.local Python 的threading.local 用法很简单：\nfrom threading import Thread, local mydata = local() mydata.number = 42 print(mydata.number) # 42 nums = [] def f(): mydata.number = 11 nums.append(mydata.number) t = Thread(target=f) t.start() t.join() print(nums) # [11] print(mydata.number) # 42 线程可以共享全局对象，但实际上各自维护了数据，互不影响。如何做到的呢？其实思路也很简单，在字典中给每个线程都创建单独的字典，在使用之前先切换过去，看上去好像在用同一个变量，其实内部分得很清楚。下面看看源码：\n... @contextmanager def _patch(self): ... with impl.locallock: object.__setattr__(self, \u0026#34;__dict__\u0026#34;, dct) yield class local: ... def __getattribute__(self, name): with _patch(self): return object.__getattribute__(self, name) def __setattr__(self, name, value): if name == \u0026#34;__dict__\u0026#34;: raise AttributeError( \u0026#34;%r object attribute \u0026#39;__dict__\u0026#39; is read-only\u0026#34; % self.__class__.__name__ ) with _patch(self): return object.__setattr__(self, name, value) ... 其中 local 在 get/set 的时候都偷偷地 _patch 了下，那么 _patch 又做了什么呢？原来是临时把 local 的 __dict__ 替换成了另外的从 impl 取到的 dict。其实现在已经大概能猜到了，通过把 local 的属性字典替换成当前线程自己的字典，就实现了 Threadlocal 的核心功能。现在来看 impl 的内部结构：\nclass _localimpl: __slots__ = \u0026#34;key\u0026#34;, \u0026#34;dicts\u0026#34;, \u0026#34;localargs\u0026#34;, \u0026#34;locallock\u0026#34;, \u0026#34;__weakref__\u0026#34; def __init__(self): self.key = \u0026#34;_threading_local._localimpl.\u0026#34; + str(id(self)) # { id(Thread) -\u0026gt; (ref(Thread), thread-local dict) } self.dicts = {} def get_dict(self): thread = current_thread() return self.dicts[id(thread)][1] def create_dict(self): localdict = {} key = self.key thread = current_thread() idt = id(thread) def local_deleted(_, key=key): thread = wrthread() if thread is not None: del thread.__dict__[key] def thread_deleted(_, idt=idt): local = wrlocal() if local is not None: dct = local.dicts.pop(idt) wrlocal = ref(self, local_deleted) wrthread = ref(thread, thread_deleted) thread.__dict__[key] = wrlocal self.dicts[idt] = wrthread, localdict return localdict 从第六行的注释可以看出，dicts 中保存了每个线程及其对应的字典，具体是用线程 id 对应到一个包含了线程弱引用和字典的元组。此外还有个单独的 self.key 属性，从 create_dict 方法中发现是为了给线程设置并标识 impl 本身用的。另外 wrlocal 和 wrthread 都小心地用了弱引用，这样就不影响 impl 和 thread 的内存回收，同时还会从相关字典中删除已经回收的对象（local_deleted 和 thread_deleted 作为 weakref 的 callback 函数）。\n现在再回头看看 local 其余的部分：\nclass local: __slots__ = \u0026#34;_local__impl\u0026#34;, \u0026#34;__dict__\u0026#34; def __new__(cls, /, *args, **kw): if (args or kw) and (cls.__init__ is object.__init__): raise TypeError(\u0026#34;Initialization arguments are not supported\u0026#34;) self = object.__new__(cls) impl = _localimpl() impl.localargs = (args, kw) impl.locallock = RLock() object.__setattr__(self, \u0026#34;_local__impl\u0026#34;, impl) impl.create_dict() return self 有一点不太好理解，就是为什么要改写 __new__，而且上来就做了一个异常判断，为什么不在 __init__ 中实现呢？其实这是为了支持以继承的方式来定制 local：\nclass MyLocal(local): def __init__(self, /, **kw): self.__dict__.update(kw) mydata = MyLocal(color=\u0026#39;red\u0026#39;) 在 __new__ 里 hack 让继承覆盖 __init__ 少了很多负担，又因为 local 本身是不支持参数的，所以有了一开始的异常判断。\n接下来说说 impl 的 localargs 和 locallock：\n@contextmanager def _patch(self): impl = object.__getattribute__(self, \u0026#34;_local__impl\u0026#34;) try: dct = impl.get_dict() except KeyError: dct = impl.create_dict() args, kw = impl.localargs self.__init__(*args, **kw) with impl.locallock: object.__setattr__(self, \u0026#34;__dict__\u0026#34;, dct) yield 一目了然，localargs 是在为新线程创建字典时重新初始化（对 Subclass 的情况很必要），而 locallock 自然是要保证线程安全，因为这里的 __setattr__ 与后面 local 的 get/set 操作中间可能会出现 Race condition。\n到这里代码已经分析得差不多了，不过还要解释下 __slots__。local 和 _localimpl 中都定义了 __slots__ 来限制可用属性，既可以优化内存也能保证使用安全。同时为了不影响弱引用和属性赋值，它们又在各自的 __slots__ 中分别加入了 __weakref__ 和 __dict__。当然，这对 local 的使用也产生了负影响：\nclass MyLocal(local): __slots__ = \u0026#39;number\u0026#39; mydata = MyLocal() mydata.number = 42 # 这里的 number 是所有线程共享的 这是因为 __slots__ 中的属性是由数据修饰符来控制的，不在 __dict__ 中保存，因此 _patch 无法产生效果。\nContext Locals 现在要说说 Flask 使用 Threadlocal 的思路，前面提到，这样的好处是不用到处传参，但必须要保证线程安全。然而对于一个 Web 框架来说，还需要考虑更多：\nThis approach, however, has a few disadvantages. For example, besides threads, there are other types of concurrency in Python. A very popular one is greenlets. Also, whether every request gets its own thread is not guaranteed in WSGI. It could be that a request is reusing a thread from a previous request, and hence data is left over in the thread local object.\n除了 greenlet，同一个线程也可能被用于处理多个请求，那么 threading.local 就不够用了，Flask 也因此重新做了实现（其实是 Werkzeug）。下面看一下源码：\ntry: from greenlet import getcurrent as get_ident except ImportError: try: from thread import get_ident except ImportError: from _thread import get_ident class Local(object): __slots__ = (\u0026#34;__storage__\u0026#34;, \u0026#34;__ident_func__\u0026#34;) def __init__(self): object.__setattr__(self, \u0026#34;__storage__\u0026#34;, {}) object.__setattr__(self, \u0026#34;__ident_func__\u0026#34;, get_ident) def __iter__(self): return iter(self.__storage__.items()) def __call__(self, proxy): \u0026#34;\u0026#34;\u0026#34;Create a proxy for a name.\u0026#34;\u0026#34;\u0026#34; return LocalProxy(self, proxy) def __release_local__(self): self.__storage__.pop(self.__ident_func__(), None) def __getattr__(self, name): try: return self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): ident = self.__ident_func__() storage = self.__storage__ try: storage[ident][name] = value except KeyError: storage[ident] = {name: value} def __delattr__(self, name): try: del self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) 相比 threading.local 这个版本简单了不少，首先尝试 import greenlet 的 get_ident 方法作为内部的 __ident_func__，如果失败再 fallback 到线程上面，这就解决了 greenlet 的问题。而对于请求复用线程的情况还引入了 LocalManager：\nclass LocalManager(object): def __init__(self, locals=None, ident_func=None): if locals is None: self.locals = [] elif isinstance(locals, Local): self.locals = [locals] else: self.locals = list(locals) if ident_func is not None: self.ident_func = ident_func for local in self.locals: object.__setattr__(local, \u0026#34;__ident_func__\u0026#34;, ident_func) else: self.ident_func = get_ident def get_ident(self): return self.ident_func() def cleanup(self): for local in self.locals: release_local(local) def make_middleware(self, app): def application(environ, start_response): return ClosingIterator(app(environ, start_response), self.cleanup) return application 简单来说就是线程在处理完 WSGI 请求之后会调用 cleanup 方法来保证 release_local 的执行，这样会把之前的数据字典从 local 中删除，然后在下一个请求中重新创建。\n相比 threading.local 这种实现更直接明了，当然前者也是为了支持 Subclass 等功能和更底层的优化，归根到底是由不同的需求决定的。\nContext Variable 除了线程和 greenlet，还有协程，如此一来上面那一套也不够用了。怎么办？Python 3.7 推出了 contextvars 这个库来保证异步任务执行的上下文隔离，不管是线程还是协程都可以直接用它做到类似 Threadlocal 的事情。\n所以 Werkzeug 从 2.x 版本开始也使用 ContextVar 来实现 Local 了：\nfrom contextvars import ContextVar class Local: __slots__ = (\u0026#34;_storage\u0026#34;,) def __init__(self) -\u0026gt; None: object.__setattr__(self, \u0026#34;_storage\u0026#34;, ContextVar(\u0026#34;local_storage\u0026#34;)) def __iter__(self) -\u0026gt; t.Iterator[t.Tuple[int, t.Any]]: return iter(self._storage.get({}).items()) def __call__(self, proxy: str) -\u0026gt; \u0026#34;LocalProxy\u0026#34;: \u0026#34;\u0026#34;\u0026#34;Create a proxy for a name.\u0026#34;\u0026#34;\u0026#34; return LocalProxy(self, proxy) def __release_local__(self) -\u0026gt; None: self._storage.set({}) def __getattr__(self, name: str) -\u0026gt; t.Any: values = self._storage.get({}) try: return values[name] except KeyError: raise AttributeError(name) from None def __setattr__(self, name: str, value: t.Any) -\u0026gt; None: values = self._storage.get({}).copy() values[name] = value self._storage.set(values) def __delattr__(self, name: str) -\u0026gt; None: values = self._storage.get({}).copy() try: del values[name] self._storage.set(values) except KeyError: raise AttributeError(name) from None 代码相比之前更加简洁，而且外部接口完全不变。\nThe End 可以想象，Threadlocal 的写法是从线程安全和代码简洁等需求中演变而来的。理解了这些，就能更好地在设计开发中做出正确的选择。\nThread-Locals in Flask Context Locals - Werkzeug Contextvars - Python Docs ","permalink":"https://iamgodot.com/posts/sourcecode-of-python-threadlocal/","summary":"TLS(Thread Local Storage)，或者说 Threadlocal，可以说是一种并发编程的常用模式，既实现了线程之间的资源隔离，又满足了全局变量的使用。\n从 TLS 出发，这篇文章研究了 Python 中的 Threadlocal 是如何实现的，比如自带的 threading.local，再比如 Flask 框架中 Local 对象。\nWhy Threadlocal 先思考一下为什么要用 Threadlocal，这就不得不提到线程安全。Race condition 说到底是因为数据共享和非原子操作，这可以体现在函数的两种基本写法：一种是显式地传参（参数对象也可能变化？这也是为什么最好不要传递可变对象），没有共享自然安全；另一种就是全局对象，这么写既简化了函数签名，代码也比较清晰，缺点就是很容易出现线程不安全的问题，所以经常会和锁配合使用。\n而 Threadlocal 就结合了两者的优点，在共享全局变量的同时，保证每个线程操作的都是自己独有的数据对象。\n对比一下 Django 和 Flask 两大框架就会发现，前者总是在视图函数中显式声明 request 参数，而后者的只需要 import 一次就可以到处使用。在 Flask 的文档中，Armin Ronacher 也提及了这一点：\nFor example, Flask uses thread-local objects internally so that you don’t have to pass objects around from function to function within a request in order to stay threadsafe.\n不过 Flask 并没有直接使用 Python 内置的 threading.","title":"Python 中的 TLS 是如何实现的"},{"content":"阅读了源码之后，我对 Python Logging 模块的几大疑惑都得到了解答：\n为什么 Logger 和 Handler 都有 setLevel 方法？\nLogging 中会出现 Race condition 吗？（感觉都是很直接的 write 操作）\n正式环境中想看日志又没办法动态调整 logLevel，感觉很鸡肋。\n用起来好像还不如 print 方便。\n会有性能问题吗？\n日常使用 首先要了解下 Logging 的用法。\n1. 配置 基本上有三种方式，代码、文件和字典。先看下如何用代码设置：\nimport logging # create logger logger = logging.getLogger(\u0026#39;simple_example\u0026#39;) logger.setLevel(logging.DEBUG) # create console handler and set level to debug ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) # create formatter formatter = logging.Formatter(\u0026#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s\u0026#39;) # add formatter to ch ch.setFormatter(formatter) # add ch to logger logger.addHandler(ch) Logging 的接口很多都是 camelCase 而非 snake_case，应该有历史原因。另外注意 setFormatter 和 addHandler 这种用词的区别，说明 Handler 的 Formatter 只能有一个，而 Logger 可以添加多个 Handler。\n第二种是文件，使用 fileConfig 接口读取，这里要求文件使用符合 ConfigParser 的格式。\n最后是利用 dictConfig 来读取一个字典，这就提供了使用 json/yaml 作为配置文件的可能，也是比较常用的一种方式。\n当然如果不做任何自定义配置也是可以 Logging 的，这时默认会将日志输出到 sys.stderr 并且 logLevel 为 WARNING。\n2. 日志打印 像 debug/info/warning/error 这些方法都会创建对应 logLevel 的日志对象，不过 exception 特殊一点，相当于 error，但是会打印额外的异常信息。\nLogging 本身的操作一般不会导致异常，但如果出现（比如配置错误或者打日志方法传入的字符串 格式化出错），除了 SystemExit 和 KeyboardInterrupt 之外，都会由 Handler 来处理：默认不会抛出，而是将错误打印到 sys.stderr。这种行为是由 logging.raiseExceptions 来控制的，也可以设置为 False，这样就会把异常直接吞掉。\n3. 更多用法 最后还有一些进阶的用法，比如自定义日志对象，可以通过定制的 Filter 添加额外的日志信息：\nimport logging from random import choice class ContextFilter(logging.Filter): \u0026#34;\u0026#34;\u0026#34; This is a filter which injects contextual information into the log. Rather than use actual contextual information, we just use random data in this demo. \u0026#34;\u0026#34;\u0026#34; USERS = [\u0026#39;jim\u0026#39;, \u0026#39;fred\u0026#39;, \u0026#39;sheila\u0026#39;] IPS = [\u0026#39;123.231.231.123\u0026#39;, \u0026#39;127.0.0.1\u0026#39;, \u0026#39;192.168.0.1\u0026#39;] def filter(self, record): record.ip = choice(ContextFilter.IPS) record.user = choice(ContextFilter.USERS) return True 代码分析 通过画图可以快速熟悉代码中的设计，比如用流程图来展示 Logging 的执行过程：\nflowchart TB Start([\"Start Logging call e.g. Logger.info(...)\"]) --\u003e LoggerLevel{\"Is current\\n level disabled?\"} LoggerLevel --\u003e |No| Stop([\"Stop\"]) LoggerLevel --\u003e |Yes| LogRecord[\"Create log record\"] LogRecord --\u003e Filter{\"Should the record\\n be filtered?\"} Filter --\u003e |Yes| Stop Filter --\u003e |No| Handler subgraph Handler[\"Handle for current logger\"] Lock[\"Acquire RLock\"] --\u003e Emit[\"Format log and write to stream\"] end Handler --\u003e Propagate{\"Should propagate\\n for current logger?\"} Propagate --\u003e |No| Stop Propagate --\u003e |Yes| ParentLogger{\"Is there a\\n parent logger?\"} ParentLogger --\u003e |No| Stop ParentLogger --\u003e |Yes| SetCurrentLogger[\"Set parent logger as current\"] SetCurrentLogger --\u003e Handler 用类图表达各个 Class 之间的关系：\nclassDiagram direction TB Filterer \u003c|-- Logger Filterer \u003c|-- Handler LoggerAdapter \"1\" *-- \"1\" Logger Manager \"1\" *-- \"1..*\" Logger Logger \u003c|-- RootLogger Logger \"1\" *-- \"*\" Filter Logger \"1\" *-- \"*\" Handler Handler \"1\" *-- \"1\" Formatter Handler \u003c-- LogRecord Handler \u003c|-- StreamHandler StreamHandler \u003c|-- FileHandler Formatter \u003c-- LogRecord Filter \u003c-- LogRecord class Manager{ +Logger root +Int disable +Dict loggerDict +getLogger() -_fixupParent() -_fixupChildren() -_clear_cache() } class LoggerAdapter{ +Logger logger +process() +debug/info/warning/error/...() } class Filterer{ +List filters +addFilter() +removeFilter() +filter() } class Logger{ +debug/info/warning/error/...() +isEnabledFor() -_log() +makeRecord() +handle() +addHandler() } class Handler{ -Str _name +Formatter formatter +RLock lock +acquire() +release() +handle() +emit() +flush() +handleError() } class StreamHandler{ +stream +setStream() } class FileHandler{ +filename +name +encoding } class Filter{ +Str name +filter() } class Formatter{ -_fmt -_style +datefmt +format() +formatTime() +formatMessage() +formatException() +formatStack() } class LogRecord{ +Str name +Str msg +args +getMessage() } 至此可以比较清晰地了解日志过程中 Logger/Filter/Handler/Formatter 几个组件之间的交互了。Logging 的实现非常 OOP，但并不是很 Pythonic，比如一些不必要的 Setter/Getter、本应该却没有使用 with 的地方（大量线程锁的获取和释放）、camelCase 的函数命名等等。不过鉴于这个模块出现得很早，可能也背了不少历史包袱吧。\n1. 线程安全 模块中有不少全局的数据结构变量，这也解释了为什么要保证线程安全，比如 logLevel：\nCRITICAL = 50 FATAL = CRITICAL ERROR = 40 WARNING = 30 WARN = WARNING INFO = 20 DEBUG = 10 NOTSET = 0 _levelToName = { CRITICAL: \u0026#39;CRITICAL\u0026#39;, ERROR: \u0026#39;ERROR\u0026#39;, WARNING: \u0026#39;WARNING\u0026#39;, INFO: \u0026#39;INFO\u0026#39;, DEBUG: \u0026#39;DEBUG\u0026#39;, NOTSET: \u0026#39;NOTSET\u0026#39;, } _nameToLevel = { \u0026#39;CRITICAL\u0026#39;: CRITICAL, \u0026#39;FATAL\u0026#39;: FATAL, \u0026#39;ERROR\u0026#39;: ERROR, \u0026#39;WARN\u0026#39;: WARNING, \u0026#39;WARNING\u0026#39;: WARNING, \u0026#39;INFO\u0026#39;: INFO, \u0026#39;DEBUG\u0026#39;: DEBUG, \u0026#39;NOTSET\u0026#39;: NOTSET, } 还有 Handlers：\n_handlers = weakref.WeakValueDictionary() #map of handler names to handlers _handlerList = [] # added to allow handlers to be removed in reverse of order initialized 线程锁的使用主要在两处，一是全局范围的，保证像上面这两种全局变量的安全读写：\n#_lock is used to serialize access to shared data structures in this module. #This needs to be an RLock because fileConfig() creates and configures #Handlers, and so might arbitrary user threads. Since Handler code updates the #shared dictionary _handlers, it needs to acquire the lock. But if configuring, #the lock would already have been acquired - so we need an RLock. #The same argument applies to Loggers and Manager.loggerDict. # _lock = threading.RLock() def _acquireLock(): if _lock: _lock.acquire() def _releaseLock(): if _lock: _lock.release() 如注释所说，因为 fileConfig() 时会重复上锁，需要 Re-entrant lock；另外一处在 Handler 内部：\nclass Handler(Filterer): def createLock(self): \u0026#34;\u0026#34;\u0026#34; Acquire a thread lock for serializing access to the underlying I/O. \u0026#34;\u0026#34;\u0026#34; self.lock = threading.RLock() _register_at_fork_reinit_lock(self) def handle(self, record): rv = self.filter(record) if rv: self.acquire() try: self.emit(record) finally: self.release() return rv 很明显，这里是为了保证 I/O 操作的原子性而上锁，不过似乎用普通的 Mutex 也是可以的。需要注意的是，这里的原子操作只针对一个线程 + 一个文件描述符的场景，如果有两个线程分别打开同一个文件日志的话是存在乱写的可能的，也就是 garble。同理，在多进程下 Logging 是不安全的，比较保险的做法是使用额外的全局锁（效率低）或者 QueueHandler。其实如果不写入文件直接输出到 sys.stderr 问题并不大，即使出现 garble（概率很低）影响也很小，在应用容器之外再做日志收集和聚合就好了。\n为了尽量保证 I/O 不出现 garble，Handler 也尽量做了优化，比如 StreamHandler 的 emit 方法：\nclass StreamHandler(Handler): def emit(self, record): try: msg = self.format(record) stream = self.stream # issue 35046: merged two stream.writes into one. stream.write(msg + self.terminator) # 使用一次 write 操作 self.flush() # 及时清空 buffer 内容 except RecursionError: # See issue 36272 raise except Exception: self.handleError(record) 2. Logger 结构 Logging 对于 Loggers 的结构设计有点类似前缀树。首先是存在一个 Root logger 作为根节点的，这也是为什么可以直接用 import logging;logging.info(...)；其次 name 不为空的 Logger 会按照 . 来切割，比如 a.b.c 这个 Logger 可以被划分为三层，a 和 a.b 这两个 Logger 如果存在的话则作为 a.b.c 的 parent，如果不存在则初始化为 PlaceHolder 占位；最后，每定义一个 Logger 都会创建对应的节点并更新上下游的父子节点。这些逻辑都被封装在 Manager 类中，简单看下代码（这里也可以看出全局线程锁的应用）：\nclass Manager(object): def getLogger(self, name): rv = None if not isinstance(name, str): raise TypeError(\u0026#39;A logger name must be a string\u0026#39;) _acquireLock() try: if name in self.loggerDict: rv = self.loggerDict[name] if isinstance(rv, PlaceHolder): ph = rv rv = (self.loggerClass or _loggerClass)(name) rv.manager = self self.loggerDict[name] = rv self._fixupChildren(ph, rv) self._fixupParents(rv) else: rv = (self.loggerClass or _loggerClass)(name) rv.manager = self self.loggerDict[name] = rv self._fixupParents(rv) finally: _releaseLock() return rv # 这两个方法会在创建 Logger 时更新相关的父子节点 def _fixupParents(self, alogger): \u0026#34;\u0026#34;\u0026#34; Ensure that there are either loggers or placeholders all the way from the specified logger to the root of the logger hierarchy. \u0026#34;\u0026#34;\u0026#34; name = alogger.name i = name.rfind(\u0026#34;.\u0026#34;) rv = None while (i \u0026gt; 0) and not rv: substr = name[:i] if substr not in self.loggerDict: self.loggerDict[substr] = PlaceHolder(alogger) else: obj = self.loggerDict[substr] if isinstance(obj, Logger): rv = obj else: assert isinstance(obj, PlaceHolder) obj.append(alogger) i = name.rfind(\u0026#34;.\u0026#34;, 0, i - 1) if not rv: rv = self.root alogger.parent = rv def _fixupChildren(self, ph, alogger): \u0026#34;\u0026#34;\u0026#34; Ensure that children of the placeholder ph are connected to the specified logger. \u0026#34;\u0026#34;\u0026#34; name = alogger.name namelen = len(name) for c in ph.loggerMap.keys(): #The if means ... if not c.parent.name.startswith(nm) if c.parent.name[:namelen] != name: alogger.parent = c.parent c.parent = alogger 像 logging.getLogger 实际上就是用的这里提供的接口，除此之外在 propagate 的时候也是通过 Manager 来定位 Parent logger。\n3. 设置 logging level Handler 的 setLevel 其实没什么用，不像 Logger 会使用 logLevel 来辅助判断是否 enabled，Handler 最多在 repr 时打印一下，不过这样设计又会造成两者的 logLevel 不一致，总之使用时以 Logger 为准就好了。\n另外其实在 Logging 的设计中 logLevel 虽然有预设，但是是可以自定义的。大概可能是默认设置已经很够用了，还没见到过哪里真的去做定制的。\n最后，不得不说，Logging 的注释非常详细，甚至有过度解释代码的嫌疑，不过作为这么古老的基础模块，可能也不是一件坏事。\n一些结论 除了代码，Logging 的官方文档也介绍了许多场景下的 Best practice。\n如果想在应用运行过程中更改配置，那么一种简单的实现是使用 fileConfig 并开启额外的端口来监听文件内容的变化。当然如果从更高层的角度来考虑，解决办法还有很多，比如在 Redis 中保存配置，再单独启动一个 Worker 来订阅更新并在变动时重新设置。\n还有关于性能的优化。另外注意不要初始化太多的 Logger，因为这些实例是不会自动 GC 的（正常来说按模块来初始化就够了，比如logger = logging.getLogger(__name__)，这样也正好合理利用了模块的名称来划分 Logger 层级）。如果有需要的话，可以考虑使用 LoggerAdapter 来维护额外的上下文信息。\n最后，到底选择 Logging 还是 print？除了这里提到的，如果涉及到多线程的场景，前者会更安全一些。而 print 简单好用，还不需要额外 import。所以很简单，一切选择都应当以实际场景为准，没有绝对的好坏和对错。\nReferences\nLogging HOWTO - Python Docs Logging Cookbook - Python Docs Logging - The Hitchhiker\u0026rsquo;s Guide to Python ","permalink":"https://iamgodot.com/posts/sourcecode-of-python-logging/","summary":"阅读了源码之后，我对 Python Logging 模块的几大疑惑都得到了解答：\n为什么 Logger 和 Handler 都有 setLevel 方法？\nLogging 中会出现 Race condition 吗？（感觉都是很直接的 write 操作）\n正式环境中想看日志又没办法动态调整 logLevel，感觉很鸡肋。\n用起来好像还不如 print 方便。\n会有性能问题吗？\n日常使用 首先要了解下 Logging 的用法。\n1. 配置 基本上有三种方式，代码、文件和字典。先看下如何用代码设置：\nimport logging # create logger logger = logging.getLogger(\u0026#39;simple_example\u0026#39;) logger.setLevel(logging.DEBUG) # create console handler and set level to debug ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) # create formatter formatter = logging.Formatter(\u0026#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s\u0026#39;) # add formatter to ch ch.","title":"Python Logging 源码分析"},{"content":"好久没有更新了，最近研究了下如何用 Python 实现 Pager 的功能，这里指的是 Terminal 中的 Paging 程序，比如 less。\nWhy Pager Pager 在大段文字的展示中很常见，比如 Linux 的 man page，而 $PAGER 就是用来指定默认 Paging 程序的环境变量。Python shell 里面的 help() 会默认翻页显示，IPython 的 ? 则更胜一筹，能够判断当前屏幕的可用空间来决定是否 Paging。\nLess 应该算是最流行的 Pager 了，相比于 more，它同时支持前进和后退翻页，而且因为不需要一次性读取整个文件，它的启动速度在打开大型文件时要远远快于 vi。因此，许多 Pager 都是通过启动系统自带的 less 程序来实现。\nDon\u0026rsquo;t Reinvent the Wheel 轮子总是有的，而且还很多，这里说几个比较好用的：\nPydoc 的 pager Click 的 echo_via_pager IPython 的 page Pydoc 是 Python 自带的，已经稳定存在了很多年，轻巧好用；Click 的实现类似，而且支持传入一个 generator；IPython 的 page 更加强大，可以自动判断当前的屏幕大小，再结合一个 screen_lines 参数来计算最终的可用空间。\n再说说这几个轮子的实现，基本思路都是上面提到的调用系统 Pager。因为要兼容五花八门的操作系统，大致上又分为三种处理方式：\n理想情况下是使用 PIPE。因为打开的系统 Pager 必然是子进程，而 PIPE 通过内存中的缓冲区实现了 IPC，这样既不用一次性读取所有数据，后续的 write 操作效率也高。\n如果 PIPE 不可用，那就需要先建立临时文件，把数据写入，最后再启动 Pager 直接打开文件。\n保底的方案是直接向标准输出写入文本数据，这种做法一般只会出现在非 tty 的设备上。\n另外 IPython 内部使用了 curses 库来检测屏幕大小，如果传入的 screen_lines 小于等于 0，就会加上检测结果的值作为最终的可用行数。从官方文档上看 Windows 的 Python 没有 curses，但提供了 ported version 的 UniCurses，不知道 IPython 的屏幕检测在 Windows 的表现如何。\nClick 虽然没有直接使用 Pydoc，但实现基本和后者相同；而 IPython 的轮子是从头造起，质量很高，值得一看。\nDo it Yourself 抛开那些杂乱的系统判断的部分，直接实现一个调用 less 的 Pager 还是很简单的。大致代码如下：\nfrom subprocess import PIPE, Popen def pager(text: str): proc = Popen( \u0026#39;less\u0026#39;, shell=True, stdin=PIPE, text=True, ) proc.communicate(text) 这样会一次性把文本写入到 PIPE 中，对于一个生成器来说，不断迭代出新内容并写入会更高效：\nfrom subprocess import PIPE, Popen def pager(generator): proc = Popen( \u0026#39;less\u0026#39;, shell=True, stdin=PIPE, text=True, ) try: for text in generator: proc.stdin.write(text) except (OSError, KeyboardInterrupt): pass else: proc.stdin.close() proc.wait() 虽然代码不麻烦，但在使用 subprocess 这个库的过程中踩了许多坑，需要对着文档来回确认。比如上面的 Popen 中的 text 参数是为了控制文本模式打开文件，但如果不传而是直接指定 encoding 或 errors 的话也会默认使用文本打开。。\n下面再啰嗦几句 subprocess，如果没兴趣可以跳过：\n现在的 Higher API 只关注 run() 就好了，以前的 call/check_call/check_output 都可以忽略，run() 中都提供对应参数 需要和子进程交互的话用 Popen() 对于不指定 shell 的 Popen() 字符串作为命令：命令中无法携带参数，只可以这样 Popen('echo', ...) 列表作为命令：所有元素会合在一起，所以可以 Popen(['echo', 'foo', 'bar']) 如果命令出错或不存在会直接触发 FileNotFound 异常 对于 shell=True 的 Popen() 官方文档直接推荐使用字符串，原因见下一行 如果使用列表的话，只有第一个元素作为命令内容，其他的都会读取为 shell 的参数 不会引发 FileNotFound 异常而是输出到 stderr 槽点满满，一开始用起来痛不欲生，不过也可能是这个库的历史包袱太重了吧。\n小小的 Pager 并不难，但兼容各种 OS 和 Terminal 真的也需要勇气，更不用说有时候 I/O 操作也表现不一。生活不易，对于这种底层功能，真的不如拿来主义呀。\n","permalink":"https://iamgodot.com/posts/about-pager/","summary":"好久没有更新了，最近研究了下如何用 Python 实现 Pager 的功能，这里指的是 Terminal 中的 Paging 程序，比如 less。\nWhy Pager Pager 在大段文字的展示中很常见，比如 Linux 的 man page，而 $PAGER 就是用来指定默认 Paging 程序的环境变量。Python shell 里面的 help() 会默认翻页显示，IPython 的 ? 则更胜一筹，能够判断当前屏幕的可用空间来决定是否 Paging。\nLess 应该算是最流行的 Pager 了，相比于 more，它同时支持前进和后退翻页，而且因为不需要一次性读取整个文件，它的启动速度在打开大型文件时要远远快于 vi。因此，许多 Pager 都是通过启动系统自带的 less 程序来实现。\nDon\u0026rsquo;t Reinvent the Wheel 轮子总是有的，而且还很多，这里说几个比较好用的：\nPydoc 的 pager Click 的 echo_via_pager IPython 的 page Pydoc 是 Python 自带的，已经稳定存在了很多年，轻巧好用；Click 的实现类似，而且支持传入一个 generator；IPython 的 page 更加强大，可以自动判断当前的屏幕大小，再结合一个 screen_lines 参数来计算最终的可用空间。\n再说说这几个轮子的实现，基本思路都是上面提到的调用系统 Pager。因为要兼容五花八门的操作系统，大致上又分为三种处理方式：\n理想情况下是使用 PIPE。因为打开的系统 Pager 必然是子进程，而 PIPE 通过内存中的缓冲区实现了 IPC，这样既不用一次性读取所有数据，后续的 write 操作效率也高。","title":"关于 Pager"},{"content":"def f1(): l = [] def c(): l.append(1) def f2(): a = 1 def c(): print(a) a = 2 类似 f1 和 f2 中的闭包写法，之前总是在用了前者多次之后，再写后一种就报错，感觉很莫名其妙，明明都差不多。研究了下发现，其实这是 Python 闭包的 BugFeature，理解之后反而觉得这样的设计是合理的。\n首先说 Closure，也就是闭包，特指内部的函数及其引用的超出本身作用域的对象，总是在函数嵌套时发生。在 f1 中，c 就是一个闭包函数，同时 l 也算作其中的一部分。因为 c 使用了 l 导致延伸了原有的作用域，所以才有闭包的产生。\n再看 f2，如果我们只对 a 做 read 操作是不会引发问题的，由于 c 中尝试了赋值操作，才导致了 UnboundLocalError. 这是因为 Python 解释器会假定函数中赋值的变量是局部变量，而 c 中本身并没有定义 local 的 a 变量；其次，异常在 print(a) 时就会抛出，不会等到 a = 2 的执行。\n那为什么 f1 没问题呢，是因为列表为可变对象，append 操作只是更新了里面的内容，并不存在赋值。\ndef f(): l = [] def c(): l.append(1) return c 像上面这样，我们可以通过执行 f 得到闭包函数 c. 此时 f 已经执行完毕，它的作用域也随之消失，l 则作为自由变量绑定到了 c 上。和 c 关联的所有自由变量名称都可以在 c.__code__.co_freevars 中看到，而真正的对象则保存在 c.__closure__ 里面。\n怎样才能给这些自由变量赋值呢？Python 提供了 nonlocal 关键字，顾名思义，它表示一个变量来自外层函数，此时再进行赋值就不会出现前面的问题了：\ndef f(): a = 1 def c(): nonlocal a print(a) a = 2 其实除了 nonlocal 之外还有个 global 关键字，目的是指定使用 Global 命名空间的变量，也就是一个模块（文件）的作用域下。\n作用域可以简单理解成变量的作用范围，a = [] 这样的赋值语句把变量 a 和列表对象做了绑定，之后 a 这个名称可以使用的范围就是它的作用域。而同一层作用域的所有绑定了的变量名和对象都存放在一个数据结构内，即命名空间，Python 的命名空间就是 Dict 来实现的。\n包括 Global，Python 一共有 LEGB 四大命名空间，一圈圈扩大，但是不相互覆盖：\nLocal: 函数内部 Enclosing: 闭包内部 Global: 模块内部 Builtin: 内建的函数和其他对象 还有一点要注意的是，和函数不同，在类的内部是无法使用闭包的，必须要以 self.a 或者 cls.a 的方式来引用类变量。\nReferences\nFluent Python ","permalink":"https://iamgodot.com/posts/closure-in-python/","summary":"def f1(): l = [] def c(): l.append(1) def f2(): a = 1 def c(): print(a) a = 2 类似 f1 和 f2 中的闭包写法，之前总是在用了前者多次之后，再写后一种就报错，感觉很莫名其妙，明明都差不多。研究了下发现，其实这是 Python 闭包的 BugFeature，理解之后反而觉得这样的设计是合理的。\n首先说 Closure，也就是闭包，特指内部的函数及其引用的超出本身作用域的对象，总是在函数嵌套时发生。在 f1 中，c 就是一个闭包函数，同时 l 也算作其中的一部分。因为 c 使用了 l 导致延伸了原有的作用域，所以才有闭包的产生。\n再看 f2，如果我们只对 a 做 read 操作是不会引发问题的，由于 c 中尝试了赋值操作，才导致了 UnboundLocalError. 这是因为 Python 解释器会假定函数中赋值的变量是局部变量，而 c 中本身并没有定义 local 的 a 变量；其次，异常在 print(a) 时就会抛出，不会等到 a = 2 的执行。\n那为什么 f1 没问题呢，是因为列表为可变对象，append 操作只是更新了里面的内容，并不存在赋值。\ndef f(): l = [] def c(): l.","title":"Python 中的闭包"},{"content":"Auth 代表了 Authentication 和 Authorization 两个概念，也就是认证与授权。基于 HTTP，两者得以遵循一定的标准，SSL/TLS 之后，又出现了 OAuth 2.0，让授权也简单了许多。\nAuthentication 认证相对来说比较直接，核心就是对 Credential(e.g. username/password) 的验证。HTTP 提供了多种认证方案，比如最常见的 Basic auth, Digest access 和 Bearer.\nBasic auth 具体来说就是服务器用 WWW-Authenticate 表示需要认证，比如 WWW-Authenticate: Basic realm='Accessing to xx site'，客户端则通过 Authorization 提供相关信息：Authorization: Basic Zm9vOmJhcg==，后面的一串编码是对用户名密码明文进行 base64 的结果，即可以直接从中 decode 出原始信息 foo:bar. 没有 HTTPS 的保护，这样很不安全，所以 Apache/Nginx 对 BA 的实现都会使用密码的哈希结果而不是原文，拿后者举例：\nhttp { server { location / { auth_basic \u0026#34;Accessing to xx site\u0026#34;; auth_basic_user_file /path/to/authfile; } } } 然后需要在 authfile 中保存 username/password pair，比如 sudo htpasswd -c /path/to/authfile user1，htpasswd 是 Apache 提供的专门用来生成 BA 使用的 Credential file 的工具。不用额外安装，我们直接用 openssl 代替：\n$ openssl passwd -apr1 foobar $apr1$BICE9LF.$9wYc.j1KyU/2/UtBg8l2W. $ openssl passwd -apr1 -salt BICE9LF. $apr1$BICE9LF.$9wYc.j1KyU/2/UtBg8l2W. 第一行的 apr1 表示使用 Apache 变种的 MD5 哈希算法，生成的结果被 $ 分隔为三部分，第二部分是随机生成的 salt，最后是哈希结果。所以第二行里，如果我们用同样的 salt 去生成就会得到相同的哈希值。\nDigest access BA 在简单的场景下配合 HTTPS 还是可以用的，哈希则给密码保护提供了新的校验思路，比如用户只需要传递密码的哈希值，再比如服务端不保存密码明文。哈希的好处包括单向（防止泄露）、简短（做摘要、签名）和变化（加 salt 可以有效对抗彩虹表），而服务器只要比较计算结果是否一致就达到了校验的目的，这样就形成了 HTTP 的 Direct Access 机制：服务端提供 nonce 和 qop(quality of protection) 参数给客户端，客户端按需生成结果返回。\nHA1 = MD5(username:realm:password) HA2 = MD5(method:digestURI) response = MD5(HA1:nonce:HA2) 根据参数的不同，HA 也要调整，比如如果 qop 指定了 auth-init，那么 HA2 就要变成 HA2 = MD5(method:digestURI:MD5(entityBody)). Header 中也要体现 Digest 的使用，比如客户端会返回 Authorization: Digest username='...', realm='...', response='...' .... 总的来说，DA 的方式不需要 HTTPS 也能够有效地保护密码安全，但是仍然阻挡不了中间人的攻击方式，因为客户端无法确认服务端的真正身份。\n调用认证 上面说的是登录认证，此外还有调用认证，比如 API. 对于泄露、篡改和伪装这三大安全问题，调用认证明显更需要防范篡改的攻击方式，此时签名技术就出现了：MAC(Message Authentication Code)，也就是对消息做摘要，以此保证其中的内容没有改动。哈希自然很适合这项工作，所以 HMAC(Hash-based MAC) 也出来了。\nMAC 有个前提是通信双方共享了某个 Secret key，而在 HMAC 相当于 Salted hashing，其中的 Salt 就是用到了 Secret key. 也就是说这类似于对称加密，服务器和用户在通信之前需要先商量好密钥。举例来说，这相当于你先注册或登录 AWS/阿里云/腾讯云的帐号，在里面创建了子帐户，此时你会得到密钥对 AppID/AppSecretKey，这个 AppSecretKey 就是给 HMAC 用的，而 AppID 标识了密钥在你的帐号下面。这样一来，权限的粒度也通过密钥对变得更小了，一个帐号下面可以开通多个 App，每个都对应不同的权限范围。\n也许 TLS 之前这种实现带来的安全保障是必要的，但现在再看这种复杂的认证流程实在觉得没有必要，用起来也麻烦，可能对于过于庞大的权限管理体系来说，复杂本身也是一种防护吧。看看 GitHub 的 OAuth APP 就感觉现代了很多，使用也很方便。\n登录凭证 除了用户名密码本身，为了增强安全性还需要其他的辅助验证，比如 2FA. 现在很多 App 都支持类似的功能，比如 GitHub/Dropbox/Discord，不过要注意 Auth app 的数据备份，之前我的 Google Authenticator 就陷入了无法找回的情况，痛定思痛之后，便改用了 Authy，这样更方便在新设备上同步。\nCredential 的校验一般只是认证的前半部分，通过之后服务器会签发一个凭证给用户，之后一段时间内便不再需要验证了。这么做的主要原因就是为了方便，因为场景中总是存在会话，没人喜欢在过程中每次都要输入密码，类似 sudo. API 调用认证就不会这么做，原因也是没有明显的会话场景。说回凭证，通常是以 Token 的形式出现，HTTP 的认证框架中的 Bearer Auth 就是把 Token 放在 Header 中传递的：Authorization: Bearer .... 当然 Bearer 主要是为了配合 OAuth 2.0，凭证也不一定就是 Token，有两种方式：\nCookie: 客户端把 SessionID 放在 Cookie 里面，服务器收到之后检查是否有对应的 Active session. 这样服务端可以完全控制 Session，但你知道，Cookie 的限制是很多的 Token: 状态信息都保存在 Token 里，所以服务器是 Stateless 的（至少对于认证来说）。客户端可以把 Token 放在 Header(standarized) 或者 Payload 里发送。好处很明显，服务端减了负，但是控制上就减弱了，比如不能随时 Invalidate 一个 Token; 另外就是 Token 不受局限，可以直接跨域 JWT 是一种很流行的 Token-based 的解决方案，简单来说就是校验通过发给客户端 Token，之后只需要检查 Token 合法性就好了，其中还可以设置 scope 和 expiration. 当然用 JWT 也会遇到控制不足的问题，一种解决办法是 Invalidate refresh token，然后等待 access token 过期（这就要求 expiration 不能太长）。如果有更复杂的需求，可能还是要自定义实现 Token.\nAuthorization 以上是认证，再来说授权。其实这两者本来就不分家，只是为了做好权限粒度上的区分，巨头拆出了后者给小公司们用。说实话哪里需要实现自己的用户名密码认证登录，直接提供 Google/FB/Wechat 第三方登录就好了，或者干脆像 TG 那样直接用手机号码。根本没有人想多记一个帐号密码啊。\n说回授权，也就是 OAuth 2.0，是一系列精心定义的授权流程，有很多 Flow，但核心其实都在 Authorization Code 这一种里面。比如我做了一个 App，想要支持 GitHub 登录，那么我要先到 GH 注册，得到 ClientID/ClientSecret，可以对照前面提到的 AppID/AppSecretKey. 那么用户在 App 上点击登录，就会先跳到 GH 页面，同意授权之后，跳回 App 同时返回一个 code，那么我的 App 利用这个 code 再结合 ClientSecret 请求 GH 的 access token. 这个过程也不复杂，重点有两个，一是注册得到的密钥对，尤其是 ClientSecret，GH 是通过它来确认 App 的合法身份的；另一个是后端，因为跳回 App 的时候实际是重定向回我预先提供的 redirect_uri 的，所以 Authorization Code 适合带有后端服务的应用，保障 Token 的安全性，否则过程中就可能出现漏洞。\nGittalk 是一款纯前端的评论应用，最大的特点是利用 GitHub Issue 来保存评论数据，但因为没有后端，它的授权过程中就并不是很安全。因为没有后端，所以 GH 跳回的 redirect_uri 其实是前端页面，在这想要 POST 请求 access token 是跨域禁止的，但 Gittalk 配置了代理服务器来克服这个问题。暂时不管代理服务器是否可靠，ClientID/ClientSecret 是确实保存在前端了的，这就意味着 100% 的泄露可能，另外登录请求的权限也未免太宽了些，看着就不是很愿意授权：\n其实 OAuth 2.0 是为纯前端应用提供了 Implicit 这种 Flow 的，就是在回调 redirect_uri 的时候直接附上 Token https://redirect_uri#token=ACCESS_TOKEN，之所以用锚点也是为了增强安全性。这种方式并不很安全，所以 Token 的过期时间要尽量短。然而 Gittalk 是没机会使用的，因为 GH 明确表示了不支持：\nTo authorize your OAuth app, consider which authorization flow best fits your app.\nweb application flow: Used to authorize users for standard OAuth apps that run in the browser. (The implicit grant type is not supported.) device flow: Used for headless apps, such as CLI tools. 除了上面两种，还有 Client Credential 这种 Flow. 简单来说，这更类似于认证而不是授权。因为不需要用户首肯，应用直接使用注册得到的 ClientID/ClientSecret 请求 Token，比较适合没有前端的命令行应用。\n最后还有一种 Password Flow，用户需要在应用中直接输入 GH 的用户名密码。这其实已经违背了 OAuth 2.0 的初衷，但 FastAPI 利用它来实现应用本身的认证登录，相当于把 Authorization 作为一种 Pseudo Authentication 了。\n授权说到这也差不多了。现在的个人/小型应用可能没有必要再实现自己的认证了，登录直接第三方（Apple/Google/GH/WeChat/手机验证码/手机号一键登录），国内外都照顾得到，用户数据依然可以维护，也不用自己管理密码了。至于安全性，HTTP 是一定要加上 S 的。\nReferences\nHTTP authentication - MDN\nDigest access authentication - Wikipedia\nMessage authentication code - Wikipedia\nHTTP API 认证授权术 - CoolShell\nOAuth 2.0 的四种方式 - 阮一峰\nAuthorizing OAuth Apps - GitHub\n","permalink":"https://iamgodot.com/posts/about-http-auth/","summary":"Auth 代表了 Authentication 和 Authorization 两个概念，也就是认证与授权。基于 HTTP，两者得以遵循一定的标准，SSL/TLS 之后，又出现了 OAuth 2.0，让授权也简单了许多。\nAuthentication 认证相对来说比较直接，核心就是对 Credential(e.g. username/password) 的验证。HTTP 提供了多种认证方案，比如最常见的 Basic auth, Digest access 和 Bearer.\nBasic auth 具体来说就是服务器用 WWW-Authenticate 表示需要认证，比如 WWW-Authenticate: Basic realm='Accessing to xx site'，客户端则通过 Authorization 提供相关信息：Authorization: Basic Zm9vOmJhcg==，后面的一串编码是对用户名密码明文进行 base64 的结果，即可以直接从中 decode 出原始信息 foo:bar. 没有 HTTPS 的保护，这样很不安全，所以 Apache/Nginx 对 BA 的实现都会使用密码的哈希结果而不是原文，拿后者举例：\nhttp { server { location / { auth_basic \u0026#34;Accessing to xx site\u0026#34;; auth_basic_user_file /path/to/authfile; } } } 然后需要在 authfile 中保存 username/password pair，比如 sudo htpasswd -c /path/to/authfile user1，htpasswd 是 Apache 提供的专门用来生成 BA 使用的 Credential file 的工具。不用额外安装，我们直接用 openssl 代替：","title":"关于 HTTP Auth"},{"content":" Where is the sun\nThat shone on my head\nThe sun in my life\nIt is dead\nIt is dead\nWhere is the light\nThat would play\nIn my streets\nAnd where are the friends\nI could meet\nI could meet\nWhere are the girls\nI left far behind\nThe spicks and the specks\nOf the girls on my mind\nWhere is the sun\nThat shone on my head\nThe sun in my life\nIt is dead\nIt is dead\n\u0026hellip;\n","permalink":"https://iamgodot.com/posts/spicks-and-specks/","summary":"Where is the sun\nThat shone on my head\nThe sun in my life\nIt is dead\nIt is dead\nWhere is the light\nThat would play\nIn my streets\nAnd where are the friends\nI could meet\nI could meet\nWhere are the girls\nI left far behind\nThe spicks and the specks\nOf the girls on my mind\nWhere is the sun\nThat shone on my head","title":"Spicks and Specks"},{"content":"没想到 2021 年的第一篇博客是关于电影的，感觉很奇特。平时看电影最多就是上豆瓣评个分抖两句机灵，这次却想写一整篇，大概对于喜欢的东西废话就会变多吧。\n一个好故事 《水浒传之英雄本色》讲述了林冲上梁山之前，和鲁智深相识结义并与朝廷决裂的故事。剧情流畅，引人入胜。\n1. 起 开头就是一个小片段，林冲从插翅虎手中救回了高衙内，寥寥几笔便刻画出了林冲的武功和衙内的无赖，也为后来两人之间的矛盾升级埋下了伏笔。\n后面又简单描绘了林冲的性格（武痴、不畏权贵）和生活状态（和妻子如胶似漆)，平稳之中让人感觉巨变即将来临。\n2. 承 这里主要开始写林冲和鲁智深相识相交到结拜成兄弟的过程，我觉得也是整个电影最好看的部分。两个英雄人物的性格碰撞，切磋武功又怕王祖贤饰演的妻子发现，十分欢乐。既有兄弟情义，又有夫妻恩爱。\n巧妙的是里面还用武功的隐喻了林冲此时的立场：以退为进。鲁智深劝其罢官上梁山，但他认为只要足够忍让，仕途之路仍然可以走出一片天。\n3. 转 与鲁智深告别之后，林冲迎来了人生的暴风雨。狡诈的高俅父子在明，阴险的陆谦在暗，栽赃诬陷，虽有丞相帮助，最后还是免不了发配充军。\n探监这里王祖贤换了黑衣，发型也改变了\n后面愈加悲惨，妻子被衙内觊觎已久，结果惨死刀下；而林冲自己也险些被手下的兵士所害，幸得结拜大哥及时来救。\n在流放的军营里，林冲依然在以退为进，拒绝鲁智深的劝说，甘愿挨饿受罚，对朝廷还抱有幻想。\n4. 合 最后，得知丞相妻子皆死，林冲终于下了复仇的决心，但他首先做的是和鲁智深决裂，支走对方，独自面对陆谦大军。这里两人的内心各有表达，林冲自言自语重复了结拜时说的话：有福同享，有祸我当；而鲁智深则把疑问都抛给了坐骑，虽然马儿再三摇头，却还是决然返回：为兄弟，没有面子就没有面子。\n结局自然是两人手刃敌人，终于齐上梁山。\n英雄本色 越写越觉得一部电影的剧情逻辑和人物形象重要，那个时候的特效很落后，但用几个简单的场景和对话就可以把每个人的性格和内心写活，看起来回味无穷。除了故事本身，整个片子的阵容也超级强大：\n主角 林冲：梁家辉的古装扮相极其帅气（发髻加高马尾），和新龙门客栈中的形象不相上下 鲁智深：徐锦江把这个角色塑造地非常到位，还被提名当年金像奖最佳男配角 妻子：一袭白衣的王祖贤绝美，柔情似水的表演让人难以忘怀 反派 高俅父子：老戏骨刘询自不必说，难得的是带胡子的奸人角色（不知道是不是唯一，老爷子一向是有胡子善没胡子奸的）；单立文的疯癫演技独树一帜，抛开角色，演员本身还是很正直的（从网上看），还给主题曲作了词 陆谦：林威很适合这种反面形象，在结尾决战的时候几次规整官帽的动作，把陆谦对功名利禄的执念体现得淋漓尽致 客串 仇五：刘青云客串的小角色，为报恩林冲而死，戏份少但很精彩，难怪后来成为影帝 丞相：午马轻松出场两次，每次都会让我想起燕赤霞 其他 导演：陈会毅，港片的武指老炮 配乐：胡伟立，绝对的大师 看完电影的光辉时刻，总是不想跳回生活的平淡点滴，但两者难免要糅和，英雄本色要面对的是漫长人生路的每一天。这部戏还有一点可贵的地方就在于演员自身也是很有性格魅力的人。之前看芒果 TV 的一路成年，梁家辉和徐锦江都是很爱家爱孩子的人，但前者也是时而暴躁的硬汉，而后者身上则充满了艺术家的多愁善感。还有息影多年的王祖贤，自己去买菜的市民刘先生。那个时代的香港影星总是不乏传奇色彩。\n资源 爱奇艺上的港片资源不算少，但这部的质量很差。YouTube 有高清的在线版本：\n可以用 yt-dlp 下载到本地。\n原声带比较好找，QQ 音乐和网易云应该都有现成的资源。\nReferences\n水浒传之英雄本色 - 豆瓣 ","permalink":"https://iamgodot.com/posts/all-men-are-brothers/","summary":"没想到 2021 年的第一篇博客是关于电影的，感觉很奇特。平时看电影最多就是上豆瓣评个分抖两句机灵，这次却想写一整篇，大概对于喜欢的东西废话就会变多吧。\n一个好故事 《水浒传之英雄本色》讲述了林冲上梁山之前，和鲁智深相识结义并与朝廷决裂的故事。剧情流畅，引人入胜。\n1. 起 开头就是一个小片段，林冲从插翅虎手中救回了高衙内，寥寥几笔便刻画出了林冲的武功和衙内的无赖，也为后来两人之间的矛盾升级埋下了伏笔。\n后面又简单描绘了林冲的性格（武痴、不畏权贵）和生活状态（和妻子如胶似漆)，平稳之中让人感觉巨变即将来临。\n2. 承 这里主要开始写林冲和鲁智深相识相交到结拜成兄弟的过程，我觉得也是整个电影最好看的部分。两个英雄人物的性格碰撞，切磋武功又怕王祖贤饰演的妻子发现，十分欢乐。既有兄弟情义，又有夫妻恩爱。\n巧妙的是里面还用武功的隐喻了林冲此时的立场：以退为进。鲁智深劝其罢官上梁山，但他认为只要足够忍让，仕途之路仍然可以走出一片天。\n3. 转 与鲁智深告别之后，林冲迎来了人生的暴风雨。狡诈的高俅父子在明，阴险的陆谦在暗，栽赃诬陷，虽有丞相帮助，最后还是免不了发配充军。\n探监这里王祖贤换了黑衣，发型也改变了\n后面愈加悲惨，妻子被衙内觊觎已久，结果惨死刀下；而林冲自己也险些被手下的兵士所害，幸得结拜大哥及时来救。\n在流放的军营里，林冲依然在以退为进，拒绝鲁智深的劝说，甘愿挨饿受罚，对朝廷还抱有幻想。\n4. 合 最后，得知丞相妻子皆死，林冲终于下了复仇的决心，但他首先做的是和鲁智深决裂，支走对方，独自面对陆谦大军。这里两人的内心各有表达，林冲自言自语重复了结拜时说的话：有福同享，有祸我当；而鲁智深则把疑问都抛给了坐骑，虽然马儿再三摇头，却还是决然返回：为兄弟，没有面子就没有面子。\n结局自然是两人手刃敌人，终于齐上梁山。\n英雄本色 越写越觉得一部电影的剧情逻辑和人物形象重要，那个时候的特效很落后，但用几个简单的场景和对话就可以把每个人的性格和内心写活，看起来回味无穷。除了故事本身，整个片子的阵容也超级强大：\n主角 林冲：梁家辉的古装扮相极其帅气（发髻加高马尾），和新龙门客栈中的形象不相上下 鲁智深：徐锦江把这个角色塑造地非常到位，还被提名当年金像奖最佳男配角 妻子：一袭白衣的王祖贤绝美，柔情似水的表演让人难以忘怀 反派 高俅父子：老戏骨刘询自不必说，难得的是带胡子的奸人角色（不知道是不是唯一，老爷子一向是有胡子善没胡子奸的）；单立文的疯癫演技独树一帜，抛开角色，演员本身还是很正直的（从网上看），还给主题曲作了词 陆谦：林威很适合这种反面形象，在结尾决战的时候几次规整官帽的动作，把陆谦对功名利禄的执念体现得淋漓尽致 客串 仇五：刘青云客串的小角色，为报恩林冲而死，戏份少但很精彩，难怪后来成为影帝 丞相：午马轻松出场两次，每次都会让我想起燕赤霞 其他 导演：陈会毅，港片的武指老炮 配乐：胡伟立，绝对的大师 看完电影的光辉时刻，总是不想跳回生活的平淡点滴，但两者难免要糅和，英雄本色要面对的是漫长人生路的每一天。这部戏还有一点可贵的地方就在于演员自身也是很有性格魅力的人。之前看芒果 TV 的一路成年，梁家辉和徐锦江都是很爱家爱孩子的人，但前者也是时而暴躁的硬汉，而后者身上则充满了艺术家的多愁善感。还有息影多年的王祖贤，自己去买菜的市民刘先生。那个时代的香港影星总是不乏传奇色彩。\n资源 爱奇艺上的港片资源不算少，但这部的质量很差。YouTube 有高清的在线版本：\n可以用 yt-dlp 下载到本地。\n原声带比较好找，QQ 音乐和网易云应该都有现成的资源。\nReferences\n水浒传之英雄本色 - 豆瓣 ","title":"水浒传之英雄本色"},{"content":"SSH 的端口转发很实用，但我总觉得难以理解和记忆，直到最近才有所好转。\n因为又派上用场了。以前基本只做做内网穿透，现在更多地拿来绕过防火墙。自己的服务器，大多数端口虽然都是被禁用的（至少禁止入网，这也是正常的安全措施），但是想要连接的话直接本地端口转发就可以了。\nTL;DR 本地端口转发在当前机器上设置，然后从本机出发，通过另一台机器，连接其他的机器。适用于防火墙的绕过、多重 SSH 登录等。\n远程端口转发在当前机器上设置，然后从另外一台机器出发，通过当前机器，连接本机或者其他的机器。适用于 NAT 网络穿透、暴露内部网络服务等。\n本质上都是先建立 SSH 会话，形成隧道，然后在上面进行正向或反向的数据传输。\nLocal Port Forwarding 为什么叫做本地呢，我想有两个原因：\n转发的端口在当前（执行 SSH 命令这台）机器上 请求是从当前机器发出的 当前机器就是我的笔记本，另外一台是服务器。比如，在服务器上部署一个应用，开放给 8000 端口，但是被墙掉了，没办法在本地调试，怎么办？防火墙肯定开放了 SSH 登录的端口，比如 22，那么就让请求从本地的端口发送到服务器的 22 端口，再转发到 8000 端口，最后原路返回。我可以设置本地的端口也是 8000，这样直接用 localhost:8000 来访问应用就好了。\n转发的重点在于本地的 8000 端口和服务器的 22 端口之间，因为请求到了服务器之后可以给应用的 8000，也可以给其他的机器，只要服务器能连接到：\n# ssh -L local_port:dest_addr:dest_port server # Local 8000 \u0026lt; -- \u0026gt; Server 22 \u0026lt; -- \u0026gt; Server 8000 # -fNT 让 ssh 不要打开服务器 shell，并且转为后台运行 # server 隐含了使用 22 端口登录，当然也可以在 ssh config 中设置任意登录端口 ssh -fNT -L 8000:localhost:8000 server 注意这里的 dest 对应的 src 是 server，也就是说 localhost 及后面的 8000 都是 server 的 IP 和端口。可以理解为 server 是中介，整条通路是 local -\u0026gt; server -\u0026gt; dest.\n除了调试应用，还可以做各种各样的事情，比如浏览文件（在服务器上开个 python -m http.server 8080），用 netcat 测试连接，甚至实现流媒体播放。最重要的是，这解放了封闭在防火墙背后的一系列端口。\n不光如此，如果服务器还连接到其他的机器，就可以将三台机器联系到一起。跳板机跨越是一个常见的例子，即本地先 SSH 登录到跳板机，再登录到服务器。利用端口转发的话只需要将 dest 设置为跳板机的地址和端口（当然，直接使用 SSH 的 ProxyJump 更加直截了当，这里有些大材小用了）。\n本地端口转发很好，但不是万能的。如果服务器没有公网 IP，或者隐藏在 NAT 背后呢？这时候就需要远程端口转发。\nRemote Port Forwarding 先解释一下我对远程两个字的理解：\n转发的端口在另外一台机器上 请求是从另外一台机器发出的 接着刚才的例子，如果服务器躲在 NAT 后面不出来，但是我的笔记本可以通过 SSH 连接，那就可以在服务器上设置远程端口转发：\n# ssh -qngfNT -R [bind_addr]:remote_port:dest_addr:dest_port host ssh -qngfNT -R 8000:localhost:8000 host 这里的 host 指的就是我的笔记本，所以服务器要可以 SSH 到我的笔记本才行？是的，这些转发的可能性都在于，必须能建立起双方之间的 SSH 会话，这也是为什么端口转发又被称为 SSH 隧道，有了通路，才可以换方向。\n和本地转发不同的是，dest 的 src 是 local，也就是当前机器（服务器），通路是 local -\u0026gt; host -\u0026gt; dest.\n其实远程端口转发最常见的用法是实现内网穿透，也是解决 NAT 的问题。比如公司的电脑在 NAT 后，通过公网服务器，我可以从家里登录到公司。\n在这个场景中，首先要保证几个前提：公司电脑和服务器都要开启了 SSH 的服务，即都能够登录上去；其次，如果想要用家里的电脑，即第三台机器，实现公司登录的话，要设置服务器 SSH 服务的 GatewayPorts 选项为 yes. 如果这些都满足，那么直接在公司电脑执行：\n# -qngfNT 一堆不是很重要但最好加上的选项 ssh -qngfNT -R 8000:localhost:22 server 8000 就是（公司电脑远程转发给）服务器的端口，在家里用这个端口登录服务器即可开始办公：\nssh user-company@ip-server -p 8000 注意上面示例中的 bind_addr，如果想只让某个固定 IP 才能登录，那么在这里加上就可以了。当然这要求家里的电脑有公网地址，而且服务器上的 GatewayPorts 设置为 clientspecified.\nOK，现在我们可以进入公司网络了，但如果公司电脑（或者办公网络）中有个需要调试的应用怎么办？那就再加一个本地端口转发：\nssh -fNT -L 8000:localhost:8000 server 现在就能用 localhost:8000 访问公司的应用了，那么如果有多个应用呢？不管是 -L 还是 -R 都支持多个参数，所以分别用不同的端口指定即可。\nReferences\nSSH port forwarding\n远程操作与端口转发 - 阮一峰\n一个很好的内网穿透的例子\n","permalink":"https://iamgodot.com/posts/ssh-port-forwarding/","summary":"SSH 的端口转发很实用，但我总觉得难以理解和记忆，直到最近才有所好转。\n因为又派上用场了。以前基本只做做内网穿透，现在更多地拿来绕过防火墙。自己的服务器，大多数端口虽然都是被禁用的（至少禁止入网，这也是正常的安全措施），但是想要连接的话直接本地端口转发就可以了。\nTL;DR 本地端口转发在当前机器上设置，然后从本机出发，通过另一台机器，连接其他的机器。适用于防火墙的绕过、多重 SSH 登录等。\n远程端口转发在当前机器上设置，然后从另外一台机器出发，通过当前机器，连接本机或者其他的机器。适用于 NAT 网络穿透、暴露内部网络服务等。\n本质上都是先建立 SSH 会话，形成隧道，然后在上面进行正向或反向的数据传输。\nLocal Port Forwarding 为什么叫做本地呢，我想有两个原因：\n转发的端口在当前（执行 SSH 命令这台）机器上 请求是从当前机器发出的 当前机器就是我的笔记本，另外一台是服务器。比如，在服务器上部署一个应用，开放给 8000 端口，但是被墙掉了，没办法在本地调试，怎么办？防火墙肯定开放了 SSH 登录的端口，比如 22，那么就让请求从本地的端口发送到服务器的 22 端口，再转发到 8000 端口，最后原路返回。我可以设置本地的端口也是 8000，这样直接用 localhost:8000 来访问应用就好了。\n转发的重点在于本地的 8000 端口和服务器的 22 端口之间，因为请求到了服务器之后可以给应用的 8000，也可以给其他的机器，只要服务器能连接到：\n# ssh -L local_port:dest_addr:dest_port server # Local 8000 \u0026lt; -- \u0026gt; Server 22 \u0026lt; -- \u0026gt; Server 8000 # -fNT 让 ssh 不要打开服务器 shell，并且转为后台运行 # server 隐含了使用 22 端口登录，当然也可以在 ssh config 中设置任意登录端口 ssh -fNT -L 8000:localhost:8000 server 注意这里的 dest 对应的 src 是 server，也就是说 localhost 及后面的 8000 都是 server 的 IP 和端口。可以理解为 server 是中介，整条通路是 local -\u0026gt; server -\u0026gt; dest.","title":"关于 SSH 端口转发"},{"content":"服务器能做什么？在 Awesome-Selfhosted 里可以找到上百种答案。如果带宽不算太小的话，那么 BT 下载是个不错的尝试。借着 No Time to Die 的上映我开始重温 007 系列，从皇家赌场到幽灵党，在服务器上的下载体验是很好的。\nBitTorrent 在此之前，我基本上把 BT、种子、磁力、迅雷下载当成同一种东西。下载电影？先找种子或者磁力链接，打开迅雷下载，然后视速度决定要不要开个会员。\n实际上这完全曲解了 BT 下载。\n首先 BitTorrent 是一种网络协议。还记得计算机网络一开始就提到过除了 C/S 架构之外，还有 P2P(Peer-to-peer)，也就是网络中的各个节点都扮演了同等的角色，既是客户端也是服务器。BT 基于 P2P 实现了去中心化的文件分享，让网络数据的传输不再仅限于服务器的能力，而是共享带宽，每个人下载的同时也在上传，所以越多人参与速度就越快。\n类似于 HTTP 和 FTP，BT 也是基于 TCP/IP 的一种应用层协议。基本上它是这么运作的：\n我有一部电影，想把资源分享到网络，要先提供一个种子文件\n种子文件实际上就是个文本文件，里面主要记录两部分信息\nTrackers: 就是 Tracker 服务器的地址，这个服务器不是用来下载资源的，而是用于获取其他 Peers 的联系方式 Files: 一个视频文件会被（逻辑）划分为很多个虚拟分块，每块的索引和验证码都包含在这里 接下来我把种子文件发布出去，等待别人下载\n这时候有人获取到种子了，于是开启了 BT 客户端下载\n客户端先解析种子文件中的信息，找到 Tracker，然后询问有哪些 Peers\n因为是第一个下载者，所以 Tracker 告知 Peer 目前只有我，也就是发布者\n之后对方会尝试与我互连，然后根据 Files 信息交换数据，这里基本就是我上传给对方\n下载的过程会以分块为单位进行，每块完成下载后会根据验证码再做校验\n如果这时又有一个人开始下载，那么我和这第一个下载者都会贡献上传\n随着更多用户的参与，（上传）下载的速度就会越来越快\n可以发现，整个过程中 Tracker 是很关键的一步，如果没有有效的 Tracker 提供 Peers，后面的下载都无法开始。所以如果你的 BT 下载没有速度，首先要尝试多添加一些 Tracker 服务器，比如 TrackersList.\n为了避免 Tracker 成为瓶颈，又出现了 DHT(Distributed Hash Table) 来帮助 Peers 的寻找：\n在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个 DHT 网络的寻址和存储。使用支持该技术的 BT 下载软件，用户无需连上 Tracker 就可以下载，因为软件会在 DHT 网络中寻找下载同一文件的其他用户并与之通讯，开始下载任务。\n这一切看起来都很（过于）理想：人人为我，我为人人。但是事实从来没有如此美好。\nBreaking Rules 首先在国内的网络环境中，BT 的使用就已经打折扣了：\n家庭网络一般都没有公网 IP 上传速度远小于下载速度（对带宽经济，但对于 BT 并不是好事） ISP 的干扰，比如针对 BT 数据包的干扰 其次就是流氓下载软件野蛮地改变了 BT 平等分享的初衷，比如迅雷。那么迅雷是如何打破规则的呢？简单来说，它在下载的时候老老实实享受其他用户的上传，等到分享时却只提供资源给自家用户，俗称吸血。不仅如此，迅雷还会维护单独的服务器，这样下载既 From peer 又 From server，也就是 P2SP，速度自然超过普通 BT 软件，同时还让人感觉很多资源只有迅雷才下得动。至于会员专享什么的，把一开始设的限制（比如连接其他 Peer 的数量）解除掉就好了，剩下的就是大肆捞钱。\n国内类似的吸血下载软件不少，但基本以迅雷为首。这么多年积累下来，就算大家觉得过分可能也无奈了，不用迅雷实在是下载不了啊。话虽如此，该抵制的还是要抵制，至少我已经从（多年前的）迅雷会员变为 BT 共产主义者了。\n最后，很多人使用 BT 也常常不遵守基本原则，比如关闭上传、下载完之后立刻删除种子资源。这也导致了很多软件增加了针对不良使用习惯的用户的限制，还出现了 PT(Private Tracker) 下载，简单讲就是在一个私密的圈子内分享资源下载，保证每个 Peer 的上传贡献。\n一个良好的网络环境既离不开硬性限制，也需要每个人的自我约束。更重要的前提是，打破黑盒，大家了解到事情背后的真相才有可能做出正确的决定。\nQbittorrent 抛弃了迅雷怎么办？其实好的选择有很多，比如 Windows 上的 IDM，或者开源的 Motrix, qbittorrent 等等。\n对于 Linux 来说，本地使用我觉得 Motrix 很不错，支持 AppImage，界面好看，还能自动更新各种 TrackerList，总之就是省心。而服务器部署我选择了 qbittorrent，GitHub 上面的文档很详尽，用 Docker 部署非常简单。\n这里要提一下，一开始使用最好先下个热门资源确认 BT 可以正常工作，比如 Ubuntu 的镜像文件。\n说回 qbittorrent，虽然不像 Motrix 可以自动更新 Trackers，但是它集成了种子的搜索功能（基本是国外资源），还有强大的 RSS 订阅。\n我的服务器是 5M 带宽，但腾讯云的出入网计算方式不太一样，对于入网速度，小于 5M 的带宽都按照 10M 计算。即便如此，下载速度还是超过了应有的限制，也许还有服务器的网络质量加成吧。\nFirewall 下着下着我感到很奇怪，因为 qbt 是用到了几个端口的，比如 UI 和下载，而下载的 6881 端口并没有在安全组开放啊，为什么还能正常使用？\n先用 nmap 测试下：\nnmap -p 6881 server 显示端口 filtered，确实是被防火墙拦住了没错。那是怎么做到的，BT 可以穿越防火墙？\n一番搜索之后我找到了答案，主要还是不太了解防火墙的工作机制：\n首先如果设置了端口禁止入网，那么外网肯定是无法向端口开启连接的 但是如果端口可以出网就不一定了，这时端口可以主动建立连接 之后外面再返回的数据包就可以穿过防火墙了 以上针对的是 Stateful firewall 的情况，也就是防火墙会跟踪并维护所有的网络连接，如果一个连接已经建立，那么即使规则不允许端口入网，数据仍然是可以正常传递的。\n再看下腾讯云的安全组介绍：\n安全组是一种虚拟防火墙，具备有状态的数据包过滤功能，\u0026hellip;\n果然是有状态的。\n不如再做个实验好了。因为家里没有公网，所以又临时开了台 vultr 服务器。先在腾讯云上监听端口：\nnc -l -p 6881 然后从 vultr 尝试连接：\nnc tecent_server_ip 6881 显示超时，因为端口被 filtered，没问题。再在 vultr 上监听：\nnc -l -p 8888 从腾讯云主动发起连接：\nnc -p 6881 vultr_server_ip 8888 果然双向可以正常通信。所以 qbittorrent 才能正常下载啊。\nReferences\nBitTorrent - Wikipedia\nPT 下载 - Wikipedia\nP2SP - Wikipedia\nStateful firewall\nMotrix\nQbittorrent - GitHub\n为什么国内 BT 环境如此恶劣？ - 知乎\n","permalink":"https://iamgodot.com/posts/from-bittorrent-to-firewall/","summary":"服务器能做什么？在 Awesome-Selfhosted 里可以找到上百种答案。如果带宽不算太小的话，那么 BT 下载是个不错的尝试。借着 No Time to Die 的上映我开始重温 007 系列，从皇家赌场到幽灵党，在服务器上的下载体验是很好的。\nBitTorrent 在此之前，我基本上把 BT、种子、磁力、迅雷下载当成同一种东西。下载电影？先找种子或者磁力链接，打开迅雷下载，然后视速度决定要不要开个会员。\n实际上这完全曲解了 BT 下载。\n首先 BitTorrent 是一种网络协议。还记得计算机网络一开始就提到过除了 C/S 架构之外，还有 P2P(Peer-to-peer)，也就是网络中的各个节点都扮演了同等的角色，既是客户端也是服务器。BT 基于 P2P 实现了去中心化的文件分享，让网络数据的传输不再仅限于服务器的能力，而是共享带宽，每个人下载的同时也在上传，所以越多人参与速度就越快。\n类似于 HTTP 和 FTP，BT 也是基于 TCP/IP 的一种应用层协议。基本上它是这么运作的：\n我有一部电影，想把资源分享到网络，要先提供一个种子文件\n种子文件实际上就是个文本文件，里面主要记录两部分信息\nTrackers: 就是 Tracker 服务器的地址，这个服务器不是用来下载资源的，而是用于获取其他 Peers 的联系方式 Files: 一个视频文件会被（逻辑）划分为很多个虚拟分块，每块的索引和验证码都包含在这里 接下来我把种子文件发布出去，等待别人下载\n这时候有人获取到种子了，于是开启了 BT 客户端下载\n客户端先解析种子文件中的信息，找到 Tracker，然后询问有哪些 Peers\n因为是第一个下载者，所以 Tracker 告知 Peer 目前只有我，也就是发布者\n之后对方会尝试与我互连，然后根据 Files 信息交换数据，这里基本就是我上传给对方\n下载的过程会以分块为单位进行，每块完成下载后会根据验证码再做校验\n如果这时又有一个人开始下载，那么我和这第一个下载者都会贡献上传\n随着更多用户的参与，（上传）下载的速度就会越来越快\n可以发现，整个过程中 Tracker 是很关键的一步，如果没有有效的 Tracker 提供 Peers，后面的下载都无法开始。所以如果你的 BT 下载没有速度，首先要尝试多添加一些 Tracker 服务器，比如 TrackersList.","title":"From BitTorrent to Firewall"},{"content":"愿逝者安息。\n同龄人，也算是同行，现在几乎不玩游戏了，但从小也在国产武侠 RPG 里泼洒了许多热情。虽然不认识，之前也未曾耳闻，心里却五味杂陈。一切的一切，我都理解的。\n我有一个梦想，将来的某一天，大家都能玩到蕴含着中国上下五千年本土文化的优质游戏大作。\n我有一个梦想，有一天，西游记能出ACT，让老外去体会中国文化西游记中”斗战胜佛”的打击快感，那一定比西方的动作巅峰之作《战神》、《鬼泣》更加深邃。\n\u0026hellip;\n我有一个梦想，将来的某一天，国产游戏能像中国的其他产业一样，以一个领跑者的姿态，面对全世界，面对全宇宙，器宇轩昂，扬眉吐气。\n\u0026hellip;\n我等着我们的好消息。\nEven Dead, You\u0026rsquo;re The Hero.\n","permalink":"https://iamgodot.com/posts/edyth/","summary":"愿逝者安息。\n同龄人，也算是同行，现在几乎不玩游戏了，但从小也在国产武侠 RPG 里泼洒了许多热情。虽然不认识，之前也未曾耳闻，心里却五味杂陈。一切的一切，我都理解的。\n我有一个梦想，将来的某一天，大家都能玩到蕴含着中国上下五千年本土文化的优质游戏大作。\n我有一个梦想，有一天，西游记能出ACT，让老外去体会中国文化西游记中”斗战胜佛”的打击快感，那一定比西方的动作巅峰之作《战神》、《鬼泣》更加深邃。\n\u0026hellip;\n我有一个梦想，将来的某一天，国产游戏能像中国的其他产业一样，以一个领跑者的姿态，面对全世界，面对全宇宙，器宇轩昂，扬眉吐气。\n\u0026hellip;\n我等着我们的好消息。\nEven Dead, You\u0026rsquo;re The Hero.","title":"Even Dead, You're The Hero"},{"content":"Heap 作为一种重要的数据结构，有许多应用场景，比如优先级队列，每次出队的都是最大值或者最小值的元素。很多语言都集成了相关实现，比如 Java 的 PriorityQueue，而 Python 提供了 heapq 模块。\n因为 Heap 通常用数组而不是链表存储，所以 Python 里面的 Heap 实质上就是一个列表，而 heapq 提供的几个函数也是以列表对象作为参数的：\nfrom heapq import heappush, heappop, heappify, heapreplace, heappushpop heap = [] heappush(heap, 1) item = heap[0] # 第一个元素代表堆顶元素 heappop(heap) heapify([3, 2, 1, 5, 6, 4]) # 把普通列表转化为堆结构 [1, 2, 3, 4, 5, 6] heapreplace([3, 4, 5], 1) # 直接将堆顶元素 3 替换为 1，最后堆结构为 [1, 4, 5] heappushpop([3, 4, 5], 1) # 先将 1 插入堆中，再 pop 出堆顶元素，最后堆结构为 [3, 4, 5] 为什么 heapq 提供的是最小堆而不是更常见的最大堆呢？这就得从源码中找答案了。\nOur API differs from textbook heap algorithms as follows:\nWe use 0-based indexing. This makes the relationship between the index for a node and the indexes for its children slightly less obvious, but is more suitable since Python uses 0-based indexing.\nOur heappop() method returns the smallest item, not the largest.\nThese two make it possible to view the heap as a regular Python list without surprises: heap[0] is the smallest item, and heap.sort() maintains the heap invariant!\n也就是说，为了保证第一个元素是最小值，以及列表的 sort 方法不会破坏堆结构（注意这里的结构不是说元素的绝对顺序，而是 heap[k] \u0026lt;= heap[2k+1] \u0026amp; heap[k] \u0026lt;= heap[2k+2] 这两个不等式），所以提供的是最小堆的接口。实际上，其实最大堆的逻辑也都已经实现了，只是作为内部函数没有暴露出来。\nHeap 本身并不复杂，但从 heapq 的代码中可以感受到，在基础概念之上，作者还结合了实际的应用场景来选择最佳的实现方案。\nSift Up 每次的 push 和 pop 操作，都要调整堆结构，因此代码中封装了 _siftdown 和 _siftup 两个函数，前者是在插入叶子节点后自底向上进行更新，而后者则是把叶子节点放到根节点的位置再从上到下做调整。特别之处是，对于 _siftup，作者没有从根节点开始向下依次做比较，而是先把根节点迅速交换到最下面，然后直接调用 _siftdown:\ndef _siftup(heap, pos): endpos = len(heap) startpos = pos newitem = heap[pos] # Bubble up the smaller child until hitting a leaf. childpos = 2*pos + 1 # leftmost child position while childpos \u0026lt; endpos: # Set childpos to index of smaller child. rightpos = childpos + 1 if rightpos \u0026lt; endpos and not heap[childpos] \u0026lt; heap[rightpos]: childpos = rightpos # Move the smaller child up. heap[pos] = heap[childpos] pos = childpos childpos = 2*pos + 1 # The leaf at pos is empty now. Put newitem there, and bubble it up # to its final resting place (by sifting its parents down). heap[pos] = newitem _siftdown(heap, startpos, pos) 原因是在实际情况中，叶子节点的值通常都很大，所以如果从根节点的位置向下比较，会迭代很多次。而切换到最下层之后，上浮调整的次数会明显小很多。从作者提供的数据来看，这种改动让 heappop 操作的 comparisons 近乎减半：\n# On random arrays of length 1000, making this change cut the number of # comparisons made by heapify() a little, and those made by exhaustive # heappop() a lot, in accord with theory. Here are typical results from 3 # runs (3 just to demonstrate how small the variance is): # # Compares needed by heapify Compares needed by 1000 heappops # -------------------------- -------------------------------- # 1837 cut to 1663 14996 cut to 8680 # 1855 cut to 1659 14966 cut to 8678 # 1847 cut to 1660 15024 cut to 8703 Merge 除了基础操作，heapq 还基于 Heap 封装了几个 higher level 的函数：\nmerge nsmallest nlargest 如果你需要归并若干个已经有序的列表又不想一次性把所有数据都读取到内存的话，那么 merge 是一个好选择。它的实现巧妙地利用了 Heap:\ndef merge(*iterables, key=None, reverse=False): h = [] h_append = h.append if reverse: _heapify = _heapify_max _heappop = _heappop_max _heapreplace = _heapreplace_max direction = -1 else: _heapify = heapify _heappop = heappop _heapreplace = heapreplace direction = 1 if key is None: for order, it in enumerate(map(iter, iterables)): try: next = it.__next__ h_append([next(), order * direction, next]) except StopIteration: pass _heapify(h) while len(h) \u0026gt; 1: try: while True: value, order, next = s = h[0] yield value s[0] = next() # raises StopIteration when exhausted _heapreplace(h, s) # restore heap condition except StopIteration: _heappop(h) # remove empty iterator if h: # fast case when only a single iterator remains value, order, next = h[0] yield value yield from next.__self__ return ... 最后面省略的是当 key 不为 None 时的处理，思路和前面基本一致。\n首先从对 reverse 的判断部分可以看出，heapq 是实现了最大堆的接口的。\n关键部分在于下面的循环中对堆结构的使用，注意到存入 Heap 的数据并不是各个列表的元素，而是由头元素、序号和迭代器三部分组成（针对每个列表）。在 heapify 时比较的就是各个列表的头元素大小，如果相同，那么就看列表们在传参进来的顺序。这样就做到了稳定排序，一个是列表之间的等值元素会按照列表的顺序排列，而某个列表中的重复元素也不会打乱原有顺序。在 while 循环中，每输出一个元素，都会重新调整 Heap 结构，以此来选择下一个列表。\n如果总共只传入了一个列表，那么就直接短路 while 的部分，直接使用列表的迭代器。这种优化在 heapq 中有很多，通过区分边界情况使用不同的方案，达到整体复杂度的最优。\nFind First N 最后看下 nsmallest 函数，它可以用来返回一个集合中最小的 n 个元素。类似 Leetcode 上面 Kth Largest Element 那道题，heapq 选择了维护一个大小为 k 的 Heap:\ndef nsmallest(n, iterable, key=None): ... # When key is none, use simpler decoration if key is None: it = iter(iterable) # put the range(n) first so that zip() doesn\u0026#39;t # consume one too many elements from the iterator result = [(elem, i) for i, elem in zip(range(n), it)] if not result: return result _heapify_max(result) top = result[0][0] order = n _heapreplace = _heapreplace_max for elem in it: if elem \u0026lt; top: _heapreplace(result, (elem, order)) top, _order = result[0] order += 1 result.sort() return [elem for (elem, order) in result] ... 这里仍然用到了 order 作为序号的方式来保证稳定。另外，获取最终的 result 后，直接应用 sort 方法而不是继续用 Heap 输出，这样写很简便，而且堆排序也不会比 Timsort 更优。\n理论上 nsmallest 和 sorted(iterable, key=key)[:n] 的效果是一样的，但是前者的可读性更好，而后者则不需要引入额外的模块。\n在函数的注解中，作者详细列出当前实现的比较次数和复杂度，同时对比了其他的方案，非常值得一读。\nReferences\nHeap - Wikipedia Timsort - Wikipedia COMPARE ALGORITHMS FOR HEAPQ.SMALLEST Kth Largest Element ","permalink":"https://iamgodot.com/posts/sourcecode-of-python-heapq/","summary":"Heap 作为一种重要的数据结构，有许多应用场景，比如优先级队列，每次出队的都是最大值或者最小值的元素。很多语言都集成了相关实现，比如 Java 的 PriorityQueue，而 Python 提供了 heapq 模块。\n因为 Heap 通常用数组而不是链表存储，所以 Python 里面的 Heap 实质上就是一个列表，而 heapq 提供的几个函数也是以列表对象作为参数的：\nfrom heapq import heappush, heappop, heappify, heapreplace, heappushpop heap = [] heappush(heap, 1) item = heap[0] # 第一个元素代表堆顶元素 heappop(heap) heapify([3, 2, 1, 5, 6, 4]) # 把普通列表转化为堆结构 [1, 2, 3, 4, 5, 6] heapreplace([3, 4, 5], 1) # 直接将堆顶元素 3 替换为 1，最后堆结构为 [1, 4, 5] heappushpop([3, 4, 5], 1) # 先将 1 插入堆中，再 pop 出堆顶元素，最后堆结构为 [3, 4, 5] 为什么 heapq 提供的是最小堆而不是更常见的最大堆呢？这就得从源码中找答案了。","title":"Python heapq 源码阅读"},{"content":"LRUCache 是一种经典的缓存机制，它的基本思路是按照最近使用的时间对元素排序，在清理时优先把搁置最久的删除掉。\n如果不想给每个缓存元素都记录一个时间戳的话，可以应用哈希链表来简单地实现 LRU 算法。也就是对一个哈希表中的所有元素增加指针，从而串起一个双链表，这样既可以快速 get value，又可以通过把最近使用过的元素放到头部来维护顺序，删除的时候从末尾开始就好了。\n手写双链表并不困难，但是借助 OrderedDict 的话，可以写出非常简短的代码：\nfrom collections import OrderedDict class LRUCache: def __init__(self, capacity): self.capacity = capacity self.hashtable = OrderedDict() def get(self, key: int) -\u0026gt; int: if key in self.hashtable: self.hashtable.move_to_end(key, last=False) return self.hashtable[key] return -1 def put(self, key: int, value: int) -\u0026gt; None: self.hashtable[key] = value self.hashtable.move_to_end(key, last=False) if len(self.hashtable) \u0026gt; self.capacity: self.hashtable.popitem() 其中最神奇的就是 move_to_end 和 popitem 方法（后者默认是弹出最后面的元素）的使用，这也得益于 OD 可以保证 key-value pair 的顺序。那么\nOD 是如何做到的呢？其实还是双链表，下面是它的 Python 实现：\nclass _Link(object): __slots__ = \u0026#39;prev\u0026#39;, \u0026#39;next\u0026#39;, \u0026#39;key\u0026#39;, \u0026#39;__weakref__\u0026#39; class OrderedDict(dict): def __init__(self, other=(), /, **kwds): \u0026#39;\u0026#39;\u0026#39;Initialize an ordered dictionary. The signature is the same as regular dictionaries. Keyword argument order is preserved. \u0026#39;\u0026#39;\u0026#39; try: self.__root except AttributeError: self.__hardroot = _Link() self.__root = root = _proxy(self.__hardroot) root.prev = root.next = root self.__map = {} self.__update(other, **kwds) def __setitem__(self, key, value, dict_setitem=dict.__setitem__, proxy=_proxy, Link=_Link): \u0026#39;od.__setitem__(i, y) \u0026lt;==\u0026gt; od[i]=y\u0026#39; # Setting a new item creates a new link at the end of the linked list, # and the inherited dictionary is updated with the new key/value pair. if key not in self: self.__map[key] = link = Link() root = self.__root last = root.prev link.prev, link.next, link.key = last, root, key last.next = link root.prev = proxy(link) # 为了保证不出现循环引用 dict_setitem(self, key, value) def __delitem__(self, key, dict_delitem=dict.__delitem__): \u0026#39;od.__delitem__(y) \u0026lt;==\u0026gt; del od[y]\u0026#39; # Deleting an existing item uses self.__map to find the link which gets # removed by updating the links in the predecessor and successor nodes. dict_delitem(self, key) link = self.__map.pop(key) link_prev = link.prev link_next = link.next link_prev.next = link_next link_next.prev = link_prev link.prev = None link.next = None def popitem(self, last=True): \u0026#39;\u0026#39;\u0026#39;Remove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO order if last is true or FIFO order if false. \u0026#39;\u0026#39;\u0026#39; if not self: raise KeyError(\u0026#39;dictionary is empty\u0026#39;) root = self.__root if last: link = root.prev link_prev = link.prev link_prev.next = root root.prev = link_prev else: link = root.next link_next = link.next root.next = link_next link_next.prev = root key = link.key del self.__map[key] # 这里并没有手动解除指针，所以有可能造成循环引用（prev 不使用 weakref 的话） value = dict.pop(self, key) return key, value def move_to_end(self, key, last=True): \u0026#39;\u0026#39;\u0026#39;Move an existing element to the end (or beginning if last is false). Raise KeyError if the element does not exist. \u0026#39;\u0026#39;\u0026#39; link = self.__map[key] link_prev = link.prev link_next = link.next soft_link = link_next.prev link_prev.next = link_next link_next.prev = link_prev root = self.__root if last: last = root.prev link.prev = last link.next = root root.prev = soft_link last.next = link else: first = root.next link.prev = root link.next = first first.prev = soft_link root.next = link 源码还有很多其他方法，这里只展示了关键的几个。可以看到，重要的数据结构在于 self.__root 为首的双链表以及 self.__map 来保存 key-link 的映射关系。这其实和哈希链表实现 LRUCache 的思路如出一辙：双链表维护顺序，字典（哈希表）快速定位元素。\nLink 的定义很精简，利用了 __slots__ 来节省空间。\nself.__root 作为伪头部节点，这样整个双链表的操作会很统一（不过感觉 root 节点不用 weakref 也没有什么问题）。\n值得一提的是 weakref 的部分，注意在 __setitem__ 方法中，root 的前置节点使用了 weakref.proxy 来定义，这是为了避免在 popitem 的时候出现虽然删除了 self.__map 中的 link 但仍然释放不了内存的情况。\n另外在 __delitem__ 最后两行，代码显式地把 link 的指针置为 None，其实不这么写的话当方法结束时 link 被回收之后也是一样的，不过这样更：\nExplicit is better than implicit.\nOD 和普通的 Python dict 在比较上也不一样：\ndef __eq__(self, other): \u0026#39;\u0026#39;\u0026#39;od.__eq__(y) \u0026lt;==\u0026gt; od==y. Comparison to another OD is order-sensitive while comparison to a regular mapping is order-insensitive. \u0026#39;\u0026#39;\u0026#39; if isinstance(other, OrderedDict): return dict.__eq__(self, other) and all(map(_eq, self, other)) return dict.__eq__(self, other) 两个 OD 对象比较时会严格按照元素的顺序，而 OD 和 dict 比较则又会忽略顺序了。\nOD 拥有 __dict__ （dict 没有），所以可以使用 d.foo = bar 这种属性赋值操作。\n自 Python3.6 开始，普通 dict 也默认会按照插入的顺序保存元素，不过如果想显式地表达 order matters，还是 OD 更合适，而且它提供的 move_to_end 和 popitem 方法也更方便。相比之下，由于 dict 高效的实现，OD 的操作性能和内存占用都要略逊一筹，所以要依据具体的场景选择使用。\n因为 LRUCache 才想一览 OD 的代码，有意思的是，在 OD 最初实现的 Issue 讨论中，就已经有人提出了支持 LRUCache 的想法，不过最终被否决了。\nReferences\nLRUCache - Leetcode\nOrderedDict vs dict - RealPython\nOrderedDict - Python Issue\n","permalink":"https://iamgodot.com/posts/sourcecode-of-python-ordereddict/","summary":"LRUCache 是一种经典的缓存机制，它的基本思路是按照最近使用的时间对元素排序，在清理时优先把搁置最久的删除掉。\n如果不想给每个缓存元素都记录一个时间戳的话，可以应用哈希链表来简单地实现 LRU 算法。也就是对一个哈希表中的所有元素增加指针，从而串起一个双链表，这样既可以快速 get value，又可以通过把最近使用过的元素放到头部来维护顺序，删除的时候从末尾开始就好了。\n手写双链表并不困难，但是借助 OrderedDict 的话，可以写出非常简短的代码：\nfrom collections import OrderedDict class LRUCache: def __init__(self, capacity): self.capacity = capacity self.hashtable = OrderedDict() def get(self, key: int) -\u0026gt; int: if key in self.hashtable: self.hashtable.move_to_end(key, last=False) return self.hashtable[key] return -1 def put(self, key: int, value: int) -\u0026gt; None: self.hashtable[key] = value self.hashtable.move_to_end(key, last=False) if len(self.hashtable) \u0026gt; self.capacity: self.hashtable.popitem() 其中最神奇的就是 move_to_end 和 popitem 方法（后者默认是弹出最后面的元素）的使用，这也得益于 OD 可以保证 key-value pair 的顺序。那么\nOD 是如何做到的呢？其实还是双链表，下面是它的 Python 实现：","title":"Python OrderedDict 实现 LRU 缓存"},{"content":"Python 的字符串自带了三种判断字符是否为数字的方法，但实际用处却相差很多。\nTL;DR 三种方法 isdecimal \u0026lt; isdigit \u0026lt; isnumeric，即包含的范围越来越大 除了 ASCII 字符以外，对于 Unicode 的字符也都覆盖在内 三种方法对于小数点和负号都会返回 False 三种方法对于空字符串都会返回 False 比较简便判断数字字符串的方法：直接使用 float 方法并检测 ValueError Decimal \u0026amp; Digit \u0026amp; Numeric 对于 isdecimal, isdigit 和 isnumeric 三种方法，目的并不是判断字符串是不是一个有效数字，而是针对每一个字符的校验：\nisdecimal: 判断字符串中的字符是否都为 Decimal，也就是在 Unicode 中类别为 Nd 的字符 isdigit: 除了 isdecimal 包含的范围之外，还会判断字符是否都为 Digit，即 Unicode 的 Numeric_Type 为 Digit 或 Decimal isnumeric: 除了 isdigit 包含的范围之外，还会判断字符是否都为 Numeric，即 Numeric_Type 为 Numeric 所以这三种方法覆盖的字符范围，每一个都是前一个的超集。对于超出 ASCII 字符之外的效果，比如：\n\u0026ldquo;０１２３４５６７８９\u0026rdquo; 这种 Full-width 字符串 isdecimal 会判定为 True，后两个方法也一样 \u0026ldquo;⓪①②③④⑤⑥⑦⑧⑨\u0026rdquo; 这种 Circled-digit 字符串 isdecimal 判定 False，但 isdigit 和 isnumeric 为 True \u0026ldquo;一二三四五六七八九十壹貳參肆伍陸柒捌玖拾\u0026rdquo; 这种中文数字字符串只有 isnumeric 才会判定为 True 总之这几种方法有更广泛的用途，根本不是为了简单的 ASCII 数字字符串的判断。即使用来做判断的话，局限性也非常大，因为如果包含小数点和负号，三个方法都会返回 False.\nMore Methods 另外 Str 还有 isalpha, isalnum 和 isascii 三种方法：\nisalpha: 判断的字符在 Unicode 中是不是 Letter 类型，除了英文字母，其他语言比如中文汉字也都会判定为 True isalnum: 这个比较简单，相当于判断 isnumeric or isalpha isascii: 判断是否为 ASCII 字符，但是对于空字符串是返回 True 的，而上面的方法都会返回 False 有一种比较常见的需求是判断字符串是否非空，那么直接 if bool(foo) 或者 if foo 即可。\nUse float() 那么有什么方法可以判断字符串是否为数字呢？这个需要先确定数字的范围，比如是否包含小数、负数、指数等等。\n使用 float 是个比较简便的方法：\ndef is_number(foo): try: float(foo.strip().replace(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39; \u0026#39;, \u0026#39;\u0026#39;)) except ValueError: return False return True 注意 float 对于 \u0026quot;inf\u0026quot; 会返回 inf 这个浮点数上限，在 Python 中会利用这个值做一些有用的数值比较。\n另外 float 类型的变量还有一个 is_integer 方法，用来判断整数很方便。\nValid Number Leetcode 上面有一道判断有效数字的题目是一个很好的练习，不仅需要考虑小数、指数和正负号，甚至 e 的大小写，Python float 中的 \u0026quot;inf\u0026quot; 和 \u0026quot;infinity\u0026quot; 都考察了。\n使用纯粹的条件判定虽然有些繁琐，但也并不是很困难。不过用正则或者有限状态机来解是更聪明的做法。\n状态机的做法单独整理一篇好了，这里略过不提。\nReferences\nUnicode numeric values and types - Wikipedia Isdecimal - Python Isdigit - Python Isnumeric - Python Check if a string is numeric\u0026hellip; What\u0026rsquo;s the difference between str.isdigit, is numeric and isdecimal in python - Stackoverflow ","permalink":"https://iamgodot.com/posts/numeric-strings-in-python/","summary":"Python 的字符串自带了三种判断字符是否为数字的方法，但实际用处却相差很多。\nTL;DR 三种方法 isdecimal \u0026lt; isdigit \u0026lt; isnumeric，即包含的范围越来越大 除了 ASCII 字符以外，对于 Unicode 的字符也都覆盖在内 三种方法对于小数点和负号都会返回 False 三种方法对于空字符串都会返回 False 比较简便判断数字字符串的方法：直接使用 float 方法并检测 ValueError Decimal \u0026amp; Digit \u0026amp; Numeric 对于 isdecimal, isdigit 和 isnumeric 三种方法，目的并不是判断字符串是不是一个有效数字，而是针对每一个字符的校验：\nisdecimal: 判断字符串中的字符是否都为 Decimal，也就是在 Unicode 中类别为 Nd 的字符 isdigit: 除了 isdecimal 包含的范围之外，还会判断字符是否都为 Digit，即 Unicode 的 Numeric_Type 为 Digit 或 Decimal isnumeric: 除了 isdigit 包含的范围之外，还会判断字符是否都为 Numeric，即 Numeric_Type 为 Numeric 所以这三种方法覆盖的字符范围，每一个都是前一个的超集。对于超出 ASCII 字符之外的效果，比如：\n\u0026ldquo;０１２３４５６７８９\u0026rdquo; 这种 Full-width 字符串 isdecimal 会判定为 True，后两个方法也一样 \u0026ldquo;⓪①②③④⑤⑥⑦⑧⑨\u0026rdquo; 这种 Circled-digit 字符串 isdecimal 判定 False，但 isdigit 和 isnumeric 为 True \u0026ldquo;一二三四五六七八九十壹貳參肆伍陸柒捌玖拾\u0026rdquo; 这种中文数字字符串只有 isnumeric 才会判定为 True 总之这几种方法有更广泛的用途，根本不是为了简单的 ASCII 数字字符串的判断。即使用来做判断的话，局限性也非常大，因为如果包含小数点和负号，三个方法都会返回 False.","title":"Numeric Strings in Python"},{"content":"Tcpdump 和 Wireshark 是抓包必备的程序，但是由于需要截取网络数据包，所以在 Linux 下必须以 root 的身份来运行。每次都 sudo 执行不方便也并不安全（对 Wireshark 来说捉包只是一小部分功能），解决方案当然有，在寻找的过程中我了解到了 Capabilities 的冰山一角。\nTL;DR 可以通过设置 Setuid 以 root 身份执行，但如此以来赋予了过高的权限（也没有必要）。 Linux 下用 Capabilities 把系统权限划分成多个条目，以此实现细粒度地提升程序的执行能力。 Setuid 先盗一张图复习下 Linux File Permission 的基础知识：\n除了 rwx 之外还存在三种特殊类型，即是为了在更高权限下运行程序：\nSetuid: 程序的运行者不再是执行者，而是变成文件的所有者 Setgid: 程序的运行群组变成了文件的所在群组，如果给目录设置，那么其中新建的文件所有群组会变成目录的群组而不是执行者的群组 Sticky bit: 针对目录设置，目录下的文件只有所有者和 root 能够重命名、移动和删除 在 Linux 中 sudo 是 Setuid 最好的例子，而 crontab 和 tmp/ 分别是 Setgid 和 Sticky bit 的典型应用。\n在命令行中测试：\n# Setuid ➜ ~ umask -S u=rwx,g=rx,o=rx ➜ ~ umask # 掩码是 022，所以默认文件的权限是 666-022=644，而目录则是 777-022=755 022 ➜ ~ touch foo.bar ➜ ~ l foo.bar -rw-r--r-- 1 godot godot 0 Nov 21 14:40 foo.bar ➜ ~ chmod u+s foo.bar # 也可以使用 chmod 4644 来 setuid ➜ ~ l foo.bar # 之所以 S 会大写是因为还没有赋予 execute 权限 -rwSr--r-- 1 godot godot 0 Nov 21 14:40 foo.bar ➜ ~ chmod u+x foo.bar ➜ ~ l foo.bar # 此时 s 变为正常小写 -rwsr--r-- 1 godot godot 0 Nov 21 14:40 foo.bar ➜ ~ chmod g+xs foo.bar # 可以使用 chmod 2644 来 setgid ➜ ~ l foo.bar -rwsr-sr-- 1 godot godot 0 Nov 21 14:48 foo.bar ➜ ~ mkdir foobar ➜ ~ l | grep foobar drwxr-xr-x 2 godot godot 4.0K Nov 21 14:50 foobar ➜ ~ chmod +t foobar # 可以使用 chmod 1755 来 set sticky bit ➜ ~ l | grep foobar drwxr-xr-t 2 godot godot 4.0K Nov 21 14:50 foobar 在 Tcpdump 上试试：\n➜ ~ l $(which tcpdump) -rwxr-xr-x 1 root root 1.3M Jun 10 18:46 /usr/bin/tcpdump ➜ ~ tcpdump tcpdump: wlp0s20f3: You don\u0026#39;t have permission to capture on that device (socket: Operation not permitted) ➜ ~ sudo chmod u+s /usr/bin/tcpdump ➜ ~ tcpdump tcpdump: verbose output suppressed, use -v[v]... for full protocol decode listening on wlp0s20f3, link-type EN10MB (Ethernet), snapshot length 262144 bytes 试验成功，Wireshark 是用 /usr/bin/dumpcap 来捉包的，所以用同样的方法 Setuid 即可。\n注意不要用 Shell Script 去测试 Setuid，因为 Linux 会忽略 Shebang 类的可执行文件，比如 #!/bin/sh 在文件开头的脚本。这会带来系统性的漏洞风险，参考 Allow-setuid-on-shell-scripts.\nCapabilities 从 Wireshark 的文档看到 Setuid 和 Setcap 都可以实现 Privilege Separation，也就是 GUI 的部分仍然按照普通用户的身份执行，而 Dumpcap 在更高的权限上运行。\n因为 Setuid 给予的权限过大，所以 Setcap 其实是更好的选择：\n# 需要确认 Wireshark 使用的是 /usr/bin/dumpcap 还是 /usr/sbin/dumpcap sudo setcap cap_net_raw,cap_net_admin+eip /usr/bin/dumpcap 那么 Capabilities 到底是什么？根据 Arch Wiki:\nCapabilities provide fine-grained control over superuser permissions, allowing use of the root user to be avoided. Software developers are encouraged to replace uses of the powerful setuid attribute in a system binary with a more minimal set of capabilities. Many packages make use of capabilities, such as CAP_NET_RAW being used for the ping binary provided by iputils. This enables e.g. ping to be run by a normal user (as with the setuid method), while at the same time limiting the security consequences of a potential vulnerability in ping.\n不过本地执行了下 getcap /usr/bin/ping 并没有看到相应的权限，但命令仍然是能正常使用的。\nCapabilities 实际上是通过 xattr(Extended Attributes) 来实现的，这是一种给文件增加额外属性的方式，所有的属性分为 Security, System, Trusted, User 四种，随便实验一下：\n➜ ~ touch foo.bar ➜ ~ setfattr -n user.foo -v bar foo.bar ➜ ~ getfattr -d foo.bar # file: foo.bar user.foo=\u0026#34;bar\u0026#34; ➜ ~ setfattr -x user.foo foo.bar # 删除属性 注意 Extended Attributes 不是默认被 cp 和 rsync 等程序保留的，所以使用的时候需要确认相关支持。比如 Capabilities 在使用 cp -a 的时候会自动复制，但是对于 rsync 来说则需要额外选项：rsync -X.\n在 Capabilities 之前，Linux 执行程序的权限分为 root 和非 root 两种，而现在系统的特权被分为不同的功能组，执行线程（进程）的时候只需要去检查组中的权限是否足够执行某个命令。\nCapabilities 相关的权限列表很长，我们要用到的有：\nCAP_NET_RAW: 允许使用原生 Socket CAP_NET_ADMIN: 允许执行网络相关操作 对文件来说，有三个集合来存放权限（Wireshark 使用 Setcap 就是把两个网络权限条目加入到 PIE 三个集合中）:\nPermitted Inheritable Effective 进程还有两个额外的集合：\nBounding Ambient 在调用 execve 方法执行程序时，内核会根据文件和进程的权限集合计算出最终的集合结果，然后判断权限是否足够执行。\n具体的计算逻辑比较复杂，参考这篇，等需要用的时候再继续研究。\nReferences\nWireshark - Archwiki Capabilities - Archwiki Extended Attributes - Archwiki ","permalink":"https://iamgodot.com/posts/from-wireshark-to-linux-capabilities/","summary":"Tcpdump 和 Wireshark 是抓包必备的程序，但是由于需要截取网络数据包，所以在 Linux 下必须以 root 的身份来运行。每次都 sudo 执行不方便也并不安全（对 Wireshark 来说捉包只是一小部分功能），解决方案当然有，在寻找的过程中我了解到了 Capabilities 的冰山一角。\nTL;DR 可以通过设置 Setuid 以 root 身份执行，但如此以来赋予了过高的权限（也没有必要）。 Linux 下用 Capabilities 把系统权限划分成多个条目，以此实现细粒度地提升程序的执行能力。 Setuid 先盗一张图复习下 Linux File Permission 的基础知识：\n除了 rwx 之外还存在三种特殊类型，即是为了在更高权限下运行程序：\nSetuid: 程序的运行者不再是执行者，而是变成文件的所有者 Setgid: 程序的运行群组变成了文件的所在群组，如果给目录设置，那么其中新建的文件所有群组会变成目录的群组而不是执行者的群组 Sticky bit: 针对目录设置，目录下的文件只有所有者和 root 能够重命名、移动和删除 在 Linux 中 sudo 是 Setuid 最好的例子，而 crontab 和 tmp/ 分别是 Setgid 和 Sticky bit 的典型应用。\n在命令行中测试：\n# Setuid ➜ ~ umask -S u=rwx,g=rx,o=rx ➜ ~ umask # 掩码是 022，所以默认文件的权限是 666-022=644，而目录则是 777-022=755 022 ➜ ~ touch foo.","title":"From Wireshark to Linux Capabilities"},{"content":"犹记得在 Java 中，int 占用 4 bytes 所以大小限制在 -2^32 和 2^32 -1 之间，如果考虑到溢出的情况，就要用 long 类型来转换。\n但是在 Python 中似乎从来没有考虑过类似的问题，也不记得 int 是占几个字节，那么是说 Python 的数字永远不会溢出吗？不可能吧。\n答案是对于 int 类型来说，可以认为不会；而 float 类型则需要注意溢出的情况。\n首先说 int 类型，打印 sys.maxsize 可以看到 Python 会根据系统是 32 位还是 64 位来确定一个上限值，这点与 Java 等语言一致。不同的是我们仍然可以使用比这个上限大（得多）的整数，因为 Python 支持的是 Arbitrary-precision arithmetic。也就是说为了突破 CPU 字长带来的运算限制，通过在软件层面模拟计算过程，是可以完成更高位数和精度的运算的。比如在公钥加密的场景下，经常需要对上百位的整数进行运算，这时候就需要在软件层面支持。\n这确实说明我们可以使用任意长度的 int 数字，只要不超出内存限制的话。因为如果给 Python 解释器分配了 2GB 内存，但是 2 * 1024 * 1024 * 1024 * 8 这么多位也不够表达的话，还是会出错的，只是并非 Overflow，而是 MemoryError.\n再说 float. 打印 sys.float_info.max 可以看到 float 的上限值，如果超出之后是会报错的，即 OverflowError. 可以这么来测试：\nIn [9]: m = 2 ** 100000 In [10]: m*.1 --------------------------------------------------------------------------- OverflowError Traceback (most recent call last) \u0026lt;ipython-input-10-03cfc6457eba\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 m*.1 OverflowError: int too large to convert to float 另外不要把这个上限与 float infinity 搞混了，因为在 Python 中可以用 float('inf') 来表示无限大，但它并非具体值，而是概念上的定义。如果非要比较的话，sys.float_info.max \u0026lt; float('inf') 是会返回 True 的。\nReferences\nArbitrary-precision arithmetic - Wikipedia OverflowError - Python Maxsize - Python How is there no integer overflow in Python? - Quora ","permalink":"https://iamgodot.com/posts/overflow-in-python/","summary":"犹记得在 Java 中，int 占用 4 bytes 所以大小限制在 -2^32 和 2^32 -1 之间，如果考虑到溢出的情况，就要用 long 类型来转换。\n但是在 Python 中似乎从来没有考虑过类似的问题，也不记得 int 是占几个字节，那么是说 Python 的数字永远不会溢出吗？不可能吧。\n答案是对于 int 类型来说，可以认为不会；而 float 类型则需要注意溢出的情况。\n首先说 int 类型，打印 sys.maxsize 可以看到 Python 会根据系统是 32 位还是 64 位来确定一个上限值，这点与 Java 等语言一致。不同的是我们仍然可以使用比这个上限大（得多）的整数，因为 Python 支持的是 Arbitrary-precision arithmetic。也就是说为了突破 CPU 字长带来的运算限制，通过在软件层面模拟计算过程，是可以完成更高位数和精度的运算的。比如在公钥加密的场景下，经常需要对上百位的整数进行运算，这时候就需要在软件层面支持。\n这确实说明我们可以使用任意长度的 int 数字，只要不超出内存限制的话。因为如果给 Python 解释器分配了 2GB 内存，但是 2 * 1024 * 1024 * 1024 * 8 这么多位也不够表达的话，还是会出错的，只是并非 Overflow，而是 MemoryError.\n再说 float. 打印 sys.float_info.max 可以看到 float 的上限值，如果超出之后是会报错的，即 OverflowError.","title":"Overflow in Python"},{"content":"在 Simple Recursion 之后，我一度把递归当作一种算法。但通过比较 Divide and Conquer 和 Dynamic Programming，我才发现之前的理解有点问题。\n一切还是要从 Algorithmic Paradigm 说起：\nAn algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.\n算法范式，是在算法的层面上抽象出来的一种更泛化的思想，常用的有：\nBrute-force search 暴力解法 Backtracking 回溯算法 Greedy algorithm 贪心算法 Divide and conquer 分治法 Dynamic programming 动态规划 Divide and Conquer 的基本思路是把复杂的问题分解成多个类似的简单问题，解决之后再组合起来得到最终结果。这种算法有很多应用，比如排序中的 Merge Sort，先将数列分解成单个元素，然后再归并，这时子数组都已经排好顺序了，所以过程很快。\n对于 DC 来说递归就成为一种很合适的实现方式，因为递归的调用是重复同一套逻辑，而 DC 中的问题和子问题也是相似的。但是这样性能会比较低下，因为很多子问题可能都是重复的，举 Fibonacci 的例子来说：\ndef fib(n): if n \u0026lt;= 0: return 0 if n == 1: return 1 return fib(n-2) + fib(n-1) 由于重复的子问题太多，最后的时间复杂度会高达 O(2^n). 此时就需要利用 Memoization 来优化，也就是缓存中间的计算结果，比如下面这个版本：\nfrom functools import cache @cache def fib(n): if n \u0026lt;= 0: return 0 if n == 1: return 1 return fib(n-2) + fib(n-1) 而这种解法实际上可以归类到另一种范式：动态规划。\nDynamic Programming 也是把问题划分成一个个小的子问题来解决，它包含两个要素：\n问题的最优解可以看成子问题的最优解的组合 子问题存在重复的情况，如 Fibonacci 的例子 如果不存在子问题的重复，而只需要求出各个子问题的最优解再合并的话，就变回 Divide and Conquer 而不算是 Dynamic Programming 了，比如 Merge Sort 和 Quick Sort.\n动态规划一般有两种实现思路：top-down 和 bottom-up. 上面缓存的写法就是 top-down，相当于把 n 从大到小地解决。而 bottom-up 可以用迭代来实现：\ndef fib(n): if n \u0026lt;= 0: return 0 if n == 1: return 1 x, y = 0, 1 for _ in range(1, n): x, y = y, x + y return y 此时可以更好地看出来，递归和算法范式并不是同一层面的概念。\n那么 Dynamic Programming 可以用递归实现 bottom-up 么？答案是肯定的，用尾递归：\ndef fib(n, x=0, y=1): if n \u0026lt;= 0: return 0 if n == 1: return 1 if n == 2: return x + y return fib(n - 1, y, x + y) 为什么这样就是 bottom-up 了呢，注意 x 和 y 的变化，是从 0 和 1 开始变化的，累积到最后 x+y 作为最终结果，所以是自底向上地解决了问题。至于尾递归，知乎上这个答案解释得很好：\n尾递归，比线性递归多一个参数，这个参数是上一次调用函数得到的结果；\n所以，关键点在于，尾递归每次调用都在收集结果，避免了线性递归不收集结果只能依次展开消耗内存的坏处。\n因为尾递归需要参数来保存中间结果，所以函数定义不像普通递归那么简洁，有两种方法可以解决，一种是像上面代码中一样使用参数默认值，还有一种就是柯里化，简单来说就是二次封装，在 Python 中可以用 partial 轻松完成:\nfrom functools import partial f = partial(fib, x=0, y=1) 尾递归的效率很高，因为不需要返回上一级调用，所以不会出现栈溢出的情况。类似 GOTO 关键字，经过优化的汇编代码会直接 JUMP 到下一个调用而不用保留之前的内部信息。\n但是这种优化需要编译器的支持，并不是所有语言都会兼容尾递归的优化，比如 Python 一直就没有 TCO(Tail Call Optimization). 其中一个重要原因就是会影响 Debug 时查看对应的栈信息，具体可以参考 Guido 叔的博客（见 References）。\n同样，尾递归只是手段，可以用它来实现 Dynamic Programming，也可以用其他的方法，比如迭代（比如 Fibonacci 中迭代的复杂度更低，因为只需要 O(1) 的空间）。DP 的关键在于 Memoization 而不是递归，这也说明了方法和原理的关系，前者可以达到目的，但是代替不了后者本身。\nReferences\nAlgorithmic paradigm - Wikipedia Divide and Conquer - Wikipedia Dynamic Programming - Wikipedia Tail Call - Wikipedia 尾调用优化 - 阮一峰 柯里化 - Wikipedia Tail Recursion Elimination - Guido Final Words on Tail Calls - Guido ","permalink":"https://iamgodot.com/posts/understand-recursion-better/","summary":"在 Simple Recursion 之后，我一度把递归当作一种算法。但通过比较 Divide and Conquer 和 Dynamic Programming，我才发现之前的理解有点问题。\n一切还是要从 Algorithmic Paradigm 说起：\nAn algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.\n算法范式，是在算法的层面上抽象出来的一种更泛化的思想，常用的有：\nBrute-force search 暴力解法 Backtracking 回溯算法 Greedy algorithm 贪心算法 Divide and conquer 分治法 Dynamic programming 动态规划 Divide and Conquer 的基本思路是把复杂的问题分解成多个类似的简单问题，解决之后再组合起来得到最终结果。这种算法有很多应用，比如排序中的 Merge Sort，先将数列分解成单个元素，然后再归并，这时子数组都已经排好顺序了，所以过程很快。","title":"Understand Recursion Better"},{"content":"这几天在做一个 CLI 项目，因为涉及到命令行操作，所以想录制一段 GIF 放在 README 中展示。\n印象里这种工具都是 JS 写的，但搜了搜居然发现有个 Python 的实现：asciinema\n用法很简单，就是安装好之后在命令行执行 asciinema rec 便会启动一个新的 Shell 并开始录制，录制的时候就像正常使用 Terminal 一样即可，完成之后按 Ctrl-D 或者 Exit 退出，asciinema 会把录制好的 cast 文件保存到本地，也可以选择上传到他们的网站：asciinema.org.\n那么 cast 文件是什么，又怎样得到 GIF 呢？其实这是 asciinema 自己定义的一种文件格式：\nA CAST file is a record of a terminal session recorded using asciinema, an open source terminal recording program. It contains a JSON-formatted header and a timestamped record of the text typed and printed during a terminal session.\n文件内容大概是这个样子的：\n{\u0026#34;version\u0026#34;: 2, \u0026#34;width\u0026#34;: 124, \u0026#34;height\u0026#34;: 63, \u0026#34;timestamp\u0026#34;: 1636292616, \u0026#34;env\u0026#34;: {\u0026#34;SHELL\u0026#34;: \u0026#34;/usr/bin/zsh\u0026#34;, \u0026#34;TERM\u0026#34;: \u0026#34;screen-256color\u0026#34;}} [1.538309, \u0026#34;o\u0026#34;, \u0026#34;#\u0026#34;] [1.915683, \u0026#34;o\u0026#34;, \u0026#34;\\b# \u0026#34;] [2.335422, \u0026#34;o\u0026#34;, \u0026#34;l\u0026#34;] [2.405338, \u0026#34;o\u0026#34;, \u0026#34;e\u0026#34;] [2.524792, \u0026#34;o\u0026#34;, \u0026#34;t\u0026#34;] [3.010565, \u0026#34;o\u0026#34;, \u0026#34;\u0026#39;\u0026#34;] [3.13154, \u0026#34;o\u0026#34;, \u0026#34;s\u0026#34;] 就像描述里说的，第一行是 JSON 格式的 header，里面存放了一些 Terminal 的元信息，比如尺寸和环境变量。下面的每一行数据都包含了时间戳和对应的终端打印信息，也就是在录制的时候键入的命令以及输出。\n对于 cast 文件，还可以直接用 asciinema 在终端回放录制的内容，比如 asciinema play -i 2 demo.cast 可以以两倍速播放。\n从官方 Issue 看，asciinema 本身目前还不支持直接导出 GIF 文件，不过其他的工具应运而生，比如：asciicast2gif.\n这个工具主要是用 JS 来解析 cast 文件并且生成若干张 PNG 图片，再调用 ImageMagick 和 gifsicle 这两个工具合成出最终的 GIF 文件：\nasciicast2gif shell script parses command line arguments and executes Node.js script (main.js). main.js loads asciicast (either from remote URL or local filesystem), generates text representation of the screen for each frame using asciinema-player\u0026rsquo;s virtual terminal emulator, and sends it to PhantomJS-based renderer script (renderer.js), which saves PNG screenshots to a temporary directory. Finally, main.js calls ImageMagick\u0026rsquo;s convert on these PNG images to construct GIF animation, also piping it to gifsicle to get the final, optimized GIF file.\n我不想在本地用 NPM 安装，所以选择了他们的 Docker 镜像试用，结果却没有想象中的顺利。原因大概是录制的时间较长（其实也就几分钟），生成的 cast 文件有 27K 左右，尝试渲染之后报错。在 Issue 查到是由于图片数量太多，gifsicle 合成失败。\n不成熟的工具用起来就是不顺手，正在纠结要不要进坑，又发现了一个在线转换 cast 为 gif 的网站：gifcast.\n试了一下异常顺利，而且网页的好处是可以预览各种 Theme 的效果，如下图：\n可能是 GIF 比较大，直接把图床的 Link 放到 README 里面加载得太慢，于是我还是选择把文件放到 REPO 里面并用 Relative Path 的方式引用。\n之后在 GitHub 上面打开展示的效果还是不错的，这里贴一下：\nReferences\nAsciinema - 录制终端工具 Gifcast - 转换 cast 文件为 GIF ","permalink":"https://iamgodot.com/posts/record-terminal/","summary":"这几天在做一个 CLI 项目，因为涉及到命令行操作，所以想录制一段 GIF 放在 README 中展示。\n印象里这种工具都是 JS 写的，但搜了搜居然发现有个 Python 的实现：asciinema\n用法很简单，就是安装好之后在命令行执行 asciinema rec 便会启动一个新的 Shell 并开始录制，录制的时候就像正常使用 Terminal 一样即可，完成之后按 Ctrl-D 或者 Exit 退出，asciinema 会把录制好的 cast 文件保存到本地，也可以选择上传到他们的网站：asciinema.org.\n那么 cast 文件是什么，又怎样得到 GIF 呢？其实这是 asciinema 自己定义的一种文件格式：\nA CAST file is a record of a terminal session recorded using asciinema, an open source terminal recording program. It contains a JSON-formatted header and a timestamped record of the text typed and printed during a terminal session.","title":"Record Terminal as GIF"},{"content":"无意中看到一种叫 look-and-say 的数列，很有意思，有点儿 Fibonacci 的感觉。数列如下：\n1, 11, 21, 1211, 111221, 312211, 13112221, 1113213211, \u0026hellip;\n从第二位开始，每个数字都是对前一个数的计数结果的描述。比如 11 表示前面的 1 有一个 1，而 21 表示前面的 11 有两个 1，1121 表示 21 有一个 2 和一个 1，依次类推，可以无穷循环出新的结果。（除了 22 这个数字，因为会一直重复 22 本身）\n后来查了查才发现原来 Leetcode 也有这道题，不过名字叫做 count-and-say。基本就是给 n 然后求此数列的第 n 项结果。\n想了想思路并不难，无非是对一个数字的所有位数循环再计数就好了，不过写的时候很犯难，竟然还写出了一个无比冗长的 for 循环加 if 面条代码。这让我意识到了自己对于循环的认识有多么不够深刻。\n之所以犯难，其实是不知道怎样把几种逻辑合并在一起，如果粗暴地列举所有分支大概是这样：\ndef find_next(num: str): result = \u0026#39;\u0026#39; cur, count = num[0], 1 size = len(num) for i in range(1, size): if num[i] == cur and i == size - 1: # count 加一 # 更新 result elif num[i] == cur: # count 加一 elif i == size - 1: # 更新 result # 更新 cur\u0026amp;count # 更新 result else: # 更新 result # 更新 cur\u0026amp;count # 还有一种情况就是并没有进入 for 循环 # 那么也需要更新 result 直接按照这些分支把代码填满肯定很难看，所以要挑选合并。看起来只有第二个分支不需要更新 result，于是我决定把它单拎出来：如果 num[i]==cur 那么 count 加一；否则就更新 result 以及 cur\u0026amp;count. 那么 i==size-1 的时候怎么办呢，既要保存当前结果又可能需要记录新的结果，一筹莫展。不过后来还是发现了巧妙的写法：\ndef find_next(num: str): result = \u0026#39;\u0026#39; cur, count = num[0], 1 for char in num[1:]: if char == cur: count += 1 continue result += f\u0026#39;{count}{cur}\u0026#39; cur = char count = 1 return f\u0026#39;{result}{count}{cur}\u0026#39; 优点在于结合了 count\u0026amp;cur 放在返回值里面，通过这两个变量做缓存，就不需要单独考虑循环到最后一位和没有进入循环的情况了，于是 for 循环也可以直接遍历元素值而不是下标。\n我正觉得这段写得精彩，却又看到了使用 while 的解法。什么，为什么会是 while 呢，明明容器长度是已知的，要用 for 才对啊。先看代码：\ndef find_next(num: str): result = \u0026#39;\u0026#39; start = cur = 0 size = len(num) while cur \u0026lt; size: while cur \u0026lt; size and num[cur] == num[start]: cur += 1 result += str(cur - start) + num[start] start = cur return result 虽然我觉得 while 循环是比 for 的可读性要差的，但不得不承认这里的嵌套 while 写法更好，关键在于更符合思考的过程。如果是手动来数的话，也是整体一个大循环，然后对重复的数字不断加一，直到有变化，就先记录前面的结果再继续数新的数字。反而在上面巧妙的 for 循环中，是不太容易想到返回时把 result, count, cur 三者组合到一起的。\n而且这里的 while 代码也很简洁。既复用了内部循环的 cur += 1，又节省了单独的 count 变量来计数。\n所以大概可能也许是，虽然已知元素的总数，但是在更符合抽象逻辑的情况下用 while 会更好吧。\n说来自己写循环的时候总会遇到几个惯性 bug：\n下标越界或者下标类型不是 int 遍历的过程中修改更新容器本身 写 while 不注意退出条件导致无限循环 不知道有没有更智能的编辑器（插件）能自动识别循环代码中的 bug 呢 - -.\nReferences\nLook and say - Wikipedia Count and say - Leetcode ","permalink":"https://iamgodot.com/posts/look-and-say/","summary":"无意中看到一种叫 look-and-say 的数列，很有意思，有点儿 Fibonacci 的感觉。数列如下：\n1, 11, 21, 1211, 111221, 312211, 13112221, 1113213211, \u0026hellip;\n从第二位开始，每个数字都是对前一个数的计数结果的描述。比如 11 表示前面的 1 有一个 1，而 21 表示前面的 11 有两个 1，1121 表示 21 有一个 2 和一个 1，依次类推，可以无穷循环出新的结果。（除了 22 这个数字，因为会一直重复 22 本身）\n后来查了查才发现原来 Leetcode 也有这道题，不过名字叫做 count-and-say。基本就是给 n 然后求此数列的第 n 项结果。\n想了想思路并不难，无非是对一个数字的所有位数循环再计数就好了，不过写的时候很犯难，竟然还写出了一个无比冗长的 for 循环加 if 面条代码。这让我意识到了自己对于循环的认识有多么不够深刻。\n之所以犯难，其实是不知道怎样把几种逻辑合并在一起，如果粗暴地列举所有分支大概是这样：\ndef find_next(num: str): result = \u0026#39;\u0026#39; cur, count = num[0], 1 size = len(num) for i in range(1, size): if num[i] == cur and i == size - 1: # count 加一 # 更新 result elif num[i] == cur: # count 加一 elif i == size - 1: # 更新 result # 更新 cur\u0026amp;count # 更新 result else: # 更新 result # 更新 cur\u0026amp;count # 还有一种情况就是并没有进入 for 循环 # 那么也需要更新 result 直接按照这些分支把代码填满肯定很难看，所以要挑选合并。看起来只有第二个分支不需要更新 result，于是我决定把它单拎出来：如果 num[i]==cur 那么 count 加一；否则就更新 result 以及 cur\u0026amp;count.","title":"Look and Say"},{"content":"祸从天降的一天。\n早上起不来，于是刷手机清醒一下，突然看到一个 ACMer 楼主提到自己没有刷过 Leetcode，面试的时候差点儿被打脸了。\n看了一下题目，要求是 O(logn) 的复杂度，默默想了想，没有特别清晰的思路。\n结果翻了翻评论，很多人都在蜻蜓点水般地表示二分查找不断分割就可以了。\n要那么简单还用你说吗？起床了起床了。\n题目是这样的：\n给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数。\n我本来的想法是归并之后计算中位数，但只能做到 O(m+n)，再优化感觉只能二分了。\n于是又开始想分别取两个数组的中位数，比较之后就可以各扔掉一半，然后对两个折半的数组继续取中位数比较。\n比如一开始找到的中位数是这样：[\u0026hellip;5\u0026hellip;], [\u0026hellip;10\u0026hellip;]，那么 5 的左边和 10 的右边就可以丢掉了，因为最终的中位数肯定在 5 和 10 中间。\n如果接下来是这样：[5..8\u0026hellip;], [\u0026hellip;7..10]，那么 8 的右边和 7 的左边也可以丢掉，因为比 8 大的元素数量达不到这两个小数组的一半，所以中位数不会在里面，比 7 小的同理。\n一直重复这个流程，最后得到的肯定就是一个或两个数，平均下就好了，时间复杂度也是符合要求的 O(logn).\n结果等到看完标答后我才反应过来自己错在哪里了，这是后话。（因为 m 和 n 不一定一样大，所以显然折半的逻辑不对）\n最优的解决方案是可以做到 O(log min(m, n)) 的，核心也是二分法，不过思路要复杂一些：\n首先明确中位数的定义。对于奇数个数字来说是最中间的元素，偶数则是中间两个元素的平均值。 要做的是将两个数组各分一刀，假设划分的下标分别是 i 和 j，那么 nums1 被分成 nums1[0, i], nums1[i:]，而 nums2 分为 nums2[0, j], nums2[j:]. 因为数组中元素的数量是奇是偶不一定，所以规定好是奇数的话多的一个放到左边。如此 i 的位置就是右边部分的第一个，而左半边正好有 i 个元素。 下标 i 和 j 之间是存在一个等式关系的，因为是中位数，所以 i + j 等于元素总数的一半，或者一半多一个（因为说好了左边多一个嘛）。那么就有 i+j=(m+n)/2 | i+j=(m+n)/2+1，合并起来写成 (m+n+1)/2. 一开始 i 的选择就先定在 nums1 的中间位置，然后根据规则不断地二分，如此就完成了最核心的循环。那么根据什么规则呢？就是两个左半部分不能大于两个右半部分，也就是 nums1[i-1]\u0026lt;=nums2[j] \u0026amp; nums2[j-1]\u0026lt;=nums1[i]. 还要注意的是 i 不是每次向左或向右移动一位，而是要按照二分的规则走，不然就变成线性的复杂度了。 解决了核心逻辑，还有两个问题要考虑： 1. 中位数计算。走完了循环我们可以获得四个数值，也就是 i-1, i, j-1, j 对应的四个元素。 1. 如果元素总数是奇数的话，我们比较 nums1[i-1] 和 nums2[j-1] 取个大的就好了（还是那句话，说好了左边多一个嘛）。 2. 否则就要取中间两个数平均了。这两个数就是两个左边的最大值，和两个右边的最小值。 2. 边界条件。之所以后说这个是因为中位数计算的时候不考虑边界就会报错，比如对 i 来说，如果 i=0 或者 i=m 的话都是会出界的，所以要分别处理。 1. 如果 i=0，说明 nums1 的左半部分为空，那么就假设这里的最大值为无限小，这样比较的话就相当于只考虑 nums2 的左半部分了。 2. 如果 i=m，说明 nums1 的右半部分为空，那么就假设这里的最小值为无限大，这样比较的话就相当于只考虑 nums2 的右半部分了。 上代码：\ndef find_median(nums1, nums2): if len(nums1) \u0026gt; len(nums2): nums1, nums2 = nums2, nums1 m, n = len(nums1), len(nums2) left, right = 0, m total_left = (m + n + 1) // 2 # 注意用 // 而不是 /，因为下标不能是浮点数 while left \u0026lt; right: i = left + (right - left + 1) // 2 # 注意用 // 而不是 /，因为下标不能是浮点数 j = total_left - i if nums1[i - 1] \u0026gt; nums2[j]: right = i - 1 else: left = i i, j = left, total_left - left first_left_max = nums1[i - 1] if i \u0026gt; 0 else -float(\u0026#34;inf\u0026#34;) first_right_min = nums1[i] if i \u0026lt; m else float(\u0026#34;inf\u0026#34;) second_left_max = nums2[j - 1] if j \u0026gt; 0 else -float(\u0026#34;inf\u0026#34;) second_right_min = nums2[j] if j \u0026lt; n else float(\u0026#34;inf\u0026#34;) if (m + n) % 2 == 1: return max(first_left_max, second_left_max) else: return ( max(first_left_max, second_left_max) + min(first_right_min, second_right_min) ) / 2 用 Python 实现的话，有两点需要注意：\n计算 total_left 和 i 的时候要用 //. 使用 float(\u0026quot;inf\u0026quot;) 来表示极大值，加负号表示极小值。 到了这里基本就结束了，但是仔细看会发现函数的一开始会比较两个数组的长度，进而保证 nums1 是长度更短的那一个。\n这是因为如果 nums1 非常长而 nums2 很短会造成 j = total_left - i 计算出来的 j 超过 nums2 的长度而出界。\n而这是因为 i 是根据 left 和 right 计算得到的（也就是 m），从而能保证界限，j 是减出来的就不一定保险了。\n最后来看一下这种方法的复杂度，因为保证了 nums1 较短，所以二分得到的时间复杂度为 O(logmin(m, n))，空间复杂度 O(1).\n虽说上面的解法最优，但并不是一个很通用的方案，可以找到中位数，但对于求 k 位数这种问题就解决不了了。又看了下官方次优的解法，虽然时间复杂度为 O(log(m+n))，但是更普适：\n分别找出两个数组的 k/2-1 的位置，那么这个位置前面有 k/2-1 个元素。 两个位置上的元素分别成为 pivot1, pivot2，如果 pivot1 的值小于 pivot2 的值，则可以舍弃 pivot1 及前面的 k/2-1 个元素。（因为即使 pivot2 前面的元素都小于 pivot1，pivot1 最多也就是第 k-1 大的元素，中位数肯定不在其中） 去掉了这部分元素之后 nums1 就相当于变短了，而 nums2 不变，于是基于这两个数组继续。 同时也要记得更新 k 值，因为已经去掉一部分元素了，所以 k 变为了原来的一半。 继续此流程。当然过程中还要注意空数组、下标越界和 k=1 等边界情况。 此处不贴代码了，见官方答案。 实现代码如下：\ndef find_median(nums1, nums2): def find_kth_element(k, nums1, nums2): \u0026#39;\u0026#39;\u0026#39;注意 k 是从 1 开始而不是 0\u0026#39;\u0026#39;\u0026#39; m, n = len(nums1), len(nums2) start1, start2 = 0, 0 while True: if start1 == m: return nums2[start2 + k - 1] if start2 == n: return nums1[start1 + k - 1] if k == 1: return min(nums1[start1], nums2[start2]) # 因为 if 检查在上面，所以要取 min 防止下面 nums1[i] 或 nums2[j] 越界 i = min(start1 + k // 2 - 1, m - 1) j = min(start2 + k // 2 - 1, n - 1) if nums1[i] \u0026lt;= nums2[j]: # k 的更新基于 start1，所以先改 k 再改 start1 k -= i - start1 + 1 start1 = i + 1 else: k -= j - start2 + 1 start2 = j + 1 length = len(nums1) + len(nums2) if length % 2 == 1: return find_kth_element(length // 2 + 1, nums1, nums2) else: return ( find_kth_element(length // 2, nums1, nums2) + find_kth_element(length // 2 + 1, nums1, nums2) ) / 2 整理完思路和代码已经是下午了，疲惫地什么都不想做。刷手机须谨慎，有风险别乱看。\nReferences\nMedia of two sorted arrays 官方答案 - Leetcode 个人觉得比较容易理解的答案 - Leetcode ","permalink":"https://iamgodot.com/posts/find-median/","summary":"祸从天降的一天。\n早上起不来，于是刷手机清醒一下，突然看到一个 ACMer 楼主提到自己没有刷过 Leetcode，面试的时候差点儿被打脸了。\n看了一下题目，要求是 O(logn) 的复杂度，默默想了想，没有特别清晰的思路。\n结果翻了翻评论，很多人都在蜻蜓点水般地表示二分查找不断分割就可以了。\n要那么简单还用你说吗？起床了起床了。\n题目是这样的：\n给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数。\n我本来的想法是归并之后计算中位数，但只能做到 O(m+n)，再优化感觉只能二分了。\n于是又开始想分别取两个数组的中位数，比较之后就可以各扔掉一半，然后对两个折半的数组继续取中位数比较。\n比如一开始找到的中位数是这样：[\u0026hellip;5\u0026hellip;], [\u0026hellip;10\u0026hellip;]，那么 5 的左边和 10 的右边就可以丢掉了，因为最终的中位数肯定在 5 和 10 中间。\n如果接下来是这样：[5..8\u0026hellip;], [\u0026hellip;7..10]，那么 8 的右边和 7 的左边也可以丢掉，因为比 8 大的元素数量达不到这两个小数组的一半，所以中位数不会在里面，比 7 小的同理。\n一直重复这个流程，最后得到的肯定就是一个或两个数，平均下就好了，时间复杂度也是符合要求的 O(logn).\n结果等到看完标答后我才反应过来自己错在哪里了，这是后话。（因为 m 和 n 不一定一样大，所以显然折半的逻辑不对）\n最优的解决方案是可以做到 O(log min(m, n)) 的，核心也是二分法，不过思路要复杂一些：\n首先明确中位数的定义。对于奇数个数字来说是最中间的元素，偶数则是中间两个元素的平均值。 要做的是将两个数组各分一刀，假设划分的下标分别是 i 和 j，那么 nums1 被分成 nums1[0, i], nums1[i:]，而 nums2 分为 nums2[0, j], nums2[j:]. 因为数组中元素的数量是奇是偶不一定，所以规定好是奇数的话多的一个放到左边。如此 i 的位置就是右边部分的第一个，而左半边正好有 i 个元素。 下标 i 和 j 之间是存在一个等式关系的，因为是中位数，所以 i + j 等于元素总数的一半，或者一半多一个（因为说好了左边多一个嘛）。那么就有 i+j=(m+n)/2 | i+j=(m+n)/2+1，合并起来写成 (m+n+1)/2.","title":"Find Median"},{"content":"近来刷题，觉得递归实在神奇。对于有的题目，用循环实现思路很清晰，改成递归却变得非常抽象；另一些相反，递归的做法既简洁又容易理解，但换成迭代就怎样都不明白了。经过几次痛苦的思考之后，我发现其中还是有迹可循的，按照套路来做，至少思路不会走得太偏。\n在维基上面发现的关于递归的笑话：\nTo understand recursion, you must understand recursion.\nWrite Recursion 审题分析过后，如果选择用递归，需要先明确两个最重要的组成部分：\n边界条件，保证函数能够返回，不会无限递归下去 递进关系，也就是上下层递归调用结果的等式规律 比如求 factorial：\ndef factorial(n): if n \u0026lt;= 2: return n return factorial(n - 1) * n 如果必要的话，还得考虑的是如何维护上下文的状态信息，目的是计算最终的返回值，有两种办法：\n使用全局（outer scope）变量 利用参数进行传递 下面的写法就是利用了参数来保存中间的计算结果：\ndef factorial(n, res): if n \u0026lt;= 2: return res * n return factorial(n - 1, res * n) 也就是所谓的尾递归，对于可以优化尾递归的语言确实可以看成这种方式是从上至下的，而常规的递归则是从下到上。但我理解递归都是先下去再上来的，尾递归只是选择了一去不返而已。\n上面的例子比较简单，反转链表的代码就比较难理解一点：\ndef reverse_list(head): if not head or not head.next: return head new_head = reverse_list_by_recursion(head.next) head.next.next = head head.next = None return new_head 其实精髓在于倒数第二三行，因为抛开边界条件和递归调用之外，还需要增加每个节点掉转的辅助逻辑。\n然而有时递归并不是重点，如果没有找好规律仍然是写不出来的，比如二叉树的层序遍历：\ndef levelorder(root): res = [] def _order(root, level): if not root: return if len(res) == level: res.append([]) res[level].append(root.val) _order(root.left, level + 1) _order(root.right, level + 1) _order(root, 0) return res 这里的上下文既用到了外层变量，也借助了中间参数，但难点并不在这里，而是在递归的思想下实现 BFS. 举这个例子想说的是递归题写不出来，不一定是递归学的不好，可能只是别的规律没有摸清楚。\n写完之后，做一些检查也是必要的：\n极端参数值的情况是否满足要求，比如 n \u0026lt; 0\n是否能够保证正常跳出，是否会导致栈溢出\n递归深度是否过多，数据有没有可能溢出\n是否存在重复计算，见下面的 Fibonacci\n是否可以做尾递归优化，或者用循环实现\nRewrite Recursion 对递归的模拟当然离不开循环，但是有的时候未必需要用栈，还有时候则非要用不可。\n第一种针对的递归通常比较简单，比如经典的 Fibonacci:\nfrom functools import cache @cache def fib(n): if n \u0026lt;= 1: return n else: return fib(n-2) + fib(n-1) 因为这种递归时间复杂度会高达 2^n，所以要加上 cache 保存数据。那么如何改写呢，非常简单，甚至不需要基于递归的写法思考：\ndef fib(n): if n \u0026lt;= 1: return n x, y = 0, 1 for _ in range(1, n): x, y = y, x + y return y 另外像求 power 或者 factorial 都是类似的情况。\n但第二种就会比较复杂，也就是需要使用 stack 这种数据结构，实际上编译器在背后也是以这样的方式实现递归代码的。举个快速排序的例子来说明，首先是递归做法：\ndef quick_sort(nums, left, right): if left \u0026gt;= right: return pivot, i, j = left, left, right while i \u0026lt; j: while nums[j] \u0026gt;= nums[pivot] and i \u0026lt; j: j -= 1 while nums[i] \u0026lt;= nums[pivot] and i \u0026lt; j: i += 1 if i \u0026lt; j: nums[i], nums[j] = nums[j], nums[i] nums[pivot], nums[i] = nums[i], nums[pivot] quick_sort(nums, left, i - 1) quick_sort(nums, i + 1, right) 前面的逻辑都在把数列分成大小两部分，重点在最后两行，也就是按照 Divide and Conquer 的思路对左右两组数分别继续进行排序。\n那么如何改写呢，先继续递归的逻辑往后推想，如果开始给左边组数排序的话，肯定要保留现场，这里就是右边组数的 index，即 i + 1 和 right 的值，不然回来的时候就定位不到了。这个保留操作就对应入栈操作。\n同理，何时出栈呢，肯定是递归调用返回的时候，要用保存的 index 做情景再现。\n于是有了迭代的写法：\ndef quick_sort_with_stack(nums, left, right): stack = list() while left \u0026lt; right or stack: if left \u0026lt; right: pivot, i, j = left, left, right while i \u0026lt; j: while nums[j] \u0026gt;= nums[pivot] and i \u0026lt; j: j -= 1 while nums[i] \u0026lt;= nums[pivot] and i \u0026lt; j: i += 1 if i \u0026lt; j: nums[i], nums[j] = nums[j], nums[i] nums[pivot], nums[i] = nums[i], nums[pivot] stack.append([i + 1, right]) right = i - 1 else: left, right = stack.pop() 可以看到，对应递归写法中每次进入下一层的时候，这里就会做入栈保存，然后更新变量（right），来模拟新的调用过程；而返回的时候，又会出栈，复原原来的 left 和 right.\n还有就是外层的 while 循环，前面的条件对应快排逻辑本身的要求，后者控制递归调用返回的时机。\n另外一个经典题目是二叉树的中序遍历，递归版本非常简单：\ndef inorder(root, result): if not root: return inorder(root.left) result.append(root.val) inorder(root.right) 可以看到和快速排序的区别是，需要先处理左子节点，然后是将节点值加入列表的逻辑，最后再处理右子节点。因为上来就做递归调用，所以改写的话也要先进行入栈操作，直到开始出栈的时候再执行逻辑，之后再（为右子节点）入栈出栈。实现如下：\ndef inorder(root): stack, res = [], [] cur = root while cur or stack: if cur: stack.append(cur) cur = cur.left else: cur = stack.pop() res.append(cur.val) cur = cur.right return res 其实 while loop 和 stack push/pop 都和快排差不多，只是对于栈来说，快排会先全部入栈再出栈，而这里会入栈出栈多遍，分别对应左子节点们和右子节点们。原因就是因为 append 逻辑夹在了两个递归调用之间，如果是先序遍历则会简单很多。\n总结起来就是确定要不要用栈，如果需要的话，想清楚：\nwhile 循环的条件，针对 base case 和 stack 栈保存的数据是什么，用什么结构 入栈和出栈的时间点 递归是一种很聪明的做法，逻辑简单清晰，可以把代码写得很优雅。缺点也很明显，极端情况下容易导致栈溢出，而且如果没有优化好，复杂度也可能会很高，毕竟用（普通）递归首先就难免调用带来的栈空间消耗。\n又想到维基上还有另一个笑话：\nRecursion, see Recursion.\nReferences\nRecursion - Wikipedia 如何写递归 - Leetcode ","permalink":"https://iamgodot.com/posts/simple-recursion/","summary":"近来刷题，觉得递归实在神奇。对于有的题目，用循环实现思路很清晰，改成递归却变得非常抽象；另一些相反，递归的做法既简洁又容易理解，但换成迭代就怎样都不明白了。经过几次痛苦的思考之后，我发现其中还是有迹可循的，按照套路来做，至少思路不会走得太偏。\n在维基上面发现的关于递归的笑话：\nTo understand recursion, you must understand recursion.\nWrite Recursion 审题分析过后，如果选择用递归，需要先明确两个最重要的组成部分：\n边界条件，保证函数能够返回，不会无限递归下去 递进关系，也就是上下层递归调用结果的等式规律 比如求 factorial：\ndef factorial(n): if n \u0026lt;= 2: return n return factorial(n - 1) * n 如果必要的话，还得考虑的是如何维护上下文的状态信息，目的是计算最终的返回值，有两种办法：\n使用全局（outer scope）变量 利用参数进行传递 下面的写法就是利用了参数来保存中间的计算结果：\ndef factorial(n, res): if n \u0026lt;= 2: return res * n return factorial(n - 1, res * n) 也就是所谓的尾递归，对于可以优化尾递归的语言确实可以看成这种方式是从上至下的，而常规的递归则是从下到上。但我理解递归都是先下去再上来的，尾递归只是选择了一去不返而已。\n上面的例子比较简单，反转链表的代码就比较难理解一点：\ndef reverse_list(head): if not head or not head.next: return head new_head = reverse_list_by_recursion(head.next) head.next.next = head head.","title":"(Re)Write recursions easily"},{"content":"这是一篇使用（过） Linux Xorg without any DE 以及笔记本外接键盘的人才能理解其中辛酸苦痛的抒情科普文。\nTL;DR 外接键盘不要开蓝牙，直接插线，除非你乐意折腾 使用 setxkbmap 而不是 xmodmap 来做 key remapping 不要用 Xorg The Irrational Part 上午十点零一分，端坐到显示器前，深呼吸两次。\nOk，回滚内核版本之后 Screen Lock 卡死的问题果然消失了，我们继续。\n进入系统，先看一下昨晚的日志吧：\n... 需求目标： 1. 交换 L-Ctrl \u0026amp; Caps-Lock 2. 交换 Win \u0026amp; Alt 当前方案： 使用 xmodmap 自定义配置文件，在 startx 时执行 已知问题： 1. 系统挂起或蓝牙睡眠导致的 keyboard reconnection 会 reset 掉 Win\u0026amp;Alt 的交换 2. 之后重新执行 xmodmap 会导致 L-Ctrl\u0026amp;Caps-Lock 交换回原状，必须执行两次 后续跟进： 1. TTY console switch 快捷键不可用 2. Terminate X 快捷键 CAB(Ctrl-Alt-Backspace) 不可用 3. Keyboard backlight ... 唔，大概记起来了，昨晚改用了 setxkbmap 之后应该可以解决重连的问题了，不过奇怪的是 ctrl:swapcaps 的 option 一直没有生效，折腾到半夜也没好..\n难道是有什么地方又去执行 xmodmap 了？奇怪，在 .xinitrc 里面已经把判断代码注释掉了呀，不管了，删除 ~/.Xmodmap 再说，反正是个软链接。\n哈，居然成功了！看来就是这个原因，估计这也是已知问题 1 的根源，xmodmap 的设置被 setxkbmap 重置了，果然直接用后者是明智的。\n不过可惜之前查了半天才解决的 .xinitrc 里面 xmodmap 执行顺序问题了：\n... if [ -f $HOME/.Xmodmap ]; then (sleep 1; xmodmap $HOME/.Xmodmap) \u0026amp; fi exec i3 ... 虽然多花了 1s 的开机时间，但毕竟规避掉了 xmodmap 设置被 wm 莫名其妙 reset 的难点，不过现在也不需要了，唔，白搞了半天..\nSetxkbmap 的 rule setting 就是好，这下插拔外接键盘 USB 也不会 reset 改键映射了。不过如果用蓝牙的话好像还不够，至少得配置 udev rule 开启蓝牙键盘唤醒再 run 个 remapping 的脚本才好，如此剩下就是背光了\u0026hellip;\n咦，好像又过去两个小时了？\n\u0026hellip;\n站起来，默默找出键盘连接线，插好，保存唯一的 setxkbmap 配置，重启。\n进入系统，改键映射正常，拔开 USB，重插，一切正常。唔，背光真好看。\n看下时间，五分钟。唔，终于清静了。\nThe Rational Part Keyboard mapping 用惯 Vim 的人可能都会有改键的需求，L-Ctrl \u0026lt;-\u0026gt; Caps-Lock 或者 Escape \u0026lt;-\u0026gt; Caps-Lock 等等。\n另外 Mac 上面的 Option | Command 对应到 Windows 键盘是 Win | Alt, 我的习惯是把 Alt 当 Option 用，所以要换到左边去。\nAbout keyboard 键盘的原理大概是每个按键都有对应的（十六进制）scancode，在内核层 scancode 会被映射会 keycode，而在 X 中（比如 xmodmap）会进一步把 keycode 对应到不同的 keysym，比如 keycode 38 = a A 就代表 keycode 为 38 的键会输出字母 a，如果配合 Shift 键则输入 A.\n而 xmodmap 改键的原理也是通过修改 keycode 的对应关系来实现的，只是在配置文件中还可以使用更方便的命令比如 clear/remove/add 来描述。\n另外 xmodmap 还支持通过修改 pointer 参数来支持触摸屏滚动的方向，比如像 Mac 一样，手指上滑让页面下翻。\n但是 xmodmap 只适合做比较简单的自定义，毕竟写起来复杂，还容易被 setxkbmap 覆盖。\nUse setxkbmap setxkbmap 使用起来很简单，如果实现我自己的需求，想要开机生效的话，直接在 .xinitrc 中加入一行命令即可：\nsetxkbmap -option ctrl:swapcaps,altwin:swap_lalt_lwin 如果支持插拔的话，则要给 Xorg 增加配置文件（如 /etc/X11/xorg.conf.d/00-keyboard.conf）：\nSection \u0026#34;ServerFlags\u0026#34; Option \u0026#34;DontZap\u0026#34; \u0026#34;False\u0026#34; EndSection Section \u0026#34;InputClass\u0026#34; Identifier \u0026#34;system-keyboard\u0026#34; MatchIsKeyboard \u0026#34;on\u0026#34; Option \u0026#34;XkbOptions\u0026#34; \u0026#34;ctrl:swapcaps,altwin:swap_lalt_lwin,terminate:ctrl_alt_bksp\u0026#34; EndSection CAB 那么上面配置文件里面的 ServerFlags 和 option 中的 terminate:ctrl_alt_bksp 是做什么的？\n就是来支持 CAB(Ctrl-Alt-Backspace) 快捷键关闭当前 X 程序的。这很有用，尤其是在 X window 卡死没有响应的时候。\n当然 Ctrl-Alt-Fx 切换 tty 或者强制关机也没什么不可以的\nWM 也好，XDG 的那些 DE 也好（GNOME/KDE/\u0026hellip;），X 战警们的难题永无止境，然而时间有限，不得不做取舍的我只好以此纪念无辜逝去的时间以及无数个奋战到深夜的自己。\nReferences\nXmodmap - Archwiki Xorg keyboard configuration - Archwiki Understand how keyboards work ","permalink":"https://iamgodot.com/posts/use-setxkbmap-for-keyboard-mapping/","summary":"这是一篇使用（过） Linux Xorg without any DE 以及笔记本外接键盘的人才能理解其中辛酸苦痛的抒情科普文。\nTL;DR 外接键盘不要开蓝牙，直接插线，除非你乐意折腾 使用 setxkbmap 而不是 xmodmap 来做 key remapping 不要用 Xorg The Irrational Part 上午十点零一分，端坐到显示器前，深呼吸两次。\nOk，回滚内核版本之后 Screen Lock 卡死的问题果然消失了，我们继续。\n进入系统，先看一下昨晚的日志吧：\n... 需求目标： 1. 交换 L-Ctrl \u0026amp; Caps-Lock 2. 交换 Win \u0026amp; Alt 当前方案： 使用 xmodmap 自定义配置文件，在 startx 时执行 已知问题： 1. 系统挂起或蓝牙睡眠导致的 keyboard reconnection 会 reset 掉 Win\u0026amp;Alt 的交换 2. 之后重新执行 xmodmap 会导致 L-Ctrl\u0026amp;Caps-Lock 交换回原状，必须执行两次 后续跟进： 1. TTY console switch 快捷键不可用 2. Terminate X 快捷键 CAB(Ctrl-Alt-Backspace) 不可用 3.","title":"Use setxkbmap for Keyboard Mapping"},{"content":" 假如生活欺骗了你，\n不要悲伤，不要心急！\n忧郁的日子里，必须镇静：\n相信吧，快乐的日子终将会来临。\n心儿永远向着未来；\n现在却常是忧郁。\n一切都是瞬息，一切都将会过去；\n而那过去了的，就会成为亲切的怀恋。\n","permalink":"https://iamgodot.com/posts/if-by-life-you-were-deceived/","summary":"假如生活欺骗了你，\n不要悲伤，不要心急！\n忧郁的日子里，必须镇静：\n相信吧，快乐的日子终将会来临。\n心儿永远向着未来；\n现在却常是忧郁。\n一切都是瞬息，一切都将会过去；\n而那过去了的，就会成为亲切的怀恋。","title":"假如生活欺骗了你"},{"content":"从兰州离开之后，终于踏上了心系已久的河西走廊之旅。自从看了同名纪录片，才真正领略到大西北的厚重，也开始了解，早在汉武帝的统治下，狭长的河西通道就已经被慢慢打开，并一步步开启了中国的历史新篇。\n其实所谓河西走廊指的是一条从中原通往关外的通道，由甘肃的武威、张掖、酒泉和敦煌几座城市相连，从地图上看，形如走廊，又在黄河以西，故此得名。为了更集中精力游览，便决定不在酒泉停留，而是游完敦煌之后，回返嘉峪关机场直接离开。\n盗图，侵删\n武威 武威，即武功军威，古称凉州。本来以为会是个喧闹的小镇模样，到了之后却发现大有不同。不仅是因为道路规划得宽敞通畅，满带科技感的市博物馆更让人耳目一新。雷台汉墓的铜奔马实际上就是在这里出土，（估计）却因为当年本地的条件不够而把大量的文物搬迁到兰州的甘肃省博了，（猜想）这座优秀市博的建立就是不想再重蹈覆辙，毕竟珍贵文物会很大程度影响旅游经济的发展（好像还为了留住西夏塔碑特意建了个西夏博物馆）。\n被掳走的马踏飞燕\n写的真好\n投影解说，满满的科技感\n西夏神碑\n美丽的自然风光都分布在市区的周边，比如附近的天梯山石窟，据说这里是最早开凿佛窟的地方。虽然因为整修所以只能看到唯一一座大佛的石像，但因为挨着水库，又到了油菜花开的季节，所以一路的景色沁人心脾，让人意犹未尽。\n另外还去了鸠摩罗什寺，位置在市内，走过去也很方便。这位龟兹国的高僧为梵文佛经的翻译做出了巨大的贡献，与玄奘齐名。而最过传奇的莫过于他被迫取妻生子的经历，饶是如此，也并没有让他迷恋俗世生活，而是一心向佛，宠辱不惊。据传他的长相还十分英俊，可以参考河西走廊纪录片里面饰演他的那位演员。\n观世音菩萨与观自在菩萨\n张掖 张国臂掖，以通西域。张掖古称甘州。这个城市要更热闹一些，可能是因为人也更多吧。印象深刻的是散步时看到一个很大的公园，进去之后发现居然是苏州园林的风格，再一看介绍果然是古时候请江浙园林设计的名家来建造的。名字叫做一园，奇怪的是在网上却没有搜到这个地标。\n张掖市区附近的景点更多，像丹霞、马蹄寺、平山湖大峡谷、扁都口和山丹军马场等等。因为时间关系并没有去看最有名的丹霞，而是去了人稍微少一些的马蹄寺。这座寺院以石窟闻名，山上的洞窟由岩壁的甬道相连，攀爬的过程略难，有的地方甚至要手脚并用。每一个洞窟里面的佛像和饰物都极为古朴，但游览的过程中心里却有些不是滋味，因为洞内标记了禁止拍照但很少有人理会，还能看到石壁上到处都是游客刻下的到此一游。这很令人惋惜，因为整座山里的三十三洞天，石窟和甬道，都是千百年前的虔诚信徒们徒手开凿的。\n三十三洞天\n在这里的几天都很顺利，没想到最后一晚却遭遇了人生首次外宿的意外事故：洗浴时整片干湿分离的玻璃碎裂、断落到地上。划伤不算严重，酒店也做了道歉和赔偿。虽然经过了妥善处理，内心却久久不能平复，回想起来也有些后怕，人生无常，一定要保护好自己。\n敦煌 敦煌意为盛大，古代称作沙州。这里是沙漠地区，所以紫外线强烈，天气尤其炎热。敦煌的景点大致分为东西两线：\n东线 莫高窟 鸣沙山、月牙泉 西线 敦煌古城 西千佛洞 阳关 玉门关 雅丹地貌 为了方便，便选择就近住在鸣沙山景区周边的民宿。景区进去便是一片沙漠，开始可以选择骑骆驼绕行一圈，虽然有些颠簸，但整趟下来还是很有意思的，之后观赏月牙泉湖，再攀爬沙山到顶。天色渐晚，狂风便卷起黄沙恐吓游人，声响虽大，却不乏有勇士们尖叫着拍照、滑沙，享受原始的混沌风光。夜晚确实是好时候，因为一到白天，烈日之下，便无人再愿与沙漠同伴了。\n高昂的头颅\n鸣沙山与月牙泉\n享受完鸣沙山的悠闲，自然要去看最著名的莫高窟。作为重点保护的古迹，门票要三个月之前就开始订，观看的过程不允许逗留和拍照，能看到的也只是几十个洞窟之中随机的八个。饶是如此，匆匆几个小时也足以让人流连忘返。在向导小哥的讲解下，一尊尊佛像雕刻，经历几个朝代的侵蚀、修补与上色，配合不同的顶部结构和栩栩如生的壁画，又重新鲜活了起来，仿佛古时的画人工匠仍然在不停地忙碌，延续佛教历史的不朽传说。\n西线的几个景点一般需要包车，用一天时间就可以看完。同行的几个小伙伴都是很有意思的人，其中有一对情侣来自成都，一路上大家相谈甚欢，还约好了之后去成都再聚。这种奇妙的偶遇让我意识到，除了很大的世界要看，还有更多的陌生人值得认识和结交。在回去的路上，司机大叔把我们拉到一处停下，大家抱怨着下车，瞬间被漫天繁星震撼，西北的夜晚无比静谧，让灿烂的星空得以尽情挥洒。我不说话，却难以克制心中的激动，眼前的景象很难用语言描绘，但足以让人忘记一切烦恼。醉后不知天在水，满船清梦压星河，古人诚不欺我。\n西出阳关无故人\n雅丹魔鬼城的小猫咪\n雅丹体，千年风沙堆积成的神奇地貌\n遥远的前方就是传说中的罗布泊\n从敦煌到嘉峪关后，这段旅程也告一段落了。那时大约在七月中旬，这篇游记却到八月底才写，因为不知道以怎样的方式来记录才最合适。太多的景色去回味，太密集的感受要消化，这并不是个好借口，但它让我深深感到，行万里路并非一句空话，如同看书，不管内容记住多少，阅读的过程都会成为心灵的积淀。这一点一滴的慰藉，让我们得以回过头来，平静地继续生活。\n","permalink":"https://iamgodot.com/posts/visit-hexi-corridor/","summary":"从兰州离开之后，终于踏上了心系已久的河西走廊之旅。自从看了同名纪录片，才真正领略到大西北的厚重，也开始了解，早在汉武帝的统治下，狭长的河西通道就已经被慢慢打开，并一步步开启了中国的历史新篇。\n其实所谓河西走廊指的是一条从中原通往关外的通道，由甘肃的武威、张掖、酒泉和敦煌几座城市相连，从地图上看，形如走廊，又在黄河以西，故此得名。为了更集中精力游览，便决定不在酒泉停留，而是游完敦煌之后，回返嘉峪关机场直接离开。\n盗图，侵删\n武威 武威，即武功军威，古称凉州。本来以为会是个喧闹的小镇模样，到了之后却发现大有不同。不仅是因为道路规划得宽敞通畅，满带科技感的市博物馆更让人耳目一新。雷台汉墓的铜奔马实际上就是在这里出土，（估计）却因为当年本地的条件不够而把大量的文物搬迁到兰州的甘肃省博了，（猜想）这座优秀市博的建立就是不想再重蹈覆辙，毕竟珍贵文物会很大程度影响旅游经济的发展（好像还为了留住西夏塔碑特意建了个西夏博物馆）。\n被掳走的马踏飞燕\n写的真好\n投影解说，满满的科技感\n西夏神碑\n美丽的自然风光都分布在市区的周边，比如附近的天梯山石窟，据说这里是最早开凿佛窟的地方。虽然因为整修所以只能看到唯一一座大佛的石像，但因为挨着水库，又到了油菜花开的季节，所以一路的景色沁人心脾，让人意犹未尽。\n另外还去了鸠摩罗什寺，位置在市内，走过去也很方便。这位龟兹国的高僧为梵文佛经的翻译做出了巨大的贡献，与玄奘齐名。而最过传奇的莫过于他被迫取妻生子的经历，饶是如此，也并没有让他迷恋俗世生活，而是一心向佛，宠辱不惊。据传他的长相还十分英俊，可以参考河西走廊纪录片里面饰演他的那位演员。\n观世音菩萨与观自在菩萨\n张掖 张国臂掖，以通西域。张掖古称甘州。这个城市要更热闹一些，可能是因为人也更多吧。印象深刻的是散步时看到一个很大的公园，进去之后发现居然是苏州园林的风格，再一看介绍果然是古时候请江浙园林设计的名家来建造的。名字叫做一园，奇怪的是在网上却没有搜到这个地标。\n张掖市区附近的景点更多，像丹霞、马蹄寺、平山湖大峡谷、扁都口和山丹军马场等等。因为时间关系并没有去看最有名的丹霞，而是去了人稍微少一些的马蹄寺。这座寺院以石窟闻名，山上的洞窟由岩壁的甬道相连，攀爬的过程略难，有的地方甚至要手脚并用。每一个洞窟里面的佛像和饰物都极为古朴，但游览的过程中心里却有些不是滋味，因为洞内标记了禁止拍照但很少有人理会，还能看到石壁上到处都是游客刻下的到此一游。这很令人惋惜，因为整座山里的三十三洞天，石窟和甬道，都是千百年前的虔诚信徒们徒手开凿的。\n三十三洞天\n在这里的几天都很顺利，没想到最后一晚却遭遇了人生首次外宿的意外事故：洗浴时整片干湿分离的玻璃碎裂、断落到地上。划伤不算严重，酒店也做了道歉和赔偿。虽然经过了妥善处理，内心却久久不能平复，回想起来也有些后怕，人生无常，一定要保护好自己。\n敦煌 敦煌意为盛大，古代称作沙州。这里是沙漠地区，所以紫外线强烈，天气尤其炎热。敦煌的景点大致分为东西两线：\n东线 莫高窟 鸣沙山、月牙泉 西线 敦煌古城 西千佛洞 阳关 玉门关 雅丹地貌 为了方便，便选择就近住在鸣沙山景区周边的民宿。景区进去便是一片沙漠，开始可以选择骑骆驼绕行一圈，虽然有些颠簸，但整趟下来还是很有意思的，之后观赏月牙泉湖，再攀爬沙山到顶。天色渐晚，狂风便卷起黄沙恐吓游人，声响虽大，却不乏有勇士们尖叫着拍照、滑沙，享受原始的混沌风光。夜晚确实是好时候，因为一到白天，烈日之下，便无人再愿与沙漠同伴了。\n高昂的头颅\n鸣沙山与月牙泉\n享受完鸣沙山的悠闲，自然要去看最著名的莫高窟。作为重点保护的古迹，门票要三个月之前就开始订，观看的过程不允许逗留和拍照，能看到的也只是几十个洞窟之中随机的八个。饶是如此，匆匆几个小时也足以让人流连忘返。在向导小哥的讲解下，一尊尊佛像雕刻，经历几个朝代的侵蚀、修补与上色，配合不同的顶部结构和栩栩如生的壁画，又重新鲜活了起来，仿佛古时的画人工匠仍然在不停地忙碌，延续佛教历史的不朽传说。\n西线的几个景点一般需要包车，用一天时间就可以看完。同行的几个小伙伴都是很有意思的人，其中有一对情侣来自成都，一路上大家相谈甚欢，还约好了之后去成都再聚。这种奇妙的偶遇让我意识到，除了很大的世界要看，还有更多的陌生人值得认识和结交。在回去的路上，司机大叔把我们拉到一处停下，大家抱怨着下车，瞬间被漫天繁星震撼，西北的夜晚无比静谧，让灿烂的星空得以尽情挥洒。我不说话，却难以克制心中的激动，眼前的景象很难用语言描绘，但足以让人忘记一切烦恼。醉后不知天在水，满船清梦压星河，古人诚不欺我。\n西出阳关无故人\n雅丹魔鬼城的小猫咪\n雅丹体，千年风沙堆积成的神奇地貌\n遥远的前方就是传说中的罗布泊\n从敦煌到嘉峪关后，这段旅程也告一段落了。那时大约在七月中旬，这篇游记却到八月底才写，因为不知道以怎样的方式来记录才最合适。太多的景色去回味，太密集的感受要消化，这并不是个好借口，但它让我深深感到，行万里路并非一句空话，如同看书，不管内容记住多少，阅读的过程都会成为心灵的积淀。这一点一滴的慰藉，让我们得以回过头来，平静地继续生活。","title":"游河西走廊"},{"content":"通常写东西不会让我很为难，虽然有时也会酝酿许久，但绝没有像游记这样令我如此困惑。\n也许是对这种类型过于陌生，也许读的太少，总是无法想象一篇好游记的模样。不过心中有了尝试的动力，只好硬着头皮思考下去。\n否定一样事物往往是容易的，如今旅游盛行，各类 app 里面的游记比比皆是，反而为我透露出些许端倪。一座城市的简介，一段行程的攻略，甚至一个地区的方志，都有助于对风土人情的了解，但同时也偏离了游记的方向。针对个人的经历，一篇游记应当是主观的，真实地记录旅途中的所见所闻，这也符合百科里的描述：\n一般而言，旅行文学是旅人的旅游记录，所录包括途中见闻、政治、社会、风土、景物云云，亦表达思想感情。\n这定义着实宽泛，那么一篇好的游记又该如何写呢，大概少不了下面几种元素：\n景色的描绘 行程的记叙 真挚的抒情 时事的议论 科学的考察 这其中并没有高下之分，在我看来，美景和奇遇是最符合游记本质的内容，不仅贴近生活，更能让人感同身受。下面三种则是借游之名作其他的表达，虽然各有侧重，但对于一篇单纯的旅行日记的升华来说，也是不可或缺的。\n偏抒情的，有柳宗元《小石潭记》、欧阳修《醉翁亭记》；带议论的，如范仲淹《岳阳楼记》、王安石《游褒禅山记》；还有科学色彩的，如郦道元的《三峡》，还有考察地质地貌的《徐霞客游记》。\n更进一步的是，关于地理和政治、经济、人文等因素之间的联结，我学到一个新的概念，地缘：\n地缘关系是指以地理位置为联结纽带，由于在一定的地理范围内共同生活、活动而交往产生的人际关系。\n现代国家地缘关系，是指以地理位置、综合国力和距离等地缘要素为基础的国家之间的地缘政治、地缘经济、地缘文明等关系。\n简单地理解，就是由于特定的地理环境，一个社会和国家的发展是存在一定的规律的，将范围扩大，也一定程度上决定了人与人、国与国之间的相处和竞争关系。\n这可能离游记本身的概念已经太远，但话说回来，去一个地方并不限于日常生活的吃喝玩乐，站在更高的角度，看到一地之理、历经之史，是一件更有意义的事。当然，说来简单，这种程度作为旅行的终极追求也不为过。\n返朴归真地想想，无论是感官体验，还是心理感受，只要自由地走了走、看了看，都不愧为一次成功的出游，如此，才是一篇好的游记最重要的前提。\n","permalink":"https://iamgodot.com/posts/on-travel-log/","summary":"通常写东西不会让我很为难，虽然有时也会酝酿许久，但绝没有像游记这样令我如此困惑。\n也许是对这种类型过于陌生，也许读的太少，总是无法想象一篇好游记的模样。不过心中有了尝试的动力，只好硬着头皮思考下去。\n否定一样事物往往是容易的，如今旅游盛行，各类 app 里面的游记比比皆是，反而为我透露出些许端倪。一座城市的简介，一段行程的攻略，甚至一个地区的方志，都有助于对风土人情的了解，但同时也偏离了游记的方向。针对个人的经历，一篇游记应当是主观的，真实地记录旅途中的所见所闻，这也符合百科里的描述：\n一般而言，旅行文学是旅人的旅游记录，所录包括途中见闻、政治、社会、风土、景物云云，亦表达思想感情。\n这定义着实宽泛，那么一篇好的游记又该如何写呢，大概少不了下面几种元素：\n景色的描绘 行程的记叙 真挚的抒情 时事的议论 科学的考察 这其中并没有高下之分，在我看来，美景和奇遇是最符合游记本质的内容，不仅贴近生活，更能让人感同身受。下面三种则是借游之名作其他的表达，虽然各有侧重，但对于一篇单纯的旅行日记的升华来说，也是不可或缺的。\n偏抒情的，有柳宗元《小石潭记》、欧阳修《醉翁亭记》；带议论的，如范仲淹《岳阳楼记》、王安石《游褒禅山记》；还有科学色彩的，如郦道元的《三峡》，还有考察地质地貌的《徐霞客游记》。\n更进一步的是，关于地理和政治、经济、人文等因素之间的联结，我学到一个新的概念，地缘：\n地缘关系是指以地理位置为联结纽带，由于在一定的地理范围内共同生活、活动而交往产生的人际关系。\n现代国家地缘关系，是指以地理位置、综合国力和距离等地缘要素为基础的国家之间的地缘政治、地缘经济、地缘文明等关系。\n简单地理解，就是由于特定的地理环境，一个社会和国家的发展是存在一定的规律的，将范围扩大，也一定程度上决定了人与人、国与国之间的相处和竞争关系。\n这可能离游记本身的概念已经太远，但话说回来，去一个地方并不限于日常生活的吃喝玩乐，站在更高的角度，看到一地之理、历经之史，是一件更有意义的事。当然，说来简单，这种程度作为旅行的终极追求也不为过。\n返朴归真地想想，无论是感官体验，还是心理感受，只要自由地走了走、看了看，都不愧为一次成功的出游，如此，才是一篇好的游记最重要的前提。","title":"论游记"},{"content":"离开北京，兰州是我的第一站。作为西北之行的起点，它是最合适的选择。一直以来，我都对这座城市充满了好感，那里是每个牛肉面爱好者都心驰神往的朝圣地。\n在出发之前，我并不了解兰州，知道的也不过拉面、牛羊肉和黄沙漫天几个关键词而已（刻板印象）。其实，同样情况的又何止这一处呢，中国地广城多，去了也难免只是匆匆一瞥，更多的地方都只是道听途说。也许，认识一个城市和交朋友差不多，知己难得，不仅需要时间和耐心，更少不了冥冥中的一抹缘分。\n之所以说缘分，是因为每一座城市都有自己的特色，无论地理、文化还是饮食，而这些是否符合个人的兴趣口味，就不好说了。有时可能令人失望，但一旦出现交集，便会发生神奇的碰撞反应。比如我从小爱吃拉面（牛肉面），所以对兰州饭馆极有亲切感，心里也埋下了有朝一日要去当地品尝正宗口味的种子。顺着这第一动力，来到这里，除了美食之外，也被当地淳朴的风土人情所感染，因此对兰州甚至整个大西北有了更多的留恋。\n来到兰州的第一张\n在兰州呆了一周左右，前几天如同饿虎扑食般奔赴各个有名的牛肉面馆，后面渐渐恢复了理智，才开始把注意力放到了其他方面。兰州牛肉面自然不用再介绍什么，值得一提的是当地的招牌是不会出现 拉面 字样的，所以也就有了其他地方的拉面馆都是青海人开的一说。来了之后，才发现一碗面之中也隐藏着很多地道的细节，比如牛肉面在当地多作为早餐，而过了中午之后基本就歇业了（也是因为汤随着煮面会越来越浑浊，所以一大早去吃最好汤最清），再比如对于面条不仅可以选择粗细，还可以告知自己要的量多量少，还有就是牛肉面的辣子很香但是并不辣，但如果招牌写了 辣子牛肉面 的话辣度会飙升。兰州的牛肉面馆众多，自然也会有排行榜，比如此行令我印象深刻的白建强、白老七（前几名似乎随着时间会不断更替，比如前些年的马子禄到现在感觉已经渐渐式微了），但整体来说平均水平是很高的，基本不用担心踩坑。最后要提下价格，一碗面均价七块，倒是一份牛肉的价格要比面还高，不过肉蛋双飞加小菜总共也不超过二十块，物美价廉。\n美！\n凉面也不错\n看到店铺转让我不禁笑了出来\n相比于文字，纪录片可以更生动地展现一个地方的历史和文化，比如这部金城兰州。汉武帝时期，霍去病大破匈奴，一路向西，而高强度的军事作战需要强有力的后勤补给，兰州地处河谷平原，又作为黄河渡口和东西的咽喉要塞，自然被重点开拓，古称金城，取的是固若金汤的寓意。黄河穿城而过，岸边是长长的健身步道，横跨黄河之上有很多架大桥，其中最有名也最古老的是中山铁桥。在此之前，唯一的渡河方式是将多艘木船连合搭建的浮桥，虽然历史悠久，但维护成本很高，不但要春建冬拆，还有被汛期洪水冲断的风险。到了1906年，通过德商引进国外技术，并且从德国海运了所有的建桥用料，第一座黄河铁桥终于建成，并且留存至今。虽然现在只允许步行游览，但不得不说，经历了一个多世纪，这座中山桥依旧岿然不动，走在上面很有安全感。如果想体验湍急的黄河水，不妨到岸边的码头乘坐羊皮筏子，纵使在炎热的七月，河水依然冰凉透骨，而且竹筏随着急流旋来转去，真的很容易头晕。最惬意的享受也在黄河边，那就是一边躺坐在岸边的靠椅乘凉，一边品尝三泡台（七宝茶）的清甜，再配上一首黄河谣，思绪伴着浑厚的唱腔变得沉重，却又在不知不觉间飘回了千百年前。\n夜晚的中山桥\n羊皮筏子\n黄河岸边好乘凉\n甜丝丝的三泡台\n兰州还是很宜居的，清凉的河风吹得空气干爽而舒适，一到傍晚便可见到熙熙攘攘的人们在岸旁的公园广场上跳舞和散步。西北的淳朴民风，让作为外地游客的我感觉不到任何拘束，过马路时，司机们常常都会主动让人。正宁路小吃街，南关夜市，加上热闹的烧烤摊和酒馆，给无聊的夜生活点缀了无数欢乐。\n真的很美\n最后一晚在河边漫步时，无意听到旁边的人闲聊，其中一个大叔说起现在的年轻人太贪图享受，即使有工作机会，也没人愿意留在西部，觉得条件艰苦，没有发展。平心而论，相比兰州作为甘肃的省会，却找不出几个互联网职位，我也会觉得去发达的一二线城市才是更好的选择。现实如此，年轻人宁肯在大都市闯荡，头破血流也不愿意回到家乡。这是个时代的难题，人口不断地向中心城市流动，新一代的信仰也在发生迁移。如今资本的巨力大行其道，教唆每个人房子、股票和大厂的工作才是人生的唯一出口，比起上一代的白手起家，我们站得更高，却很难再有一往无前的勇气。\n不知是惭愧还是迷茫，望着滚滚河水，我陷入了沉思。黄河之水天上来，奔流到海不复回。也许它比我更加困惑，也许它至少清楚，只要保持前行，终有一天会和答案相遇。\n","permalink":"https://iamgodot.com/posts/visit-lanzhou/","summary":"离开北京，兰州是我的第一站。作为西北之行的起点，它是最合适的选择。一直以来，我都对这座城市充满了好感，那里是每个牛肉面爱好者都心驰神往的朝圣地。\n在出发之前，我并不了解兰州，知道的也不过拉面、牛羊肉和黄沙漫天几个关键词而已（刻板印象）。其实，同样情况的又何止这一处呢，中国地广城多，去了也难免只是匆匆一瞥，更多的地方都只是道听途说。也许，认识一个城市和交朋友差不多，知己难得，不仅需要时间和耐心，更少不了冥冥中的一抹缘分。\n之所以说缘分，是因为每一座城市都有自己的特色，无论地理、文化还是饮食，而这些是否符合个人的兴趣口味，就不好说了。有时可能令人失望，但一旦出现交集，便会发生神奇的碰撞反应。比如我从小爱吃拉面（牛肉面），所以对兰州饭馆极有亲切感，心里也埋下了有朝一日要去当地品尝正宗口味的种子。顺着这第一动力，来到这里，除了美食之外，也被当地淳朴的风土人情所感染，因此对兰州甚至整个大西北有了更多的留恋。\n来到兰州的第一张\n在兰州呆了一周左右，前几天如同饿虎扑食般奔赴各个有名的牛肉面馆，后面渐渐恢复了理智，才开始把注意力放到了其他方面。兰州牛肉面自然不用再介绍什么，值得一提的是当地的招牌是不会出现 拉面 字样的，所以也就有了其他地方的拉面馆都是青海人开的一说。来了之后，才发现一碗面之中也隐藏着很多地道的细节，比如牛肉面在当地多作为早餐，而过了中午之后基本就歇业了（也是因为汤随着煮面会越来越浑浊，所以一大早去吃最好汤最清），再比如对于面条不仅可以选择粗细，还可以告知自己要的量多量少，还有就是牛肉面的辣子很香但是并不辣，但如果招牌写了 辣子牛肉面 的话辣度会飙升。兰州的牛肉面馆众多，自然也会有排行榜，比如此行令我印象深刻的白建强、白老七（前几名似乎随着时间会不断更替，比如前些年的马子禄到现在感觉已经渐渐式微了），但整体来说平均水平是很高的，基本不用担心踩坑。最后要提下价格，一碗面均价七块，倒是一份牛肉的价格要比面还高，不过肉蛋双飞加小菜总共也不超过二十块，物美价廉。\n美！\n凉面也不错\n看到店铺转让我不禁笑了出来\n相比于文字，纪录片可以更生动地展现一个地方的历史和文化，比如这部金城兰州。汉武帝时期，霍去病大破匈奴，一路向西，而高强度的军事作战需要强有力的后勤补给，兰州地处河谷平原，又作为黄河渡口和东西的咽喉要塞，自然被重点开拓，古称金城，取的是固若金汤的寓意。黄河穿城而过，岸边是长长的健身步道，横跨黄河之上有很多架大桥，其中最有名也最古老的是中山铁桥。在此之前，唯一的渡河方式是将多艘木船连合搭建的浮桥，虽然历史悠久，但维护成本很高，不但要春建冬拆，还有被汛期洪水冲断的风险。到了1906年，通过德商引进国外技术，并且从德国海运了所有的建桥用料，第一座黄河铁桥终于建成，并且留存至今。虽然现在只允许步行游览，但不得不说，经历了一个多世纪，这座中山桥依旧岿然不动，走在上面很有安全感。如果想体验湍急的黄河水，不妨到岸边的码头乘坐羊皮筏子，纵使在炎热的七月，河水依然冰凉透骨，而且竹筏随着急流旋来转去，真的很容易头晕。最惬意的享受也在黄河边，那就是一边躺坐在岸边的靠椅乘凉，一边品尝三泡台（七宝茶）的清甜，再配上一首黄河谣，思绪伴着浑厚的唱腔变得沉重，却又在不知不觉间飘回了千百年前。\n夜晚的中山桥\n羊皮筏子\n黄河岸边好乘凉\n甜丝丝的三泡台\n兰州还是很宜居的，清凉的河风吹得空气干爽而舒适，一到傍晚便可见到熙熙攘攘的人们在岸旁的公园广场上跳舞和散步。西北的淳朴民风，让作为外地游客的我感觉不到任何拘束，过马路时，司机们常常都会主动让人。正宁路小吃街，南关夜市，加上热闹的烧烤摊和酒馆，给无聊的夜生活点缀了无数欢乐。\n真的很美\n最后一晚在河边漫步时，无意听到旁边的人闲聊，其中一个大叔说起现在的年轻人太贪图享受，即使有工作机会，也没人愿意留在西部，觉得条件艰苦，没有发展。平心而论，相比兰州作为甘肃的省会，却找不出几个互联网职位，我也会觉得去发达的一二线城市才是更好的选择。现实如此，年轻人宁肯在大都市闯荡，头破血流也不愿意回到家乡。这是个时代的难题，人口不断地向中心城市流动，新一代的信仰也在发生迁移。如今资本的巨力大行其道，教唆每个人房子、股票和大厂的工作才是人生的唯一出口，比起上一代的白手起家，我们站得更高，却很难再有一往无前的勇气。\n不知是惭愧还是迷茫，望着滚滚河水，我陷入了沉思。黄河之水天上来，奔流到海不复回。也许它比我更加困惑，也许它至少清楚，只要保持前行，终有一天会和答案相遇。","title":"游兰州"},{"content":"逛胡同是我在北京生活最享受的事情之一。在六月的夏季，常有蓝天白云的好时候，阳光不算毒辣，微风轻拂而过，靠在墙边的树荫下，让鸟语蝉声把自己勾回无忧无虑的童年。\n地安门总是我行程的起点。从这里进护国寺街，买份杏仁豆腐边吃边往里走，到定阜街再多几步就能看见辅仁大学的校门，不过现在已经挂上了北师大的牌子。继续向前是恭王府，想绕过的话可以穿过柳荫街去后海（如果感兴趣，还有南海、中海、北海、前海、后海和西海，一溜儿全是水路）。之后沿着湖面随便溜达溜达再一路向东，穿过烟袋斜街就是鼓楼了。走的时候叼根冰棍儿，边嗦边逛才过瘾，不用担心，一路上公厕比小商店多。\n沿途的风景如画：\n定阜街，到这里就可以开始买冰棍儿了\n每次都看，没一次记住的\n已经是旧址了，牌子上写的北京师范大学\n云的排列挺奇特的，应该有点儿讲究\n小红门，拍成这样已经很努力了\n阳光衬着树绿太美，驻足良久\n后海，云卷云又舒\n前面就是酒吧街了\n到了鼓楼街，如果觉得饿，拐进方砖厂胡同，有家 69 号炸酱面在等待。等待的意思是，想吃你得耐心地排网红队。等不及也不要紧，对面是个菜市场，里面有家小付煎饼，糁子面糊（不同于天津煎饼用的绿豆面）加现磨豆浆，七块钱的煎饼可以吃得很满足。\n再往前有两个选择，一是左转向北，经过北锣鼓巷往外环走；又或者趁天色未晚去景山公园逛逛，既可以远眺北京城，也不至于累得走不动。\n北京好像一直都在变大，但是真正让我感到留恋的就那么几条街，即使这样，也总是看不够其中的风景。千百年来的人和事，积淀在这片土地上，能带人回到民国、晚清和大明朝。\n夏天的胡同，胡同的夏天，时空是两条长河，相互交错着延伸，汇聚在此，化作美丽的漩涡。感觉说来奇妙，我亦不信邪，然而每一刻的风情，与任一个往昔都有细微差别。虽然不知会飘向何处，但它存在过，就已经完全足够了。\n","permalink":"https://iamgodot.com/posts/hutongs-in-beijing-summer/","summary":"逛胡同是我在北京生活最享受的事情之一。在六月的夏季，常有蓝天白云的好时候，阳光不算毒辣，微风轻拂而过，靠在墙边的树荫下，让鸟语蝉声把自己勾回无忧无虑的童年。\n地安门总是我行程的起点。从这里进护国寺街，买份杏仁豆腐边吃边往里走，到定阜街再多几步就能看见辅仁大学的校门，不过现在已经挂上了北师大的牌子。继续向前是恭王府，想绕过的话可以穿过柳荫街去后海（如果感兴趣，还有南海、中海、北海、前海、后海和西海，一溜儿全是水路）。之后沿着湖面随便溜达溜达再一路向东，穿过烟袋斜街就是鼓楼了。走的时候叼根冰棍儿，边嗦边逛才过瘾，不用担心，一路上公厕比小商店多。\n沿途的风景如画：\n定阜街，到这里就可以开始买冰棍儿了\n每次都看，没一次记住的\n已经是旧址了，牌子上写的北京师范大学\n云的排列挺奇特的，应该有点儿讲究\n小红门，拍成这样已经很努力了\n阳光衬着树绿太美，驻足良久\n后海，云卷云又舒\n前面就是酒吧街了\n到了鼓楼街，如果觉得饿，拐进方砖厂胡同，有家 69 号炸酱面在等待。等待的意思是，想吃你得耐心地排网红队。等不及也不要紧，对面是个菜市场，里面有家小付煎饼，糁子面糊（不同于天津煎饼用的绿豆面）加现磨豆浆，七块钱的煎饼可以吃得很满足。\n再往前有两个选择，一是左转向北，经过北锣鼓巷往外环走；又或者趁天色未晚去景山公园逛逛，既可以远眺北京城，也不至于累得走不动。\n北京好像一直都在变大，但是真正让我感到留恋的就那么几条街，即使这样，也总是看不够其中的风景。千百年来的人和事，积淀在这片土地上，能带人回到民国、晚清和大明朝。\n夏天的胡同，胡同的夏天，时空是两条长河，相互交错着延伸，汇聚在此，化作美丽的漩涡。感觉说来奇妙，我亦不信邪，然而每一刻的风情，与任一个往昔都有细微差别。虽然不知会飘向何处，但它存在过，就已经完全足够了。","title":"胡同的夏天"},{"content":"没有人永远二十多岁，但永远有人二十多岁。今天像往常一样度过，但回头看看，对于过去的十年仍然感到不可思议。一方面，自己真的离开了这段生命区间，另一方面，是没想到会以这样的轨迹一路走过来。\n打开记忆的盒子，这段青春岁月过得有慢有快。前半部分在校园，回想起来却满是彷徨挣扎，漫长得支离破碎；工作之后，仿佛才睁开眼睛，开始看清自己和身边的人，反而觉得有趣，日子也变得快了。与这个世界交手多年，你是否光彩依旧，兴致盎然？对我来说，人生越来越接近一场游戏，过去就像开场的热身，而下面正题才刚刚开始。\n每个人都会害怕，有的人害怕孤单，有的人害怕错过。我也一样，甚至比别人更多，因为内心敏感，所以时常会有各种念头冒出来。经历一些事之后，好像切断了部分神经，变得愈加迟钝了。有时周围的人夸我勇敢，他们不知道的是，我的思绪会飘回某个时间点，在那里，自己一无所有，这感受如此真实，于是再做大胆的决定时，我会想，没什么了不起，大不了和从前一样罢了。\n过去的早已过去，珍贵的也不会忘记。认识过很多人，但保持联系的少之又少。有的以为永远不会分开却陌路，有的中间失去联系却成为知己。我不爱交际，所以有朋友全凭好运气，甚至还需要对方迁就，这并非我所愿，希望以后能多做些好事，让这些人开心快乐。\n往事一幕幕，如同幻灯片，为自己播放简单，其他人却无从知晓。很多经历，忘了遗憾，讲出来矫情。文字略有不同，比如博客，记录在互联网上，能给虚无缥缈的时间打下烙印。日后想追溯，也不至于无迹可循。\n小时候觉得做一番惊天动地的大事业才足够好，近几年来想法越来越不一样，不是失去了理想，是感到更重要，也更困难的是找到自己真正想做的事情。为了弄清楚这问题本身，可能要付出更多的努力，还有时候，追赶了很远才发现走错了路。想要的不好找，不想要的却容易分别，但后者总要为了前者而做。弄清楚这事的好处并不明显，但它却能让人不再质疑自己，并可以专注且热情地投身其中，哪怕是还在追寻的过程中。\n说得差不多了，仔细想想，不过三十而已。今天翻来覆去地循环一首歌，就以此做结：\n《Free Bird》\nIf I leave here tomorrow\nWould you still remember me?\nFor I must be travelling on, now,\n\u0026lsquo;Cause there\u0026rsquo;s too many places I\u0026rsquo;ve got to see.\n\u0026hellip;\n","permalink":"https://iamgodot.com/posts/goodbye-20/","summary":"没有人永远二十多岁，但永远有人二十多岁。今天像往常一样度过，但回头看看，对于过去的十年仍然感到不可思议。一方面，自己真的离开了这段生命区间，另一方面，是没想到会以这样的轨迹一路走过来。\n打开记忆的盒子，这段青春岁月过得有慢有快。前半部分在校园，回想起来却满是彷徨挣扎，漫长得支离破碎；工作之后，仿佛才睁开眼睛，开始看清自己和身边的人，反而觉得有趣，日子也变得快了。与这个世界交手多年，你是否光彩依旧，兴致盎然？对我来说，人生越来越接近一场游戏，过去就像开场的热身，而下面正题才刚刚开始。\n每个人都会害怕，有的人害怕孤单，有的人害怕错过。我也一样，甚至比别人更多，因为内心敏感，所以时常会有各种念头冒出来。经历一些事之后，好像切断了部分神经，变得愈加迟钝了。有时周围的人夸我勇敢，他们不知道的是，我的思绪会飘回某个时间点，在那里，自己一无所有，这感受如此真实，于是再做大胆的决定时，我会想，没什么了不起，大不了和从前一样罢了。\n过去的早已过去，珍贵的也不会忘记。认识过很多人，但保持联系的少之又少。有的以为永远不会分开却陌路，有的中间失去联系却成为知己。我不爱交际，所以有朋友全凭好运气，甚至还需要对方迁就，这并非我所愿，希望以后能多做些好事，让这些人开心快乐。\n往事一幕幕，如同幻灯片，为自己播放简单，其他人却无从知晓。很多经历，忘了遗憾，讲出来矫情。文字略有不同，比如博客，记录在互联网上，能给虚无缥缈的时间打下烙印。日后想追溯，也不至于无迹可循。\n小时候觉得做一番惊天动地的大事业才足够好，近几年来想法越来越不一样，不是失去了理想，是感到更重要，也更困难的是找到自己真正想做的事情。为了弄清楚这问题本身，可能要付出更多的努力，还有时候，追赶了很远才发现走错了路。想要的不好找，不想要的却容易分别，但后者总要为了前者而做。弄清楚这事的好处并不明显，但它却能让人不再质疑自己，并可以专注且热情地投身其中，哪怕是还在追寻的过程中。\n说得差不多了，仔细想想，不过三十而已。今天翻来覆去地循环一首歌，就以此做结：\n《Free Bird》\nIf I leave here tomorrow\nWould you still remember me?\nFor I must be travelling on, now,\n\u0026lsquo;Cause there\u0026rsquo;s too many places I\u0026rsquo;ve got to see.\n\u0026hellip;","title":"Goodbye 20s"},{"content":"近来在中文独立博客列表里发现不少同道中人，借这个机会重新思考了独立博客这件事。\n什么是独立博客呢，根据维基百科：\n独立博客一般指在采用独立域名和网络主机的博客，既在空间、域名和内容上相对独立的博客。独立博客相当于一个独立的网站，而且不属于任何其他网站。相对于BSP下的博客，独立博客更自由、灵活，不受限制。\n这里的定义更接近个人网站的概念，但我想，应当对其做进一步的区分。\n首先，有些“博客”更像是教程网站或电商平台，在我看来，如果没有生活和观点的记录，就已经脱离了（独立）博客的范畴。在个人内容的前提下，我心中的独立博客：\n个人搭建，独立空间、域名：并非必要，公共平台也可以很好。 基于独立思考的创作：有自己的观点，非流水账，非转发集锦。 具备个人特色的写作：这一点并不容易，但我觉得找到自己的风格是很重要的。 下面说几个我比较认可的做法。\n有选择地记录 与其纠结记录什么，不如先想想哪些内容不合适。比如：\n仅叙述事情的经过（流水账）。 过于简单的介绍或教程。 咀嚼前人观点的老生常谈。 一开始可能会为了写而写，但不要放弃自我的表达。\n有意识地删减 自从发现自己有行文啰嗦的毛病之后，就立下了目标：言简意赅。\n有时会翻看之前的博客，看看还有哪些可以删减的地方。当然，有时为了说清楚某件事，难免为此多添笔墨，因此也需要一定的取舍。\n尝试不同的叙述视角 我认为在表述论点时第一人称是最佳选择，但是其他视角也有各自的适用场景。对于历史事件的描绘，第三人称是必要的；而第二人称可以给读者带来更真切的感受。\n之所以提到这一点，是因为在写作时偶尔会对此感到困惑。有时候会突然想换一种视角，但又怕打乱原有的风格。大概只有多尝试才能找到最适合自己的方式吧。\n如今的独立博客早已不是主流，但依然不断地有人出现并坚持在这条路上。自由独立地表达内心，我想这就是它最大的意义。\n","permalink":"https://iamgodot.com/posts/on-independent-blog/","summary":"近来在中文独立博客列表里发现不少同道中人，借这个机会重新思考了独立博客这件事。\n什么是独立博客呢，根据维基百科：\n独立博客一般指在采用独立域名和网络主机的博客，既在空间、域名和内容上相对独立的博客。独立博客相当于一个独立的网站，而且不属于任何其他网站。相对于BSP下的博客，独立博客更自由、灵活，不受限制。\n这里的定义更接近个人网站的概念，但我想，应当对其做进一步的区分。\n首先，有些“博客”更像是教程网站或电商平台，在我看来，如果没有生活和观点的记录，就已经脱离了（独立）博客的范畴。在个人内容的前提下，我心中的独立博客：\n个人搭建，独立空间、域名：并非必要，公共平台也可以很好。 基于独立思考的创作：有自己的观点，非流水账，非转发集锦。 具备个人特色的写作：这一点并不容易，但我觉得找到自己的风格是很重要的。 下面说几个我比较认可的做法。\n有选择地记录 与其纠结记录什么，不如先想想哪些内容不合适。比如：\n仅叙述事情的经过（流水账）。 过于简单的介绍或教程。 咀嚼前人观点的老生常谈。 一开始可能会为了写而写，但不要放弃自我的表达。\n有意识地删减 自从发现自己有行文啰嗦的毛病之后，就立下了目标：言简意赅。\n有时会翻看之前的博客，看看还有哪些可以删减的地方。当然，有时为了说清楚某件事，难免为此多添笔墨，因此也需要一定的取舍。\n尝试不同的叙述视角 我认为在表述论点时第一人称是最佳选择，但是其他视角也有各自的适用场景。对于历史事件的描绘，第三人称是必要的；而第二人称可以给读者带来更真切的感受。\n之所以提到这一点，是因为在写作时偶尔会对此感到困惑。有时候会突然想换一种视角，但又怕打乱原有的风格。大概只有多尝试才能找到最适合自己的方式吧。\n如今的独立博客早已不是主流，但依然不断地有人出现并坚持在这条路上。自由独立地表达内心，我想这就是它最大的意义。","title":"论独立博客"},{"content":"之前听过这么一段话：\n当你老了，回顾一生，就会发觉：什么时候出国读书，什么时候决定做第一份职业，何时选定对象而恋爱，什么时候结婚，其实都是命运的巨变。只是当时站在三岔路口，眼见风云千樯，你做出选择的那一天，在日记上，相当沉闷和平凡，当时还以为是生命中普通的一天。\n我想，今天早上在公交车上度过的短暂时光，已可算是我生命中的巨变，自己并非没有察觉，因为这一切来得如同阳光普照，万象更新。\n近几年来，渐渐开始习惯有规划地做事，生活也变得规律简单。看过 The social delimma 那部纪录片之后，关闭了朋友圈，对手机的依赖也愈加减少。初期时常恍惚，甚至不知该做些什么，习惯之后反而觉得轻松，时间好像在不知不觉中变多了。\n然而焦虑和不安却总是挥之不去，有时来自周围的人，有时是未来的自己。这些情绪化为奋斗的催化剂，又将我变成行尸走肉。不管如何挣扎，都填补不了内心的空洞，只觉得一切虚如幻梦。\n以上作为背景的铺垫，还有两件小事发生得更早些，之所以一起记录，是因为回头来看，它们恰好可以串在一起。\n首先是在听晓说播客的时候，高晓松提到了人类和小麦之间的驯服关系：人们发现种子落在地里可以长出食物于是开启了农业时代，是为人类驯服了小麦；而农业发展也使得人们的生活从悠闲的采摘变成了繁忙的耕种，即小麦反过来驯服了人类。想来真的讽刺，生活水平提高，我们却变得更忙碌。\n其次是孟岩的一篇文章，里面解释了文字作为思想交流工具的特点和局限性。信息传输难免会有损耗，再加上背景知识和人生阅历的差异，很多道理往往只可意会，不可言传。\n最后就是今天早上无意中看到的一段话，我因此打开了通向自己内心的大门。\n弄清楚我们想做什么是世上最困难的事情之一。不但在青少年时代如此，在我们一生中，这个问题都存在着。除非你亲自弄清楚什么是你真正想做的事，否则你会做一些对你没有太大意义的事，你的生命就会变得十分悲惨，正因为你过得很悲惨，你就必须从戏院、酗酒、阅读数不尽的书籍，做社会改革的工作以及其他事情来让自己分心。你一旦发现真正爱做的事，你就是一个自由的人了，然后你就会有能力、信心和主动创造的力量。但是如果你不知道自己真正爱做的是什么，你只好去做人人羡慕的律师、政客或这个那个，于是你就不会有快乐，因为那份职业会变成毁灭你自己及其他人的工具。\n之所以受了巨大震动，是因为我迷惘在这个问题上太久了。同样，我未想清楚自己是谁，也困惑于奋斗的意义。如果没有弄清楚这些，可能越努力，就会越痛苦吧。\n回看高晓松的播客，让我意识到人类的发展史就像自己的困兽之斗，经历了许多，却仍旧徘徊在内心之外；再联系到孟岩的文章，如果没有切身的痛苦挣扎，即使看到那段话，我也不会有所感悟。\n因为今天，我已和过去不一样，感谢一切的点点滴滴，感谢生命之光。\n","permalink":"https://iamgodot.com/posts/the-silverlining/","summary":"之前听过这么一段话：\n当你老了，回顾一生，就会发觉：什么时候出国读书，什么时候决定做第一份职业，何时选定对象而恋爱，什么时候结婚，其实都是命运的巨变。只是当时站在三岔路口，眼见风云千樯，你做出选择的那一天，在日记上，相当沉闷和平凡，当时还以为是生命中普通的一天。\n我想，今天早上在公交车上度过的短暂时光，已可算是我生命中的巨变，自己并非没有察觉，因为这一切来得如同阳光普照，万象更新。\n近几年来，渐渐开始习惯有规划地做事，生活也变得规律简单。看过 The social delimma 那部纪录片之后，关闭了朋友圈，对手机的依赖也愈加减少。初期时常恍惚，甚至不知该做些什么，习惯之后反而觉得轻松，时间好像在不知不觉中变多了。\n然而焦虑和不安却总是挥之不去，有时来自周围的人，有时是未来的自己。这些情绪化为奋斗的催化剂，又将我变成行尸走肉。不管如何挣扎，都填补不了内心的空洞，只觉得一切虚如幻梦。\n以上作为背景的铺垫，还有两件小事发生得更早些，之所以一起记录，是因为回头来看，它们恰好可以串在一起。\n首先是在听晓说播客的时候，高晓松提到了人类和小麦之间的驯服关系：人们发现种子落在地里可以长出食物于是开启了农业时代，是为人类驯服了小麦；而农业发展也使得人们的生活从悠闲的采摘变成了繁忙的耕种，即小麦反过来驯服了人类。想来真的讽刺，生活水平提高，我们却变得更忙碌。\n其次是孟岩的一篇文章，里面解释了文字作为思想交流工具的特点和局限性。信息传输难免会有损耗，再加上背景知识和人生阅历的差异，很多道理往往只可意会，不可言传。\n最后就是今天早上无意中看到的一段话，我因此打开了通向自己内心的大门。\n弄清楚我们想做什么是世上最困难的事情之一。不但在青少年时代如此，在我们一生中，这个问题都存在着。除非你亲自弄清楚什么是你真正想做的事，否则你会做一些对你没有太大意义的事，你的生命就会变得十分悲惨，正因为你过得很悲惨，你就必须从戏院、酗酒、阅读数不尽的书籍，做社会改革的工作以及其他事情来让自己分心。你一旦发现真正爱做的事，你就是一个自由的人了，然后你就会有能力、信心和主动创造的力量。但是如果你不知道自己真正爱做的是什么，你只好去做人人羡慕的律师、政客或这个那个，于是你就不会有快乐，因为那份职业会变成毁灭你自己及其他人的工具。\n之所以受了巨大震动，是因为我迷惘在这个问题上太久了。同样，我未想清楚自己是谁，也困惑于奋斗的意义。如果没有弄清楚这些，可能越努力，就会越痛苦吧。\n回看高晓松的播客，让我意识到人类的发展史就像自己的困兽之斗，经历了许多，却仍旧徘徊在内心之外；再联系到孟岩的文章，如果没有切身的痛苦挣扎，即使看到那段话，我也不会有所感悟。\n因为今天，我已和过去不一样，感谢一切的点点滴滴，感谢生命之光。","title":"生命之光"},{"content":"最近碰到一个服务器报错，排查后发现是参数中包含了 emoji，导致数据库插入记录失败了。\n虽然业务上不要求支持，但好奇之下，我还是基于 MySQL 做了个实验。\nWhat\u0026rsquo;s emoji 🧐 关于 emoji 比较官方的解释：\nEmoji are pictographs (pictorial symbols) that are typically presented in a colorful form and used inline in text. They represent things such as faces, weather, vehicles and buildings, food and drink, animals and plants, or icons that represent emotions, feelings, or activities.\n那么 emoji 是怎么来的呢：\nEmoji are \u0026ldquo;picture characters\u0026rdquo; originally associated with cellular telephone usage in Japan, but now popular worldwide. The word emoji comes from the Japanese 絵 (e ≅ picture) + 文字 (moji ≅ written character).\n关于更详细的说明，可以阅读这篇文章：Everything you need to know about emoji。\nCharset in MySQL MySQL 中的 utf8（也就是 utf8mb3）最多只用 3 个字节编码，所以是无法支持 BMP（简单来说就是绝大部分的文字和符号）以外的字符的，emoji（需要 4 个字节表示）就是其中之一，此时就需要使用 utf8mb4 编码，如下图所示：\nCharset 有多个级别的设置，可以只对单表或者单列使用 utf8mb4，毕竟这种方式要占用更多的存储空间。\nMySQL 对 Charset 的支持分为以下几种，从上到下的粒度依次减小，如果某一级没有显式设定的话会默认使用上一级的配置：\ncharacter_set_server character_set_database table character set column character set 前两者可以在 show variables like \u0026quot;character%\u0026quot;; 的结果中找到，后面两个（如果指定了的话）可以通过建表语句 show create table t_name; 查看。\nMore charset in MySQL 按理说完成上述设置后字段就能够支持 emoji 了，但插入时却失败了：\n原因是还有变量没设置正确：\ncharacter_set_client 和 character_set_connection 的值还是 utf8，它们控制的分别是客户端在交互和传输过程中使用的字符集。更新之后插入成功，但查询结果却显示乱码：\n这是因为 character_set_results 还没改过来，它表示服务器在回传响应时使用的字符集。再次更新后，便一切正常了：\nDjango settings 在服务器开发中，还要记得更改代码中的 Charset，比如 Django 里的配置：\nDATABASES = { \u0026#34;default\u0026#34;: { # ... \u0026#34;OPTIONS\u0026#34;: { \u0026#34;charset\u0026#34;: \u0026#34;utf8mb4\u0026#34;, # ... } } } 除了更换字符集，也有应用层的解决方案。比如先维护 emoji 与普通字符串的映射，然后在存储前和查询后做转换。虽然麻烦些，但好处是不破坏现有数据库的状态，更加灵活地控制转换逻辑。\n当然，如果能在一开始确认需求，比如为用户名或评论支持 emoji，然后建表时直接使用 utf8mb4 是最好的。\n","permalink":"https://iamgodot.com/posts/use-emoji-in-mysql/","summary":"最近碰到一个服务器报错，排查后发现是参数中包含了 emoji，导致数据库插入记录失败了。\n虽然业务上不要求支持，但好奇之下，我还是基于 MySQL 做了个实验。\nWhat\u0026rsquo;s emoji 🧐 关于 emoji 比较官方的解释：\nEmoji are pictographs (pictorial symbols) that are typically presented in a colorful form and used inline in text. They represent things such as faces, weather, vehicles and buildings, food and drink, animals and plants, or icons that represent emotions, feelings, or activities.\n那么 emoji 是怎么来的呢：\nEmoji are \u0026ldquo;picture characters\u0026rdquo; originally associated with cellular telephone usage in Japan, but now popular worldwide.","title":"Use emoji in MySQL"},{"content":"最近读了《编写可读代码的艺术》这本书，收获良多。\n整本书的核心都在于一个原则：代码应当易于理解。作者在开篇就提出了可读性的概念：\n代码的写法应当使别人理解它所需要的时间最小化。\n上述的别人更有可能是未来的自己，所以保证可读性非常有助于节省自己的时间。\nNaming There are only two hard things in Computer Science: cache invalidation and naming things. \u0026ndash; Phil Karlton\n命名非常重要。不论是变量常量，还是方法对象，一旦确定名称，代码的整体风格就开始受到影响，并且会一直持续下去。\n书里介绍的各种技巧，大致都基于信息量和准确性两点。前者可以保证名称足够有意义，同时也检验了其存在的必要性；而后者能够减少代码中的重复定义，还有助于加速 debug 的推导过程。\n另外，单词量有时也会影响命名能力。比如 make，作为动词来描述一个操作可能并不够清晰，更好的选择还有 create/generate/setup/compose 等。如果不认识这些单词，就想不到更多更合适的名称。\nComment 给代码加注释是一件很有争议的事情，因此作者也提到：要明确什么时候需要，什么时候不需要。好的代码如同好的文章，自成一体，但这不代表注释就是无意义的。\n广义上讲，注释也是另一种形式的文档。单行注释、方法的注解和模块的说明，对于不想了解实现细节的人来说，比代码本身更有价值。\n在工作中，写文档的时间并不比编码少。两者并不冲突，因为归根到底都是要把一件事情描述清楚，一个给人看，另一个给机器。文档写得清晰，写代码也会轻松。从使用者的角度看，对于开源项目，我们对文档的关注度更高，在使用中大部分时间都是在查阅手册，而非源代码。\nLess is more 在 Python 中写出好看的 Oneliner 很容易，但后果可能是灾难性的，会给代码的修改和调试过程带来意想不到的困难。Debug 时往往需要快速定位问题，如果遇到过于压缩的语句，便很难在短时间内拆解逻辑，更不用说再做修改，此时的代码就像个花瓶，精致而易碎。\nLess is more。不考虑可读性的话，代码越少，带来的麻烦反而会越多。\nWriting 书里还说把想法变成代码，关键在于是否能把程序要做的事情用自然语言解释清楚。\n这和写文章何其相似：命题，描述中心思想，行文通顺，言之有物。如果是写一个函数，那就变成：抽象接口，梳理逻辑，解耦并拆分子任务。\n随着时间发展，还要给内容做适当的减法。比如抽取重复的代码逻辑，OOP，用第三方库代替现有功能。对于文章来说则是，删除废话，同样的描述语只保留一个，使用更精简的词汇表达等等。\n把编码当成写作，是这件事最吸引我的地方。前者不只是枯燥的堆砌，后者也并非涂鸦般简单，在 Art of readability 这一点上，它们是相通的。\n","permalink":"https://iamgodot.com/posts/the-art-of-readable-code/","summary":"最近读了《编写可读代码的艺术》这本书，收获良多。\n整本书的核心都在于一个原则：代码应当易于理解。作者在开篇就提出了可读性的概念：\n代码的写法应当使别人理解它所需要的时间最小化。\n上述的别人更有可能是未来的自己，所以保证可读性非常有助于节省自己的时间。\nNaming There are only two hard things in Computer Science: cache invalidation and naming things. \u0026ndash; Phil Karlton\n命名非常重要。不论是变量常量，还是方法对象，一旦确定名称，代码的整体风格就开始受到影响，并且会一直持续下去。\n书里介绍的各种技巧，大致都基于信息量和准确性两点。前者可以保证名称足够有意义，同时也检验了其存在的必要性；而后者能够减少代码中的重复定义，还有助于加速 debug 的推导过程。\n另外，单词量有时也会影响命名能力。比如 make，作为动词来描述一个操作可能并不够清晰，更好的选择还有 create/generate/setup/compose 等。如果不认识这些单词，就想不到更多更合适的名称。\nComment 给代码加注释是一件很有争议的事情，因此作者也提到：要明确什么时候需要，什么时候不需要。好的代码如同好的文章，自成一体，但这不代表注释就是无意义的。\n广义上讲，注释也是另一种形式的文档。单行注释、方法的注解和模块的说明，对于不想了解实现细节的人来说，比代码本身更有价值。\n在工作中，写文档的时间并不比编码少。两者并不冲突，因为归根到底都是要把一件事情描述清楚，一个给人看，另一个给机器。文档写得清晰，写代码也会轻松。从使用者的角度看，对于开源项目，我们对文档的关注度更高，在使用中大部分时间都是在查阅手册，而非源代码。\nLess is more 在 Python 中写出好看的 Oneliner 很容易，但后果可能是灾难性的，会给代码的修改和调试过程带来意想不到的困难。Debug 时往往需要快速定位问题，如果遇到过于压缩的语句，便很难在短时间内拆解逻辑，更不用说再做修改，此时的代码就像个花瓶，精致而易碎。\nLess is more。不考虑可读性的话，代码越少，带来的麻烦反而会越多。\nWriting 书里还说把想法变成代码，关键在于是否能把程序要做的事情用自然语言解释清楚。\n这和写文章何其相似：命题，描述中心思想，行文通顺，言之有物。如果是写一个函数，那就变成：抽象接口，梳理逻辑，解耦并拆分子任务。\n随着时间发展，还要给内容做适当的减法。比如抽取重复的代码逻辑，OOP，用第三方库代替现有功能。对于文章来说则是，删除废话，同样的描述语只保留一个，使用更精简的词汇表达等等。\n把编码当成写作，是这件事最吸引我的地方。前者不只是枯燥的堆砌，后者也并非涂鸦般简单，在 Art of readability 这一点上，它们是相通的。","title":"The Art of Readable Code"},{"content":"The Social Dilemma 是一部 Netflix 原创纪录片，讲述了社交平台是如何通过大数据算法分析人们的行为偏好，并利用广告推送获利的。这一切高速发展到今天，已经脱离设计者的初衷，把无数用户变成了资本交易的砝码。\nThreat 影片在采访中穿插了一部短片，描述了一个家庭的孩子们从一开始沉迷社交应用到最终被洗脑的过程。两部分内容交织在一起，更让人感觉到那些负面影响是真实地存在于我们的生活中。\n免费的应用背后隐藏着简单粗暴的商业模式：广告商出钱给科技公司，后者投放广告。听上去很合理，但科技手段却在资本的推动下演变成为高效的洗脑工具。\nIf you don\u0026rsquo;t pay for the product, then you are the product.\nIt\u0026rsquo;s the gradual, slight, imperceptible change in your own behavior and perception that is the product.\n这些 App 并不限于被动使用，还能够主动出击。消息提醒、定时推送、定位监控像一个个无形的陷阱，让它们可以精准地对用户实施围捕。\n在我看来，科技的阴谋论有些老生常谈。但想想自己，再结合片中的分析，确实有些后怕。习惯养成，让我很难抗拒每天对手机和各类 App 的使用；信息茧房，让我看到越来越多的相似言论，相信世界一如既往地符合自己的想象。\n至于人控制人，自古以来都是如此吧，不论手机还是八股。但影片还提到，在大数据的疯狂催化下，科技的巨兽早已脱缰，没有人知道这样发展下去，究竟会对世界造成怎样的影响。所以如果有一天我们迎来终结者或者奥创的剧情，可能也不足为奇。\nSolution 影片后面还给出了一些应对的建议，比如：\n关闭消息推送和应用提醒。 使用其他的搜索引擎（不记录个人数据的那种）。 拒绝类似 Youtube Video 的推荐。 关注不同的消息源，比如 Twitter 上不同立场的帐号。 不要给孩子太多的手机使用和网络社交时间。 删除社交应用帐号。 这些建议看上去有些不太现实，我觉得最重要的是想清楚使用手机和 App 的目的，不要被带着走。经过一番尝试，我做了如下改变：\n卸载不必要的应用。 社交：保留微信（关闭朋友圈）和豆瓣，还有 TG。 阅读：一个 RSS App，外加微信公众号。 音乐：一个简洁版的 QQ 音乐（网易云的广告太多了）。 尽量关闭所有的推送提醒。 捡回 Kindle。 整体效果还不错，明显感觉到时间变多了，最重要的两点要数退出朋友圈和关闭通知。虽然依旧会刷豆瓣，但是有了防范之心，也不算太沉迷。\n这应该是目前为止纪录片影响我最大的一次了。\nDilemma 说回社交本身，App 真的可以带来改变么？像我自己，现实生活中不爱说话，虚拟世界里同样一言不发。潜水围观网络上的各种喧闹，沉默地与街上形形色色的人擦肩而过，好像并没有什么不同。\n为了避免出门选择网络，又因为惯性迷失其中，对我来说，这才是真正的 Social dilemma，进退两难。如今，距离不是社交的障碍，恐惧才是。想交朋友，就要走出去，还得学会说话，见识这个世界的真实面貌。\n以影片最后的一句话结尾吧：\nThe world is beautiful, it\u0026rsquo;s great out there.\n","permalink":"https://iamgodot.com/posts/the-social-dilemma/","summary":"The Social Dilemma 是一部 Netflix 原创纪录片，讲述了社交平台是如何通过大数据算法分析人们的行为偏好，并利用广告推送获利的。这一切高速发展到今天，已经脱离设计者的初衷，把无数用户变成了资本交易的砝码。\nThreat 影片在采访中穿插了一部短片，描述了一个家庭的孩子们从一开始沉迷社交应用到最终被洗脑的过程。两部分内容交织在一起，更让人感觉到那些负面影响是真实地存在于我们的生活中。\n免费的应用背后隐藏着简单粗暴的商业模式：广告商出钱给科技公司，后者投放广告。听上去很合理，但科技手段却在资本的推动下演变成为高效的洗脑工具。\nIf you don\u0026rsquo;t pay for the product, then you are the product.\nIt\u0026rsquo;s the gradual, slight, imperceptible change in your own behavior and perception that is the product.\n这些 App 并不限于被动使用，还能够主动出击。消息提醒、定时推送、定位监控像一个个无形的陷阱，让它们可以精准地对用户实施围捕。\n在我看来，科技的阴谋论有些老生常谈。但想想自己，再结合片中的分析，确实有些后怕。习惯养成，让我很难抗拒每天对手机和各类 App 的使用；信息茧房，让我看到越来越多的相似言论，相信世界一如既往地符合自己的想象。\n至于人控制人，自古以来都是如此吧，不论手机还是八股。但影片还提到，在大数据的疯狂催化下，科技的巨兽早已脱缰，没有人知道这样发展下去，究竟会对世界造成怎样的影响。所以如果有一天我们迎来终结者或者奥创的剧情，可能也不足为奇。\nSolution 影片后面还给出了一些应对的建议，比如：\n关闭消息推送和应用提醒。 使用其他的搜索引擎（不记录个人数据的那种）。 拒绝类似 Youtube Video 的推荐。 关注不同的消息源，比如 Twitter 上不同立场的帐号。 不要给孩子太多的手机使用和网络社交时间。 删除社交应用帐号。 这些建议看上去有些不太现实，我觉得最重要的是想清楚使用手机和 App 的目的，不要被带着走。经过一番尝试，我做了如下改变：\n卸载不必要的应用。 社交：保留微信（关闭朋友圈）和豆瓣，还有 TG。 阅读：一个 RSS App，外加微信公众号。 音乐：一个简洁版的 QQ 音乐（网易云的广告太多了）。 尽量关闭所有的推送提醒。 捡回 Kindle。 整体效果还不错，明显感觉到时间变多了，最重要的两点要数退出朋友圈和关闭通知。虽然依旧会刷豆瓣，但是有了防范之心，也不算太沉迷。","title":"The Social Dilemma"},{"content":"Pandemic: How to Prevent an Outbreak 是 Netflix 出品的一部纪录片，共有六集。这部短剧在 2020 年初播出，正好赶上了新冠的爆发。它告诉人们，疫情并非大自然的偷袭，而是暴风雨按部就班的来临。\nInfluenza 这个词源自意大利语，意思就是我们常说的流感（Flu）。虽然普通感冒和流行性感冒都是由于呼吸道感染病毒导致的，但后者的症状严重很多，传染性也更强。\n目前人类感染的流感病毒有甲型、乙型、丙型三种。其中甲型 H1N1 病毒正是 1918 年西班牙流感大流行事件中造成全球 5 亿人感染、1.7 千万至 5 千万人死亡的罪魁祸首。之后的一百年里还出现过多次流感疫情，比如 2003 年起源于国内的 H5N1 禽流感，和 2009 年墨西哥城爆发的甲型 H1N1 流感（也称为猪流感），后者在一年多的时间内导致 7 亿到 14 亿人感染、15 万到 57.5 万人死亡。\n此外还有庞大的冠状病毒家族，包括这次的 COVID-19，之前的非典 SARS-CoV（严重急性呼吸综合症）和 MERS-CoV（中东呼吸综合症）。常见的冠状病毒通常会引起上呼吸道感染，而 SARS 和 MERS 带来的症状更加严重，比如呼吸急促、肺炎甚至导致死亡。\n这些远不是全部，还有更多更致命的病毒散落在全世界的各个地方。比如埃博拉，在苏丹和刚果出现，是一种能引起人类和其他灵长类动物产生埃博拉出血热的烈性传染病病毒。生物安全等级为 4 级，比 SARS 和艾滋病还要高一级。\n常见的传染病分类 呼吸道传染病 流感（Flu） 肺结核（Tuberculosis） 百日咳（Whooping cough） 麻疹（Measles） 非典（SARS） 消化道传染病 细菌性痢疾（Bacillary dysentery） 小儿麻痹症（Polio） 蛔虫病（Ascariasis） 伤寒（Typhoid） 霍乱（Cholera） 血液传染病 乙肝（Hepatitis B） 疟疾（Helopyra） 性传染病 艾滋病（AIDS） 梅毒（Syphilis） 故事线 说回纪录片，整剧分成多条故事线叙述，可能是因为内容太多，在有限的篇幅里稍显凌乱。我尝试梳理了每条支线的梗概：\nDr. Dennis Carroll，就是最开始那个白色长发的美国老头，应该是个国际性防控组织的主任。他一直在越南进行禽流感的防治，也多亏了像他一样坚守在世界各地的工作者，让偏远地区的疫情能得到及时的控制。 Holly Goracke，是俄克拉荷马州 Jefferson County Hospital 唯一的医生。是当地唯一的专业医师，也正因为此，她一直住在医院，一个月（也可能是半个月，记不太清楚了）才休息一次。可能是由于之前的婚姻很不幸福，所以在最后，为了和男友（一个非常理解她的好男人）修复关系，她选择了回归家庭生活。这一段很打动我，因为最近疫情的发展让我深刻意识到医护人员的辛劳付出，为了治病救人牺牲自己的生活、家庭甚至生命。从来就没有什么天使，他（她）们只是一群普通人，却勇敢地坚守在抗疫的最前线。 Jake Glanville，一个稍微有点发福的科技创业公司 CEO，致力于世界首批 Universal Flu Vaccine 的发明。如果能够成功制造这种疫苗，人们只要打一次疫苗便能够终生免疫了。此外还有一个年轻一些的女科学家，因为作为研究对象的小猪价格昂贵，所以他们两个跑到危地马拉去搞研究，一个小猪很便宜的地方。在最后他们获取了阶段性成功，证明了疫苗在猪身上是有效的，也因此得到了盖茨基金会的赞助。 Dr. Dinesh Vijay，是一位印度医师，剧中主要展现了他尽力救治各种被流感折磨的病人。由于印度的人数众多，如果疫情失控，医疗资源肯定是不够的。其实国内也是一样，很多人意识不到病毒的危险，也做不到基本的防护措施，一旦爆发，传播速度会非常快。 Dr. Syra Madad，纽约健康医院（不太知道怎么翻译）的一位高级主管，从埃博拉的时候就开始参与到传染病的防控工作，看起来是一位非常善良能干的女性。她信仰伊斯兰教，有两个孩子，每天除了繁忙的工作还要带孩子，感觉她的丈夫太不负责了。 Dr. Michel Yao，是 WHO 的工作人员，在非洲进行埃博拉病毒的防控工作，努力阻止病毒蔓延到戈马（刚果的一座城市）。因为经济落后，非洲的防疫开展起来更加艰难，很多人不理解检查站和疫苗注射这类措施，更有人恶意伤害志愿者们。其中有一段 Michel 在跟家人视频之后说自己一直想辞职回家，但是看到每天能减少一些无辜人的伤亡，就又能多坚持一段时间。看了不禁莫名感动，没有这些人的坚持，可能大家都逃脱不了被感染的命运。 Tucson, Arizona, USA。这里是美国墨西哥的边境，在这个临时的避难所，每天都会有几十甚至上百的移民来落脚，对于这些人，接种疫苗是必要的，但如果没有足够的资源，志愿者也无能为力。这里主要是以一位美国大妈（志愿者）的视角来讲述的，她有句话说得很好：我们已经有足够的天灾了，不要再增加无谓的人祸。 Corvallis, Oregon, USA。这部分描绘了两拨人对于疫苗的不同态度。政府一方想增加法案，禁止未接种疫苗的孩子和其他孩子接触。反对者们对此非常不满，他们认为这侵犯了人权自由，同时也因为疫苗的副作用拒绝接种。最后法庭的审判结果驳回了法案，然而双方都知道这场没有硝烟的战争不会停止，只是暂时告一段落而已。 我认为疫苗的普及是必要的，也坚信自由不可或缺。在美国，类似的意识形态冲突好像无处不在。最后一个故事里，再发展下去，也许法案会通过，反对者们不得不接受现实，或者选择离开，搬到其他州生活。大家都有自己的立场和顾虑，结局却无法让所有人满意，但那又怎么样呢？\n除了这部纪录片，还有很多电影都在一定程度上预言了这次的全球疫情，比如美国电影《传染病》，韩国电影《流感》。当时人们可能觉得危言耸听，现在想想多么讽刺啊。\n另外再推荐两本书：\n大流感 致命流感 ","permalink":"https://iamgodot.com/posts/pandemic/","summary":"Pandemic: How to Prevent an Outbreak 是 Netflix 出品的一部纪录片，共有六集。这部短剧在 2020 年初播出，正好赶上了新冠的爆发。它告诉人们，疫情并非大自然的偷袭，而是暴风雨按部就班的来临。\nInfluenza 这个词源自意大利语，意思就是我们常说的流感（Flu）。虽然普通感冒和流行性感冒都是由于呼吸道感染病毒导致的，但后者的症状严重很多，传染性也更强。\n目前人类感染的流感病毒有甲型、乙型、丙型三种。其中甲型 H1N1 病毒正是 1918 年西班牙流感大流行事件中造成全球 5 亿人感染、1.7 千万至 5 千万人死亡的罪魁祸首。之后的一百年里还出现过多次流感疫情，比如 2003 年起源于国内的 H5N1 禽流感，和 2009 年墨西哥城爆发的甲型 H1N1 流感（也称为猪流感），后者在一年多的时间内导致 7 亿到 14 亿人感染、15 万到 57.5 万人死亡。\n此外还有庞大的冠状病毒家族，包括这次的 COVID-19，之前的非典 SARS-CoV（严重急性呼吸综合症）和 MERS-CoV（中东呼吸综合症）。常见的冠状病毒通常会引起上呼吸道感染，而 SARS 和 MERS 带来的症状更加严重，比如呼吸急促、肺炎甚至导致死亡。\n这些远不是全部，还有更多更致命的病毒散落在全世界的各个地方。比如埃博拉，在苏丹和刚果出现，是一种能引起人类和其他灵长类动物产生埃博拉出血热的烈性传染病病毒。生物安全等级为 4 级，比 SARS 和艾滋病还要高一级。\n常见的传染病分类 呼吸道传染病 流感（Flu） 肺结核（Tuberculosis） 百日咳（Whooping cough） 麻疹（Measles） 非典（SARS） 消化道传染病 细菌性痢疾（Bacillary dysentery） 小儿麻痹症（Polio） 蛔虫病（Ascariasis） 伤寒（Typhoid） 霍乱（Cholera） 血液传染病 乙肝（Hepatitis B） 疟疾（Helopyra） 性传染病 艾滋病（AIDS） 梅毒（Syphilis） 故事线 说回纪录片，整剧分成多条故事线叙述，可能是因为内容太多，在有限的篇幅里稍显凌乱。我尝试梳理了每条支线的梗概：","title":"Pandemic"},{"content":"朋友们 莫愁前路无知已，天下谁人不识君。\n胡涂说 Airing 的小屋 Sulv\u0026rsquo;s Blog 关于我 名 Godot，Python 工程师，北漂多年，现已南下。\n爱好写东西，包括代码。博客虽然小众，却是精神家园。\n喜欢看书，少时钟情武侠，如今乐于哲学。记忆里的书单已有些破碎：\n武侠 金庸：缘起。 古龙：永远的浪漫，永远的紫禁之巅。 温瑞安：坑多，且大。 小说 王小波：写文章与写代码的最高境界大概也许是一样的罢。 都梁：爱李云龙，爱钟跃民，爱北平。 毛姆：剃刀边缘无比锋利，欲通过者无不艰辛。 鲁迅：此后如竟没有炬火，我便是唯一的光。 哲学 道德经：道生万物，为法自然。 世界哲学史：人不能两次阅读同一本哲学史，因为实在太累了。 叔本华：哲学可以很深奥，他的文字却如此流畅。 喜欢电影，自觉在演员认脸方面有一定天赋。热爱老式港片，热爱那个黄金年代。\n喜欢音乐，不懂，但爱听，摇滚、流行、说唱以及 OST 等。\n喜欢游戏谈不上，只是很享受在其中探索的感觉，比如刺客信条：奥德赛。\n喜欢的工具：\nArch Linux Neovim 日常开发 Typora 博客写作 Picgo 配合博客图片上传 Obsidian 知识库，配合 Dropbox 同步 Taskito 任务清单 App Google Keep 手机记录专用 关于博客 写过框架，也曾尝试 Hexo、WordPress、Ghost，目前在用 Hugo，感觉尚可：\n没有导入导出的格式要求，只需维护 Markdown 文件。 Typora 配合 Picgo 可以轻松上传图片。 用 shortcodes 渲染 Youtube 或 Mermaid。 推荐集成 giscus 作为评论系统。 仓库在 GitHub 维护，提交推送之后会自动触发部署更新，很方便。 ","permalink":"https://iamgodot.com/about/","summary":"朋友们 莫愁前路无知已，天下谁人不识君。\n胡涂说 Airing 的小屋 Sulv\u0026rsquo;s Blog 关于我 名 Godot，Python 工程师，北漂多年，现已南下。\n爱好写东西，包括代码。博客虽然小众，却是精神家园。\n喜欢看书，少时钟情武侠，如今乐于哲学。记忆里的书单已有些破碎：\n武侠 金庸：缘起。 古龙：永远的浪漫，永远的紫禁之巅。 温瑞安：坑多，且大。 小说 王小波：写文章与写代码的最高境界大概也许是一样的罢。 都梁：爱李云龙，爱钟跃民，爱北平。 毛姆：剃刀边缘无比锋利，欲通过者无不艰辛。 鲁迅：此后如竟没有炬火，我便是唯一的光。 哲学 道德经：道生万物，为法自然。 世界哲学史：人不能两次阅读同一本哲学史，因为实在太累了。 叔本华：哲学可以很深奥，他的文字却如此流畅。 喜欢电影，自觉在演员认脸方面有一定天赋。热爱老式港片，热爱那个黄金年代。\n喜欢音乐，不懂，但爱听，摇滚、流行、说唱以及 OST 等。\n喜欢游戏谈不上，只是很享受在其中探索的感觉，比如刺客信条：奥德赛。\n喜欢的工具：\nArch Linux Neovim 日常开发 Typora 博客写作 Picgo 配合博客图片上传 Obsidian 知识库，配合 Dropbox 同步 Taskito 任务清单 App Google Keep 手机记录专用 关于博客 写过框架，也曾尝试 Hexo、WordPress、Ghost，目前在用 Hugo，感觉尚可：\n没有导入导出的格式要求，只需维护 Markdown 文件。 Typora 配合 Picgo 可以轻松上传图片。 用 shortcodes 渲染 Youtube 或 Mermaid。 推荐集成 giscus 作为评论系统。 仓库在 GitHub 维护，提交推送之后会自动触发部署更新，很方便。 ","title":""}]