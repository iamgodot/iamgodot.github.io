<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Code on Godot's Blog</title><link>https://iamgodot.com/categories/code/</link><description>Recent content in Code on Godot's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 11 Aug 2022 07:19:04 +0800</lastBuildDate><atom:link href="https://iamgodot.com/categories/code/index.xml" rel="self" type="application/rss+xml"/><item><title>Amazon OA 2022</title><link>https://iamgodot.com/posts/amazon-oa-2022/</link><pubDate>Thu, 11 Aug 2022 07:19:04 +0800</pubDate><guid>https://iamgodot.com/posts/amazon-oa-2022/</guid><description>分享一下今年准备 Amazon OA 时整理的题目。
按照低中高的难度简单分了下类，最后的难题能理解思路是最好的，不建议死记硬背。
Easy 1. Maximum quality sent via a channel 给一个 packets 数组和 k 个 channel，要求每个 channel 里面必须至少有一个数组里面的元素，每个元素只能在一个 channel 里面。其中 packets 中的元素数量是大于等于 k 的。要求算出所有channel中位数之和的最大值。
def solution(packets: List[int], channels: int) -&amp;gt; int: &amp;#34;&amp;#34;&amp;#34; 将 packets 排序，依次把最大的一个元素分配给各 channel， 剩下的元素放到最后一个 channel。 &amp;#34;&amp;#34;&amp;#34; packets.sort() total = 0 length = len(packets) for i in range(length - channels + 1, length): total += packets[i] rest = length - channels + 1 if rest % 2 == 0: sum = packets[(rest - 1) // 2] + packets[rest // 2] total += sum // 2 if sum % 2 == 0 else sum // 2 + 1 else: total += packets[rest // 2] return total 这是当时做 OA 的第一题，很轻松搞定，结果第二题非常 Hard，下面会提到。</description></item><item><title>Sum of Total Strength of Wizards</title><link>https://iamgodot.com/posts/sum-of-total-strength-of-wizards/</link><pubDate>Tue, 26 Jul 2022 10:41:55 +0800</pubDate><guid>https://iamgodot.com/posts/sum-of-total-strength-of-wizards/</guid><description>前两天有幸做了一道算法题，虽然没能成功解决，但题目很有意思，充分展现了算法的魅力所在。
抛开题面的包装不谈，核心内容就是给定一个数组，计算它的所有子数组的最小值与加和的乘积的总和。
（这里要注意子数组的定义，一定是连续的，如果不连续的话叫做子序列。）
比如对于 [1, 2, 3] 来说，一共有六种情况：
[1]: 1 * 1 = 1 [2]: 2 * 2 = 4 [3]: 3 * 3 = 9 [1, 2]: 1 * (1 + 2) = 3 [2, 3]: 2 * (2 + 3) = 10 [1, 2, 3]: 1 * (1 + 2 + 3) = 6 最后答案为 1 + 4 + 9 + 3 + 10 + 6 = 33。</description></item><item><title>关于 SSH 端口转发</title><link>https://iamgodot.com/posts/ssh-port-forwarding/</link><pubDate>Wed, 22 Dec 2021 11:36:49 +0800</pubDate><guid>https://iamgodot.com/posts/ssh-port-forwarding/</guid><description>SSH 的端口转发很实用，但我总觉得难以理解和记忆，直到最近才有所好转。
因为又派上用场了。以前基本只做做内网穿透，现在更多地拿来绕过防火墙。自己的服务器，大多数端口虽然都是被禁用的（至少禁止入网，这也是正常的安全措施），但是想要连接的话直接本地端口转发就可以了。
TL;DR 本地端口转发在当前机器上设置，然后从本机出发，通过另一台机器，连接其他的机器。适用于防火墙的绕过、多重 SSH 登录等。
远程端口转发在当前机器上设置，然后从另外一台机器出发，通过当前机器，连接本机或者其他的机器。适用于 NAT 网络穿透、暴露内部网络服务等。
本质上都是先建立 SSH 会话，形成隧道，然后在上面进行正向或反向的数据传输。
Local Port Forwarding 为什么叫做本地呢，我想有两个原因：
转发的端口在当前（执行 SSH 命令这台）机器上 请求是从当前机器发出的 当前机器就是我的笔记本，另外一台是服务器。比如，在服务器上部署一个应用，开放给 8000 端口，但是被墙掉了，没办法在本地调试，怎么办？防火墙肯定开放了 SSH 登录的端口，比如 22，那么就让请求从本地的端口发送到服务器的 22 端口，再转发到 8000 端口，最后原路返回。我可以设置本地的端口也是 8000，这样直接用 localhost:8000 来访问应用就好了。
转发的重点在于本地的 8000 端口和服务器的 22 端口之间，因为请求到了服务器之后可以给应用的 8000，也可以给其他的机器，只要服务器能连接到：
# ssh -L local_port:dest_addr:dest_port server # Local 8000 &amp;lt; -- &amp;gt; Server 22 &amp;lt; -- &amp;gt; Server 8000 # -fNT 让 ssh 不要打开服务器 shell，并且转为后台运行 # server 隐含了使用 22 端口登录，当然也可以在 ssh config 中设置任意登录端口 ssh -fNT -L 8000:localhost:8000 server 注意这里的 dest 对应的 src 是 server，也就是说 localhost 及后面的 8000 都是 server 的 IP 和端口。可以理解为 server 是中介，整条通路是 local -&amp;gt; server -&amp;gt; dest.</description></item><item><title>From BitTorrent to Firewall</title><link>https://iamgodot.com/posts/from-bittorrent-to-firewall/</link><pubDate>Mon, 20 Dec 2021 17:00:00 +0800</pubDate><guid>https://iamgodot.com/posts/from-bittorrent-to-firewall/</guid><description>服务器能做什么？在 Awesome-Selfhosted 里可以找到上百种答案。如果带宽不算太小的话，那么 BT 下载是个不错的尝试。借着 No Time to Die 的上映我开始重温 007 系列，从皇家赌场到幽灵党，在服务器上的下载体验是很好的。
BitTorrent 在此之前，我基本上把 BT、种子、磁力、迅雷下载当成同一种东西。下载电影？先找种子或者磁力链接，打开迅雷下载，然后视速度决定要不要开个会员。
实际上这完全曲解了 BT 下载。
首先 BitTorrent 是一种网络协议。还记得计算机网络一开始就提到过除了 C/S 架构之外，还有 P2P(Peer-to-peer)，也就是网络中的各个节点都扮演了同等的角色，既是客户端也是服务器。BT 基于 P2P 实现了去中心化的文件分享，让网络数据的传输不再仅限于服务器的能力，而是共享带宽，每个人下载的同时也在上传，所以越多人参与速度就越快。
类似于 HTTP 和 FTP，BT 也是基于 TCP/IP 的一种应用层协议。基本上它是这么运作的：
我有一部电影，想把资源分享到网络，要先提供一个种子文件
种子文件实际上就是个文本文件，里面主要记录两部分信息
Trackers: 就是 Tracker 服务器的地址，这个服务器不是用来下载资源的，而是用于获取其他 Peers 的联系方式 Files: 一个视频文件会被（逻辑）划分为很多个虚拟分块，每块的索引和验证码都包含在这里 接下来我把种子文件发布出去，等待别人下载
这时候有人获取到种子了，于是开启了 BT 客户端下载
客户端先解析种子文件中的信息，找到 Tracker，然后询问有哪些 Peers
因为是第一个下载者，所以 Tracker 告知 Peer 目前只有我，也就是发布者
之后对方会尝试与我互连，然后根据 Files 信息交换数据，这里基本就是我上传给对方
下载的过程会以分块为单位进行，每块完成下载后会根据验证码再做校验
如果这时又有一个人开始下载，那么我和这第一个下载者都会贡献上传
随着更多用户的参与，（上传）下载的速度就会越来越快
可以发现，整个过程中 Tracker 是很关键的一步，如果没有有效的 Tracker 提供 Peers，后面的下载都无法开始。所以如果你的 BT 下载没有速度，首先要尝试多添加一些 Tracker 服务器，比如 TrackersList.</description></item><item><title>Python heapq 源码阅读</title><link>https://iamgodot.com/posts/sourcecode-of-python-heapq/</link><pubDate>Mon, 29 Nov 2021 23:26:37 +0800</pubDate><guid>https://iamgodot.com/posts/sourcecode-of-python-heapq/</guid><description>Heap 作为一种重要的数据结构，有许多应用场景，比如优先级队列，每次出队的都是最大值或者最小值的元素。很多语言都集成了相关实现，比如 Java 的 PriorityQueue，而 Python 提供了 heapq 模块。
因为 Heap 通常用数组而不是链表存储，所以 Python 里面的 Heap 实质上就是一个列表，而 heapq 提供的几个函数也是以列表对象作为参数的：
from heapq import heappush, heappop, heappify, heapreplace, heappushpop heap = [] heappush(heap, 1) item = heap[0] # 第一个元素代表堆顶元素 heappop(heap) heapify([3, 2, 1, 5, 6, 4]) # 把普通列表转化为堆结构 [1, 2, 3, 4, 5, 6] heapreplace([3, 4, 5], 1) # 直接将堆顶元素 3 替换为 1，最后堆结构为 [1, 4, 5] heappushpop([3, 4, 5], 1) # 先将 1 插入堆中，再 pop 出堆顶元素，最后堆结构为 [3, 4, 5] 为什么 heapq 提供的是最小堆而不是更常见的最大堆呢？这就得从源码中找答案了。</description></item><item><title>Python OrderedDict 实现 LRU 缓存</title><link>https://iamgodot.com/posts/sourcecode-of-python-ordereddict/</link><pubDate>Sun, 28 Nov 2021 17:50:51 +0800</pubDate><guid>https://iamgodot.com/posts/sourcecode-of-python-ordereddict/</guid><description>LRUCache 是一种经典的缓存机制，它的基本思路是按照最近使用的时间对元素排序，在清理时优先把搁置最久的删除掉。
如果不想给每个缓存元素都记录一个时间戳的话，可以应用哈希链表来简单地实现 LRU 算法。也就是对一个哈希表中的所有元素增加指针，从而串起一个双链表，这样既可以快速 get value，又可以通过把最近使用过的元素放到头部来维护顺序，删除的时候从末尾开始就好了。
手写双链表并不困难，但是借助 OrderedDict 的话，可以写出非常简短的代码：
from collections import OrderedDict class LRUCache: def __init__(self, capacity): self.capacity = capacity self.hashtable = OrderedDict() def get(self, key: int) -&amp;gt; int: if key in self.hashtable: self.hashtable.move_to_end(key, last=False) return self.hashtable[key] return -1 def put(self, key: int, value: int) -&amp;gt; None: self.hashtable[key] = value self.hashtable.move_to_end(key, last=False) if len(self.hashtable) &amp;gt; self.capacity: self.hashtable.popitem() 其中最神奇的就是 move_to_end 和 popitem 方法（后者默认是弹出最后面的元素）的使用，这也得益于 OD 可以保证 key-value pair 的顺序。那么
OD 是如何做到的呢？其实还是双链表，下面是它的 Python 实现：</description></item><item><title>Numeric Strings in Python</title><link>https://iamgodot.com/posts/numeric-strings-in-python/</link><pubDate>Sun, 21 Nov 2021 17:44:36 +0800</pubDate><guid>https://iamgodot.com/posts/numeric-strings-in-python/</guid><description>Python 的字符串自带了三种判断字符是否为数字的方法，但实际用处却相差很多。
TL;DR 三种方法 isdecimal &amp;lt; isdigit &amp;lt; isnumeric，即包含的范围越来越大 除了 ASCII 字符以外，对于 Unicode 的字符也都覆盖在内 三种方法对于小数点和负号都会返回 False 三种方法对于空字符串都会返回 False 比较简便判断数字字符串的方法：直接使用 float 方法并检测 ValueError Decimal &amp;amp; Digit &amp;amp; Numeric 对于 isdecimal, isdigit 和 isnumeric 三种方法，目的并不是判断字符串是不是一个有效数字，而是针对每一个字符的校验：
isdecimal: 判断字符串中的字符是否都为 Decimal，也就是在 Unicode 中类别为 Nd 的字符 isdigit: 除了 isdecimal 包含的范围之外，还会判断字符是否都为 Digit，即 Unicode 的 Numeric_Type 为 Digit 或 Decimal isnumeric: 除了 isdigit 包含的范围之外，还会判断字符是否都为 Numeric，即 Numeric_Type 为 Numeric 所以这三种方法覆盖的字符范围，每一个都是前一个的超集。对于超出 ASCII 字符之外的效果，比如：
&amp;ldquo;０１２３４５６７８９&amp;rdquo; 这种 Full-width 字符串 isdecimal 会判定为 True，后两个方法也一样 &amp;ldquo;⓪①②③④⑤⑥⑦⑧⑨&amp;rdquo; 这种 Circled-digit 字符串 isdecimal 判定 False，但 isdigit 和 isnumeric 为 True &amp;ldquo;一二三四五六七八九十壹貳參肆伍陸柒捌玖拾&amp;rdquo; 这种中文数字字符串只有 isnumeric 才会判定为 True 总之这几种方法有更广泛的用途，根本不是为了简单的 ASCII 数字字符串的判断。即使用来做判断的话，局限性也非常大，因为如果包含小数点和负号，三个方法都会返回 False.</description></item><item><title>From Wireshark to Linux Capabilities</title><link>https://iamgodot.com/posts/from-wireshark-to-linux-capabilities/</link><pubDate>Sun, 21 Nov 2021 13:39:25 +0800</pubDate><guid>https://iamgodot.com/posts/from-wireshark-to-linux-capabilities/</guid><description>Tcpdump 和 Wireshark 是抓包必备的程序，但是由于需要截取网络数据包，所以在 Linux 下必须以 root 的身份来运行。每次都 sudo 执行不方便也并不安全（对 Wireshark 来说捉包只是一小部分功能），解决方案当然有，在寻找的过程中我了解到了 Capabilities 的冰山一角。
TL;DR 可以通过设置 Setuid 以 root 身份执行，但如此以来赋予了过高的权限（也没有必要）。 Linux 下用 Capabilities 把系统权限划分成多个条目，以此实现细粒度地提升程序的执行能力。 Setuid 先盗一张图复习下 Linux File Permission 的基础知识：
除了 rwx 之外还存在三种特殊类型，即是为了在更高权限下运行程序：
Setuid: 程序的运行者不再是执行者，而是变成文件的所有者 Setgid: 程序的运行群组变成了文件的所在群组，如果给目录设置，那么其中新建的文件所有群组会变成目录的群组而不是执行者的群组 Sticky bit: 针对目录设置，目录下的文件只有所有者和 root 能够重命名、移动和删除 在 Linux 中 sudo 是 Setuid 最好的例子，而 crontab 和 tmp/ 分别是 Setgid 和 Sticky bit 的典型应用。
在命令行中测试：
# Setuid ➜ ~ umask -S u=rwx,g=rx,o=rx ➜ ~ umask # 掩码是 022，所以默认文件的权限是 666-022=644，而目录则是 777-022=755 022 ➜ ~ touch foo.</description></item><item><title>Overflow in Python</title><link>https://iamgodot.com/posts/overflow-in-python/</link><pubDate>Fri, 12 Nov 2021 17:20:10 +0800</pubDate><guid>https://iamgodot.com/posts/overflow-in-python/</guid><description>犹记得在 Java 中，int 占用 4 bytes 所以大小限制在 -2^32 和 2^32 -1 之间，如果考虑到溢出的情况，就要用 long 类型来转换。
但是在 Python 中似乎从来没有考虑过类似的问题，也不记得 int 是占几个字节，那么是说 Python 的数字永远不会溢出吗？不可能吧。
答案是对于 int 类型来说，可以认为不会；而 float 类型则需要注意溢出的情况。
首先说 int 类型，打印 sys.maxsize 可以看到 Python 会根据系统是 32 位还是 64 位来确定一个上限值，这点与 Java 等语言一致。不同的是我们仍然可以使用比这个上限大（得多）的整数，因为 Python 支持的是 Arbitrary-precision arithmetic。也就是说为了突破 CPU 字长带来的运算限制，通过在软件层面模拟计算过程，是可以完成更高位数和精度的运算的。比如在公钥加密的场景下，经常需要对上百位的整数进行运算，这时候就需要在软件层面支持。
这确实说明我们可以使用任意长度的 int 数字，只要不超出内存限制的话。因为如果给 Python 解释器分配了 2GB 内存，但是 2 * 1024 * 1024 * 1024 * 8 这么多位也不够表达的话，还是会出错的，只是并非 Overflow，而是 MemoryError.
再说 float. 打印 sys.float_info.max 可以看到 float 的上限值，如果超出之后是会报错的，即 OverflowError.</description></item><item><title>Understand Recursion Better</title><link>https://iamgodot.com/posts/understand-recursion-better/</link><pubDate>Mon, 08 Nov 2021 18:18:10 +0800</pubDate><guid>https://iamgodot.com/posts/understand-recursion-better/</guid><description>在 Simple Recursion 之后，我一度把递归当作一种算法。但通过比较 Divide and Conquer 和 Dynamic Programming，我才发现之前的理解有点问题。
一切还是要从 Algorithmic Paradigm 说起：
An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.
算法范式，是在算法的层面上抽象出来的一种更泛化的思想，常用的有：
Brute-force search 暴力解法 Backtracking 回溯算法 Greedy algorithm 贪心算法 Divide and conquer 分治法 Dynamic programming 动态规划 Divide and Conquer 的基本思路是把复杂的问题分解成多个类似的简单问题，解决之后再组合起来得到最终结果。这种算法有很多应用，比如排序中的 Merge Sort，先将数列分解成单个元素，然后再归并，这时子数组都已经排好顺序了，所以过程很快。</description></item><item><title>Record Terminal as GIF</title><link>https://iamgodot.com/posts/record-terminal/</link><pubDate>Sun, 07 Nov 2021 21:35:44 +0800</pubDate><guid>https://iamgodot.com/posts/record-terminal/</guid><description>这几天在做一个 CLI 项目，因为涉及到命令行操作，所以想录制一段 GIF 放在 README 中展示。
印象里这种工具都是 JS 写的，但搜了搜居然发现有个 Python 的实现：asciinema
用法很简单，就是安装好之后在命令行执行 asciinema rec 便会启动一个新的 Shell 并开始录制，录制的时候就像正常使用 Terminal 一样即可，完成之后按 Ctrl-D 或者 Exit 退出，asciinema 会把录制好的 cast 文件保存到本地，也可以选择上传到他们的网站：asciinema.org.
那么 cast 文件是什么，又怎样得到 GIF 呢？其实这是 asciinema 自己定义的一种文件格式：
A CAST file is a record of a terminal session recorded using asciinema, an open source terminal recording program. It contains a JSON-formatted header and a timestamped record of the text typed and printed during a terminal session.</description></item><item><title>Look and Say</title><link>https://iamgodot.com/posts/look-and-say/</link><pubDate>Sun, 07 Nov 2021 16:59:50 +0800</pubDate><guid>https://iamgodot.com/posts/look-and-say/</guid><description>无意中看到一种叫 look-and-say 的数列，很有意思，有点儿 Fibonacci 的感觉。数列如下：
1, 11, 21, 1211, 111221, 312211, 13112221, 1113213211, &amp;hellip;
从第二位开始，每个数字都是对前一个数的计数结果的描述。比如 11 表示前面的 1 有一个 1，而 21 表示前面的 11 有两个 1，1121 表示 21 有一个 2 和一个 1，依次类推，可以无穷循环出新的结果。（除了 22 这个数字，因为会一直重复 22 本身）
后来查了查才发现原来 Leetcode 也有这道题，不过名字叫做 count-and-say。基本就是给 n 然后求此数列的第 n 项结果。
想了想思路并不难，无非是对一个数字的所有位数循环再计数就好了，不过写的时候很犯难，竟然还写出了一个无比冗长的 for 循环加 if 面条代码。这让我意识到了自己对于循环的认识有多么不够深刻。
之所以犯难，其实是不知道怎样把几种逻辑合并在一起，如果粗暴地列举所有分支大概是这样：
def find_next(num: str): result = &amp;#39;&amp;#39; cur, count = num[0], 1 size = len(num) for i in range(1, size): if num[i] == cur and i == size - 1: # count 加一 # 更新 result elif num[i] == cur: # count 加一 elif i == size - 1: # 更新 result # 更新 cur&amp;amp;count # 更新 result else: # 更新 result # 更新 cur&amp;amp;count # 还有一种情况就是并没有进入 for 循环 # 那么也需要更新 result 直接按照这些分支把代码填满肯定很难看，所以要挑选合并。看起来只有第二个分支不需要更新 result，于是我决定把它单拎出来：如果 num[i]==cur 那么 count 加一；否则就更新 result 以及 cur&amp;amp;count.</description></item><item><title>Find Median</title><link>https://iamgodot.com/posts/find-median/</link><pubDate>Wed, 03 Nov 2021 17:07:04 +0800</pubDate><guid>https://iamgodot.com/posts/find-median/</guid><description>祸从天降的一天。
早上起不来，于是刷手机清醒一下，突然看到一个 ACMer 楼主提到自己没有刷过 Leetcode，面试的时候差点儿被打脸了。
看了一下题目，要求是 O(logn) 的复杂度，默默想了想，没有特别清晰的思路。
结果翻了翻评论，很多人都在蜻蜓点水般地表示二分查找不断分割就可以了。
要那么简单还用你说吗？起床了起床了。
题目是这样的：
给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数。
我本来的想法是归并之后计算中位数，但只能做到 O(m+n)，再优化感觉只能二分了。
于是又开始想分别取两个数组的中位数，比较之后就可以各扔掉一半，然后对两个折半的数组继续取中位数比较。
比如一开始找到的中位数是这样：[&amp;hellip;5&amp;hellip;], [&amp;hellip;10&amp;hellip;]，那么 5 的左边和 10 的右边就可以丢掉了，因为最终的中位数肯定在 5 和 10 中间。
如果接下来是这样：[5..8&amp;hellip;], [&amp;hellip;7..10]，那么 8 的右边和 7 的左边也可以丢掉，因为比 8 大的元素数量达不到这两个小数组的一半，所以中位数不会在里面，比 7 小的同理。
一直重复这个流程，最后得到的肯定就是一个或两个数，平均下就好了，时间复杂度也是符合要求的 O(logn).
结果等到看完标答后我才反应过来自己错在哪里了，这是后话。（因为 m 和 n 不一定一样大，所以显然折半的逻辑不对）
最优的解决方案是可以做到 O(log min(m, n)) 的，核心也是二分法，不过思路要复杂一些：
首先明确中位数的定义。对于奇数个数字来说是最中间的元素，偶数则是中间两个元素的平均值。 要做的是将两个数组各分一刀，假设划分的下标分别是 i 和 j，那么 nums1 被分成 nums1[0, i], nums1[i:]，而 nums2 分为 nums2[0, j], nums2[j:]. 因为数组中元素的数量是奇是偶不一定，所以规定好是奇数的话多的一个放到左边。如此 i 的位置就是右边部分的第一个，而左半边正好有 i 个元素。 下标 i 和 j 之间是存在一个等式关系的，因为是中位数，所以 i + j 等于元素总数的一半，或者一半多一个（因为说好了左边多一个嘛）。那么就有 i+j=(m+n)/2 | i+j=(m+n)/2+1，合并起来写成 (m+n+1)/2.</description></item><item><title>(Re)Write recursions easily</title><link>https://iamgodot.com/posts/simple-recursion/</link><pubDate>Mon, 25 Oct 2021 08:56:54 +0800</pubDate><guid>https://iamgodot.com/posts/simple-recursion/</guid><description>近来刷题，觉得递归实在神奇。对于有的题目，用循环实现思路很清晰，改成递归却变得非常抽象；另一些相反，递归的做法既简洁又容易理解，但换成迭代就怎样都不明白了。经过几次痛苦的思考之后，我发现其中还是有迹可循的，按照套路来做，至少思路不会走得太偏。
在维基上面发现的关于递归的笑话：
To understand recursion, you must understand recursion.
Write Recursion 审题分析过后，如果选择用递归，需要先明确两个最重要的组成部分：
边界条件，保证函数能够返回，不会无限递归下去 递进关系，也就是上下层递归调用结果的等式规律 比如求 factorial：
def factorial(n): if n &amp;lt;= 2: return n return factorial(n - 1) * n 如果必要的话，还得考虑的是如何维护上下文的状态信息，目的是计算最终的返回值，有两种办法：
使用全局（outer scope）变量 利用参数进行传递 下面的写法就是利用了参数来保存中间的计算结果：
def factorial(n, res): if n &amp;lt;= 2: return res * n return factorial(n - 1, res * n) 也就是所谓的尾递归，对于可以优化尾递归的语言确实可以看成这种方式是从上至下的，而常规的递归则是从下到上。但我理解递归都是先下去再上来的，尾递归只是选择了一去不返而已。
上面的例子比较简单，反转链表的代码就比较难理解一点：
def reverse_list(head): if not head or not head.next: return head new_head = reverse_list_by_recursion(head.next) head.next.next = head head.</description></item><item><title>Use setxkbmap for Keyboard Mapping</title><link>https://iamgodot.com/posts/use-setxkbmap-for-keyboard-mapping/</link><pubDate>Sat, 16 Oct 2021 04:57:10 +0800</pubDate><guid>https://iamgodot.com/posts/use-setxkbmap-for-keyboard-mapping/</guid><description>这是一篇使用（过） Linux Xorg without any DE 以及笔记本外接键盘的人才能理解其中辛酸苦痛的抒情科普文。
TL;DR 外接键盘不要开蓝牙，直接插线，除非你乐意折腾 使用 setxkbmap 而不是 xmodmap 来做 key remapping 不要用 Xorg The Irrational Part 上午十点零一分，端坐到显示器前，深呼吸两次。
Ok，回滚内核版本之后 Screen Lock 卡死的问题果然消失了，我们继续。
进入系统，先看一下昨晚的日志吧：
... 需求目标： 1. 交换 L-Ctrl &amp;amp; Caps-Lock 2. 交换 Win &amp;amp; Alt 当前方案： 使用 xmodmap 自定义配置文件，在 startx 时执行 已知问题： 1. 系统挂起或蓝牙睡眠导致的 keyboard reconnection 会 reset 掉 Win&amp;amp;Alt 的交换 2. 之后重新执行 xmodmap 会导致 L-Ctrl&amp;amp;Caps-Lock 交换回原状，必须执行两次 后续跟进： 1. TTY console switch 快捷键不可用 2. Terminate X 快捷键 CAB(Ctrl-Alt-Backspace) 不可用 3.</description></item><item><title>Use emoji in MySQL</title><link>https://iamgodot.com/posts/use-emoji-in-mysql/</link><pubDate>Sat, 21 Nov 2020 17:22:18 +0800</pubDate><guid>https://iamgodot.com/posts/use-emoji-in-mysql/</guid><description>最近碰到一个服务器报错，排查后发现是参数中包含了 emoji，导致数据库插入记录失败了。
虽然业务上不要求支持，但好奇之下，我还是基于 MySQL 做了个实验。
What&amp;rsquo;s emoji 🧐 关于 emoji 比较官方的解释：
Emoji are pictographs (pictorial symbols) that are typically presented in a colorful form and used inline in text. They represent things such as faces, weather, vehicles and buildings, food and drink, animals and plants, or icons that represent emotions, feelings, or activities.
那么 emoji 是怎么来的呢：
Emoji are &amp;ldquo;picture characters&amp;rdquo; originally associated with cellular telephone usage in Japan, but now popular worldwide.</description></item><item><title>The Art of Readable Code</title><link>https://iamgodot.com/posts/the-art-of-readable-code/</link><pubDate>Sat, 31 Oct 2020 15:54:05 +0800</pubDate><guid>https://iamgodot.com/posts/the-art-of-readable-code/</guid><description>最近读了《编写可读代码的艺术》这本书，收获良多。
整本书的核心都在于一个原则：代码应当易于理解。作者在开篇就提出了可读性的概念：
代码的写法应当使别人理解它所需要的时间最小化。
上述的别人更有可能是未来的自己，所以保证可读性非常有助于节省自己的时间。
Naming There are only two hard things in Computer Science: cache invalidation and naming things. &amp;ndash; Phil Karlton
命名非常重要。不论是变量常量，还是方法对象，一旦确定名称，代码的整体风格就开始受到影响，并且会一直持续下去。
书里介绍的各种技巧，大致都基于信息量和准确性两点。前者可以保证名称足够有意义，同时也检验了其存在的必要性；而后者能够减少代码中的重复定义，还有助于加速 debug 的推导过程。
另外，单词量有时也会影响命名能力。比如 make，作为动词来描述一个操作可能并不够清晰，更好的选择还有 create/generate/setup/compose 等。如果不认识这些单词，就想不到更多更合适的名称。
Comment 给代码加注释是一件很有争议的事情，因此作者也提到：要明确什么时候需要，什么时候不需要。好的代码如同好的文章，自成一体，但这不代表注释就是无意义的。
广义上讲，注释也是另一种形式的文档。单行注释、方法的注解和模块的说明，对于不想了解实现细节的人来说，比代码本身更有价值。
在工作中，写文档的时间并不比编码少。两者并不冲突，因为归根到底都是要把一件事情描述清楚，一个给人看，另一个给机器。文档写得清晰，写代码也会轻松。从使用者的角度看，对于开源项目，我们对文档的关注度更高，在使用中大部分时间都是在查阅手册，而非源代码。
Less is more 在 Python 中写出好看的 Oneliner 很容易，但后果可能是灾难性的，会给代码的修改和调试过程带来意想不到的困难。Debug 时往往需要快速定位问题，如果遇到过于压缩的语句，便很难在短时间内拆解逻辑，更不用说再做修改，此时的代码就像个花瓶，精致而易碎。
Less is more。不考虑可读性的话，代码越少，带来的麻烦反而会越多。
Writing 书里还说把想法变成代码，关键在于是否能把程序要做的事情用自然语言解释清楚。
这和写文章何其相似：命题，描述中心思想，行文通顺，言之有物。如果是写一个函数，那就变成：抽象接口，梳理逻辑，解耦并拆分子任务。
随着时间发展，还要给内容做适当的减法。比如抽取重复的代码逻辑，OOP，用第三方库代替现有功能。对于文章来说则是，删除废话，同样的描述语只保留一个，使用更精简的词汇表达等等。
把编码当成写作，是这件事最吸引我的地方。前者不只是枯燥的堆砌，后者也并非涂鸦般简单，在 Art of readability 这一点上，它们是相通的。</description></item></channel></rss>